{"meta":{"title":"Marlowe","subtitle":"","description":"","author":"John Doe","url":"https://xmmarlowe.github.io","root":"/"},"pages":[{"title":"","date":"2020-12-02T14:11:24.545Z","updated":"2020-12-02T14:11:24.545Z","comments":true,"path":"404.html","permalink":"https://xmmarlowe.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2020-10-12T12:20:20.000Z","updated":"2020-12-01T14:26:10.112Z","comments":true,"path":"about/index.html","permalink":"https://xmmarlowe.github.io/about/index.html","excerpt":"","text":"个人博客：Marlowe毕业学校：重庆理工大学本科专业：计算机科学与技术个人邮箱：marlowe246@qq.comGithub:Marlowe"},{"title":"所有分类","date":"2020-12-01T14:23:54.558Z","updated":"2020-12-01T14:23:54.558Z","comments":true,"path":"categories/index.html","permalink":"https://xmmarlowe.github.io/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-12-01T14:23:54.500Z","updated":"2020-12-01T14:23:54.500Z","comments":true,"path":"tags/index.html","permalink":"https://xmmarlowe.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"海量数据Top K问题","slug":"海量数据Top K问题","date":"2021-05-07T05:40:02.000Z","updated":"2021-05-07T14:49:06.131Z","comments":true,"path":"2021/05/07/海量数据Top K问题/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/07/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AETop%20K%E9%97%AE%E9%A2%98/","excerpt":"问题引入：10亿个数中找出最大的10000个数（top K问题）","text":"问题引入：10亿个数中找出最大的10000个数（top K问题） Top K 问题在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最高的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。 针对top K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆，即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树或者Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K。 解决的几种方法假设场景为：1亿个数中找出最大的1000个数 直接排序最容易想到的方法是将数据全部排序，然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的1000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。 局部淘汰法第二种方法为局部淘汰法，该方法与排序方法类似，用一个容器保存前1000个数，然后将剩余的所有数字——与容器内的最小数字相比，如果所有后续的元素都比容器内的1000个数还小，那么容器内这个1000个数就是最大1000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小，即1000。 分治法第三种方法是分治法，将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的1000个，最后在剩下的100*1000个数据里面找出最大的1000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的1000个数据的方法如下：用快速排序的方法。 Hash法第四种方法是Hash法。如果这1亿个数里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的1000个数。 最小堆第五种方法采用最小堆。首先读入前1000个数来创建大小为1000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为1000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后输出当前堆中的所有1000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是1000（常数）。 分场景方法选择实际上，最优的解决方案应该是最符合实际设计需求的方案，在时间应用中，可能有足够大的内存，那么直接将数据扔到内存中一次性处理即可，也可能机器有多个核，这样可以采用多线程处理整个数据集。 下面针对不同的应用场景，分析了适合相应应用场景的解决方案。 单机+单核+足够大内存如果需要查找10亿个查询次（每个占8B）中出现频率最高的10个，考虑到每个查询词占8B，则10亿个查询次所需的内存大约是10^9 * 8B=8GB内存。如果有这么大内存，直接在内存中对查询次进行排序，顺序遍历找出10个出现频率最大的即可。这种方法简单快速，使用。然后，也可以先用HashMap求出每个词出现的频率，然后求出频率最大的10个词。 单机+多核+足够大内存这时可以直接在内存中使用Hash方法将数据划分成n个partition，每个partition交给一个线程处理，线程的处理逻辑同（1）类似，最后一个线程将结果归并。 该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。而针对此问题，解决的方法是，将数据划分成c×n个partition（c&gt;1），每个线程处理完当前partition后主动取下一个partition继续处理，知道所有数据处理完毕，最后由一个线程进行归并。 单机+单核+受限内存这种情况下，需要将原数据文件切割成一个一个小文件，如次啊用hash(x)%M，将原文件中的数据切割成M小文件，如果小文件仍大于内存大小，继续采用Hash的方法对数据文件进行分割，知道每个小文件小于内存大小，这样每个文件可放到内存中处理。采用（1）的方法依次处理每个小文件。 多机+受限内存这种情况，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用（3）中的策略解决本地的数据。可采用hash+socket方法进行数据分发。 重点讲下最小堆算法 在几千亿个数据中如何获取10000个最大的数？ 一个复杂度比较低的算法就是利用最小堆算法，它的思想就是：先建立一个容量为K的最小堆，然后遍历这几千亿个数，如果对于遍历到的数大于最小堆的根节点，那么这个数入堆，并且调整最小堆的结构，遍历完成以后，最小堆的数字就是这几千亿个数中最大的K个数了。 先来介绍一下最小堆：最小堆（小根堆）是一种数据结构，它首先是一颗完全二叉树，并且，它所有父节点的值小于或等于两个子节点的值。最小堆的存储结构（物理结构）实际上是一个数组。 因为它是一个完全二叉树，对于下标小于 数组.length/2 - 1 时有叶子节点 ， 对于下标为i（基0），其左节点下标为2i + 1，右节点下标为2i + 2。 最小堆如图所示，对于每个非叶子节点的数值，一定不大于孩子节点的数值。这样可用含有K个节点的最小堆来保存K个目前的最大值(当然根节点是其中的最小数值)。 每次有数据输入的时候可以先与根节点比较。若不大于根节点，则舍弃；否则用新数值替换根节点数值。并进行最小堆的调整。 代码实现：创建堆的复杂度是O(N)，调整最小堆的时间复杂度为O(logK)，因此Top K算法(问题)时间复杂度为O(NlogK)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class TopK &#123; //创建堆 int[] createHeap(int a[], int k) &#123; int[] result = new int[k]; for (int i = 0; i &lt; k; i++) &#123; result[i] = a[i]; &#125; //完全二叉树的数组表示中，下标小于等于result.length / 2 - 1才有子节点 for (int i = result.length / 2 - 1;i &gt;= 0;i--)&#123; heapify(i,result); &#125; return result; &#125; void heapify(int i,int[] result)&#123; int left = 2 * i + 1; int right = 2 * i + 2; int smallest = i; if (left &lt; result.length &amp;&amp; result[left] &lt; result[i])&#123; smallest = left; &#125; if (right &lt; result.length &amp;&amp; result[right] &lt; result[smallest])&#123; smallest = right; &#125; if (smallest == i)&#123; return; &#125; else &#123; int temp = result[i]; result[i] = result[smallest]; result[smallest] = temp; &#125; heapify(smallest,result); &#125; //调整堆 void filterDown(int a[], int value) &#123; a[0] = value; int parent = 0; while(parent &lt; a.length)&#123; int left = 2*parent+1; int right = 2*parent+2; int smallest = parent; if(left &lt; a.length &amp;&amp; a[parent] &gt; a[left])&#123; smallest = left; &#125; if(right &lt; a.length &amp;&amp; a[smallest] &gt; a[right])&#123; smallest = right; &#125; if(smallest == parent)&#123; break; &#125;else&#123; int temp = a[parent]; a[parent] = a[smallest]; a[smallest] = temp; parent = smallest; &#125; &#125; &#125; //遍历数组，并且调整堆 int[] findTopKByHeap(int input[], int k) &#123; int heap[] = this.createHeap(input, k); for(int i=k;i&lt;input.length;i++)&#123; if(input[i]&gt;heap[0])&#123; this.filterDown(heap, input[i]); &#125; &#125; return heap; &#125; public static void main(String[] args) &#123; int a[] = &#123; 100,101,5,4,88,89,845,45,8,4,5,8,452,1,5,8,4,5,8,4,588,44444,88888,777777,100000&#125;; int result[] = new TopK().findTopKByHeap(a, 5); for (int temp : result) &#123; System.out.println(temp); &#125; &#125;&#125; 参考10亿个数中找出最大的10000个数（top K问题）","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://xmmarlowe.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Top K","slug":"Top-K","permalink":"https://xmmarlowe.github.io/tags/Top-K/"}],"author":"Marlowe"},{"title":"进程调度算法","slug":"操作系统/进程调度算法","date":"2021-05-07T05:10:56.000Z","updated":"2021-05-07T14:49:06.135Z","comments":true,"path":"2021/05/07/操作系统/进程调度算法/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/","excerpt":"","text":"介绍无论是在批处理系统还是分时系统中，用户进程数一般都多于处理机数、这将导致它们互相争夺处理机。另外，系统进程也同样需要使用处理机。这就要求进程调度程序按一定的策略，动态地把处理机分配给处于就绪队列中的某一个进程，以使之执行。 7种调度算法先来先服务调度算法（FCFS）先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。 执行时间与调度之后执行顺序： 短作业优先(SJF)的调度算法从就绪队列中选出⼀个估计运⾏时间最短的进程为之分配资源，使它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被阻塞放弃占⽤ CPU 时再重新调度。 优先级调度为每个流程分配优先级，⾸先执⾏具有最⾼优先级的进程，依此类推。具有相同优先级的进程以 FCFS ⽅式执⾏。可以根据内存要求，时间要求或任何其他资源要求来确定优先级 时间⽚轮转调度算法(RR)时间⽚轮转调度是⼀种最古⽼，最简单，最公平且使⽤最⼴的算法，⼜称 RR(Round robin)调度。每个进程被分配⼀个时间段，称作它的时间⽚，即该进程允许运⾏的时间。 时间片为4，到期后切换下一个进程： 最短剩余时间优先最短剩余时间是针对最短进程优先增加了抢占机制的版本。在这种情况下，进程调度总是选择预期剩余时间最短的进程。当一个进程加入到就绪队列时，他可能比当前运行的进程具有更短的剩余时间，因此只要新进程就绪，调度程序就能可能抢占当前正在运行的进程。像最短进程优先一样，调度程序正在执行选择函数是必须有关于处理时间的估计，并且存在长进程饥饿的危险。 高响应比优先调度算法根据比率：R=(w+s)/s （R为响应比，w为等待处理的时间，s为预计的服务时间） 如果该进程被立即调用，则R值等于归一化周转时间（周转时间和服务时间的比率）。R最小值为1.0，只有第一个进入系统的进程才能达到该值。调度规则为：当前进程完成或被阻塞时，选择R值最大的就绪进程，它说明了进程的年龄。当偏向短作业时，长进程由于得不到服务，等待时间不断增加，从而增加比值，最终在竞争中赢了短进程。和最短进程优先、最短剩余时间优先一样，使用最高响应比策略需要估计预计服务时间。 ​ 高响应比优先调度算法主要用于作业调度，该算法是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。 根据公式可知： 当作业的等待时间相同时，则要求服务时间越短，其响应比越高，有利于短作业。 当要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。 对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。克服了饥饿状态，兼顾了长作业。 多级反馈队列调度算法前⾯介绍的⼏种进程调度的算法都有⼀定的局限性。如短进程优先的调度算法，仅照顾了短进程⽽忽略了⻓进程 。多级反馈队列调度算法既能使⾼优先级的作业得到响应⼜能使短作业（进程）迅速完成。，因⽽它是⽬前被公认的⼀种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。 多级反馈队列调度算法的实现思想如下： 应设置多个就绪队列，并为各个队列赋予不同的优先级，第1级队列的优先级最高，第2级队列次之，其余队列的优先级逐次降低。 赋予各个队列中进程执行时间片的大小也各不相同，在优先级越高的队列中，每个进程的运行时间片就越小。例如，第2级队列的时间片要比第1级队列的时间片长一倍， ……第i+1级队列的时间片要比第i级队列的时间片长一倍。 当一个新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第2级队列的末尾，再同样地按FCFS 原则等待调度执行；如果它在第2级队列中运行一个时间片后仍未完成，再以同样的方法放入第3级队列……如此下去，当一个长进程从第1级队列依次降到第 n 级队列后，在第 n 级队列中便釆用时间片轮转的方式运行。 仅当第1级队列为空时，调度程序才调度第2级队列中的进程运行；仅当第1 ~ (i-1)级队列均为空时，才会调度第i级队列中的进程运行。如果处理机正在执行第i级队列中的某进程时，又有新进程进入优先级较高的队列（第 1 ~ (i-1)中的任何一个队列），则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i级队列的末尾，把处理机分配给新到的更高优先级的进程。 参考操作系统之进程调度算法","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"调度","slug":"调度","permalink":"https://xmmarlowe.github.io/tags/%E8%B0%83%E5%BA%A6/"}],"author":"Marlowe"},{"title":"Redis6.0 相关问题","slug":"NoSQL/Redis6-0 相关问题","date":"2021-05-07T04:55:58.000Z","updated":"2021-05-07T14:49:06.138Z","comments":true,"path":"2021/05/07/NoSQL/Redis6-0 相关问题/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/07/NoSQL/Redis6-0%20%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","excerpt":"","text":"Redis6.0之前的版本真的是单线程吗？Redis在处理客户端的请求时，包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。但如果严格来讲从Redis4.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 key 的删除等等。 Redis6.0之前为什么一直不使用多线程？官方曾做过类似问题的回复：使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。 使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。Redis通过AE事件模型以及IO多路复用等技术，处理性能非常高，因此没有必要使用多线程。单线程机制使得 Redis 内部实现的复杂度大大降低，Hash 的惰性 Rehash、Lpush 等等 “线程不安全” 的命令都可以无锁进行。 Redis6.0 之后为何引入了多线程？Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。 虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。 Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80,000到100,000 QPS，这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。 但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QPS。常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器太多，维护代价大；某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。 从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向: 提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式 使用多线程充分利用多核，典型的实现比如 Memcached。 协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因： 可以充分利用服务器 CPU 资源，目前主线程只能利用一个核 多线程任务可以分摊 Redis 同步 IO 读写负荷 Redis6.0默认是否开启了多线程？Redis6.0 的多线程默认是禁用的，只使用主线程。 如需开启需要修改 redis 配置文件 redis.conf ： 1io-threads-do-reads yes Redis6.0多线程开启时，线程数如何设置？开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 redis.conf : 1io-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程 Redis6.0多线程的实现机制？ 流程简述如下： 1、主线程负责接收建立连接请求，获取 socket 放入全局等待读处理队列 2、主线程处理完读事件之后，通过 RR(Round Robin) 将这些连接分配给这些 IO 线程 3、主线程阻塞等待 IO 线程读取 socket 完毕 4、主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行 5、主线程阻塞等待 IO 线程将数据回写 socket 完毕 6、解除绑定，清空等待队列 该设计有如下特点： 1、IO 线程要么同时在读 socket，要么同时在写，不会同时读或写 2、IO 线程只负责读写 socket 解析命令，不负责命令处理 开启多线程后，是否会存在线程并发安全问题？从上面的实现机制可以看出，Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行。所以我们不需要去考虑控制 key、lua、事务，LPUSH/LPOP 等等的并发及线程安全问题。 Redis6.0的多线程和Memcached多线程模型进行对比前些年memcached 是各大互联网公司常用的缓存方案，因此redis 和 memcached 的区别基本成了面试官缓存方面必问的面试题，最近几年memcached用的少了，基本都是 redis。不过随着Redis6.0加入了多线程特性，类似的问题可能还会出现，接下来我们只针对多线程模型来简单比较一下。 如上图所示：Memcached 服务器采用 master-woker 模式进行工作，服务端采用 socket 与客户端通讯。主线程、工作线程 采用 pipe管道进行通讯。主线程采用 libevent 监听 listen、accept 的读事件，事件响应后将连接信息的数据结构封装起来，根据算法选择合适的工作线程，将连接任务携带连接信息分发出去，相应的线程利用连接描述符建立与客户端的socket连接 并进行后续的存取数据操作。 Redis6.0与Memcached多线程模型对比： 相同点： 都采用了 master线程-worker 线程的模型 不同点： Memcached 执行主逻辑也是在 worker 线程里，模型更加简单，实现了真正的线程隔离，符合我们对线程隔离的常规理解。而 Redis 把处理逻辑交还给 master 线程，虽然一定程度上增加了模型复杂度，但也解决了线程并发安全等问题。 Redis线程中经常提到IO多路复用，如何理解？这是IO模型的一种，即经典的Reactor设计模式，有时也称为异步阻塞IO。 多路指的是多个socket连接，复用指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。 参考Redis 6.0 新特性-多线程连环13问！","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis 单线程模型","slug":"NoSQL/Redis-单线程模型","date":"2021-05-06T14:44:45.000Z","updated":"2021-05-07T05:20:51.279Z","comments":true,"path":"2021/05/06/NoSQL/Redis-单线程模型/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/06/NoSQL/Redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Redis单线程模型文件事件处理器 Redis基于Reactor模式开发了网络事件处理器,这个处理器就叫做文件事件处理器(file event handler).这个文件事件处理器是单线程的,所以Redis才叫做单线程的模型,文件事件处理器采用了IO多路复用机制同时监听多个socket,根据socket上的事件来选择对应的事件处理器来处理这个事件; 如果被监听的socket准备好执行accept,read,write,close等事件/操作的时候,跟事件/操作对应的文件事件就会产生,这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件; 文件事件处理器是单线程模式运行的,但是通过IO多路复用机制监听多个socket,可以实现高性能的网络通信模型.又可以跟内部其他单线程的模块进行对接,保证了Redis内部的线程模型的简单性; 文件事件处理器的结构包含4个部分 ①.多个socket;②.IO多路复用程序;③.文件事件分派器;④.事件处理器(命令请求处理器,命令回复处理器,连接应答处理器等等); 多个socket可能并发的产生不同的操作,每个操作对应不同的文件事件,但是IO多路复用程序会监听多个socket,会将socket放入一个队列中排队,然后每次从队列中取出一个socket给事件分派器,事件分派器再把socket分派给对应的事件处理器去处理; 当一个socket的事件被处理完之后,IO多路复用程序才会将队列中的下一个socket取出交给事件分派器.文件事件分派器再根据socket当前产生的事件来选择对应的事件处理器来处理; 文件事件 当socket变得可读时(比如客户端对Redis执行write操作或者close操作),或者有新的可以应答的socket出现时(客户端对Redis执行connect操作),socket就会产生一个”AE_READABLE”事件; 当socket变得可写的时候(客户端对Redis执行read操作),socket就会产生一个”AE_WRITABLE”事件; IO多路复用程序可以同时监听”AE_READABLE”和”AE_WRITABLE”两种事件,要是一个socket同时产生了”AE_READABLE”和”AE_WRITABLE”两种事件,那么文件事件分派器会优先处理”AE_READABLE”事件,然后才是”AE_WRITABLE”事件; 常用的文件事件处理器 如果是客户端要连接Redis,那么会为socket关联连接应答处理器; 如果是客户端要写数据到Redis,那么会为socket关联命令请求处理器; 如果是客户端要从Redis中读取数据(Redis发送数据给客户端),那么会为socket关联命令回复处理器; 客户端与Redis通信的一次流程如图: 说明: ①.在Redis启动及初始化的时候,Redis会(预先)将连接应答处理器跟”AE_READABLE”事件关联起来,接着如果一个客户端向Redis发起连接,此时就会产生一个”AE_READABLE”事件,然后由连接应答处理器来处理跟客户端建立连接,创建客户端对应的socket,同时将这个socket的”AE_READABLE”事件跟命令请求处理器关联起来;②.当客户端向Redis发起请求的时候(不管是读请求还是写请求,都一样),首先就会在之前创建的客户端对应的socket上产生一个”AE_READABLE”事件,然后IO多路复用程序会监听到在之前创建的客户端对应的socket上产生了一个”AE_READABLE”事件,接着把这个socket放入一个队列中排队,然后由文件事件分派器从队列中获取socket交给对应的命令请求处理器来处理(因为之前在Redis启动并进行初始化的时候就已经预先将”AE_READABLE”事件跟命令请求处理器关联起来了).之后命令请求处理器就会从之前创建的客户端对应的socket中读取请求相关的数据,然后在自己的内存中进行执行和处理;③.当客户端请求处理完成,Redis这边也准备好了给客户端的响应数据之后,就会(预先)将socket的”AE_WRITABLE”事件跟命令回复处理器关联起来,当客户端这边准备好读取响应数据时,就会在之前创建的客户端对应的socket上产生一个”AE_WRITABLE”事件,然后IO多路复用程序会监听到在之前创建的客户端对应的socket上产生了一个”AE_WRITABLE”事件,接着把这个socket放入一个队列中排队,然后由文件事件分派器从队列中获取socket交给对应的命令回复处理器来处理(因为之前在Redis这边准备好给客户端的响应数据之后就已经预先将”AE_WRITABLE”事件跟命令回复处理器关联起来了),之后命令回复处理器就会向之前创建的客户端对应的socket输出/写入准备好的响应数据,最终返回给客户端,供客户端来读取;④.当命令回复处理器将准备好的响应数据写完之后,就会删除之前创建的客户端对应的socket上的”AE_WRITABLE”事件和命令回复处理器的关联关系; 为什么Redis单线程模型也能效率这么高? 纯内存操作; 核心是基于非阻塞的IO多路复用机制; 底层使用C语言实现,一般来说,C 语言实现的程序”距离”操作系统更近,执行速度相对会更快; 单线程同时也避免了多线程的上下文频繁切换问题,预防了多线程可能产生的竞争问题; 参考Redis单线程模型","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Linux常用命令总结","slug":"操作系统/Linux常用命令总结","date":"2021-05-06T14:20:52.000Z","updated":"2021-05-07T05:20:43.229Z","comments":true,"path":"2021/05/06/操作系统/Linux常用命令总结/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/","excerpt":"","text":"目录切换命令 cd usr： 切换到该目录下 usr 目录 cd ..（或cd../）： 切换到上一层目录 cd /： 切换到系统根目录 cd ~： 切换到用户主目录 cd -： 切换到上一个操作所在目录 目录的操作命令(增删改查) mkdir 目录名称： 增加目录。 ls/ll（ll 是 ls -l 的别名，ll 命令可以看到该目录下的所有目录和文件的详细信息）：查看目录信息。 find 目录 参数： 寻找目录（查）。示例：① 列出当前目录及子目录下所有文件和文件夹: find .；② 在/home目录下查找以.txt 结尾的文件名:find /home -name “.txt” ,忽略大小写: find /home -iname “.txt” ；③ 当前目录及子目录下查找所有以.txt 和.pdf 结尾的文件:find . ( -name “.txt” -o -name “.pdf” )或find . -name “.txt” -o -name “.pdf”。 mv 目录名称 新目录名称： 修改目录的名称（改）。注意：mv 的语法不仅可以对目录进行重命名而且也可以对各种文件，压缩包等进行 重命名的操作。mv 命令用来对文件或目录重新命名，或者将文件从一个目录移到另一个目录中。后面会介绍到 mv 命令的另一个用法。 mv 目录名称 目录的新位置： 移动目录的位置—剪切（改）。注意：mv 语法不仅可以对目录进行剪切操作，对文件和压缩包等都可执行剪切操作。另外 mv 与 cp 的结果不同，mv 好像文件“搬家”，文件个数并未增加。而 cp 对文件进行复制，文件个数增加了。 cp -r 目录名称 目录拷贝的目标位置： 拷贝目录（改），-r 代表递归拷贝 。注意：cp 命令不仅可以拷贝目录还可以拷贝文件，压缩包等，拷贝文件和压缩包时不 用写-r 递归。 rm [-rf] 目录: 删除目录（删）。注意：rm 不仅可以删除目录，也可以删除其他文件或压缩包，为了增强大家的记忆， 无论删除任何目录或文件，都直接使用rm -rf 目录/文件/压缩包。 文件的操作命令(增删改查) touch 文件名称: 文件的创建（增）。 cat/more/less/tail 文件名称： 文件的查看（查） 。命令 tail -f 文件 可以对某个文件进行动态监控，例如 tomcat 的日志文件， 会随着程序的运行，日志会变化，可以使用 tail -f catalina-2016-11-11.log 监控 文 件的变化 。 vim 文件： 修改文件的内容（改）。vim 编辑器是 Linux 中的强大组件，是 vi 编辑器的加强版，vim 编辑器的命令和快捷方式有很多，但此处不一一阐述，大家也无需研究的很透彻，使用 vim 编辑修改文件的方式基本会使用就可以了。在实际开发中，使用 vim 编辑器主要作用就是修改配置文件，下面是一般步骤： vim 文件——&gt;进入文件—–&gt;命令模式——&gt;按i进入编辑模式—–&gt;编辑文件 ——-&gt;按Esc进入底行模式—–&gt;输入：wq/q! （输入 wq 代表写入内容并退出，即保存；输入 q!代表强制退出不保存）。 rm -rf 文件： 删除文件（删）。 压缩文件的操作命令打包并压缩文件Linux 中的打包文件一般是以.tar 结尾的，压缩的命令一般是以.gz 结尾的。而一般情况下打包和压缩是一起进行的，打包并压缩后的文件的后缀名一般.tar.gz。 命令：tar -zcvf 打包压缩后的文件名 要打包压缩的文件 ，其中： z：调用 gzip 压缩命令进行压缩 c：打包文件 v：显示运行过程 f：指定文件名 比如：假如 test 目录下有三个文件分别是：aaa.txt bbb.txt ccc.txt，如果我们要打包 test 目录并指定压缩后的压缩包名称为 test.tar.gz 可以使用命令：tar -zcvf test.tar.gz aaa.txt bbb.txt ccc.txt 或 tar -zcvf test.tar.gz /test/ 解压压缩包命令：tar [-xvf] 压缩文件 其中：x：代表解压 示例： 将 /test 下的 test.tar.gz 解压到当前目录下可以使用命令：tar -xvf test.tar.gz 将 /test 下的 test.tar.gz 解压到根目录/usr 下:tar -xvf test.tar.gz -C /usr（- C 代表指定解压的位置） Linux 的权限命令操作系统中每个文件都拥有特定的权限、所属用户和所属组。权限是操作系统用来限制资源访问的机制，在 Linux 中权限一般分为读(readable)、写(writable)和执行(excutable)，分为三组。分别对应文件的属主(owner)，属组(group)和其他用户(other)，通过这样的机制来限制哪些用户、哪些组可以对特定的文件进行什么样的操作。 通过 ls -l 命令我们可以 查看某个目录下的文件或目录的权限 示例：在随意某个目录下ls -l 第一列的内容的信息解释如下： 下面将详细讲解文件的类型、Linux 中权限以及文件有所有者、所在组、其它组具体是什么？ 文件的类型： d： 代表目录 -： 代表文件 l： 代表软链接（可以认为是 window 中的快捷方式） Linux 中权限分为以下几种： r：代表权限是可读，r 也可以用数字 4 表示 w：代表权限是可写，w 也可以用数字 2 表示 x：代表权限是可执行，x 也可以用数字 1 表示 文件和目录权限的区别： 对文件和目录而言，读写执行表示不同的意义。 对于文件： 权限名称 可执行操作 r 可以使用 cat 查看文件的内容 w 可以修改文件的内容 x 可以将其运行为二进制文件 对于目录：|权限名称|可执行操作||:–:|:–:||r|可以查看目录下列表||w|可以创建和删除目录下文件||x|可以使用 cd 进入目录| 需要注意的是： 超级用户可以无视普通用户的权限，即使文件目录权限是 000，依旧可以访问。 在 linux 中的每个用户必须属于一个组，不能独立于组外。在 linux 中每个文件有所有者、所在组、其它组的概念。 所有者(u)： 一般为文件的创建者，谁创建了该文件，就天然的成为该文件的所有者，用 ls ‐ahl 命令可以看到文件的所有者 也可以使用 chown 用户名 文件名来修改文件的所有者 。 文件所在组(g)： 当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组用 ls ‐ahl命令可以看到文件的所有组也可以使用 chgrp 组名 文件名来修改文件所在的组。 其它组(o)： 除开文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组。 修改文件/目录的权限的命令：chmod 示例：修改/test 下的 aaa.txt 的权限为文件所有者有全部权限，文件所有者所在的组有读写权限，其他用户只有读的权限。 chmod u=rwx,g=rw,o=r aaa.txt 或者 chmod 764 aaa.txt 补充一个比较常用的东西: 假如我们装了一个 zookeeper，我们每次开机到要求其自动启动该怎么办？ 新建一个脚本 zookeeper为新建的脚本 zookeeper 添加可执行权限，命令是:chmod +x zookeeper把 zookeeper 这个脚本添加到开机启动项里面，命令是：chkconfig –add zookeeper如果想看看是否添加成功，命令是：chkconfig –list Linux 用户管理Linux 系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 Linux 用户管理相关命令: useradd 选项 用户名:添加用户账号 userdel 选项 用户名:删除用户帐号 usermod 选项 用户名:修改帐号 passwd 用户名:更改或创建用户的密码 passwd -S 用户名 :显示用户账号密码信息 passwd -d 用户名: 清除用户密码 useradd 命令用于 Linux 中创建的新的系统用户。useradd可用来建立用户帐号。帐号建好之后，再用passwd设定帐号的密码．而可用userdel删除帐号。使用useradd指令所建立的帐号，实际上是保存在 /etc/passwd文本文件中。 passwd命令用于设置用户的认证信息，包括用户密码、密码过期时间等。系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 Linux 系统用户组的管理每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同 Linux 系统对用户组的规定有所不同，如 Linux 下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。 Linux 系统用户组的管理相关命令: groupadd 选项 用户组 :增加一个新的用户组 groupdel 用户组:要删除一个已有的用户组 groupmod 选项 用户组 : 修改用户组的属性 其他常用命令 pwd： 显示当前所在位置 sudo + 其他命令：以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行。 grep 要搜索的字符串 要搜索的文件 –color： 搜索命令，–color 代表高亮显示 ps -ef/ps -aux： 这两个命令都是查看当前系统正在运行进程，两者的区别是展示格式不同。如果想要查看特定的进程可以使用这样的格式：ps aux|grep redis （查看包括 redis 字符串的进程），也可使用 pgrep redis -a。 注意：如果直接用 ps（（Process Status））命令，会显示所有进程的状态，通常结合 grep 命令查看某进程的状态。 kill -9 进程的pid： 杀死进程（-9 表示强制终止。）先用 ps 查找进程，然后用 kill 杀掉 网络通信命令： 查看当前系统的网卡信息：ifconfig 查看与某台机器的连接情况：ping 查看当前系统的端口使用：netstat -an 查看磁盘信息命令： df -hl：查看磁盘剩余空间 df -h：查看每个根路径的分区大小 du -sh [目录名]：返回该目录的大小 du -sm [文件夹]：返回该文件夹总M数 du -h [目录名]：查看指定文件夹下的所有文件大小（包含子文件夹） du(disk usage)df 以磁盘分区为单位查看文件系统，可以获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 net-tools 和 iproute2 ： net-tools起源于 BSD 的 TCP/IP 工具箱，后来成为老版本 LinuxLinux 中配置网络功能的工具。但自 2001 年起，Linux 社区已经对其停止维护。同时，一些 Linux 发行版比如 Arch Linux 和 CentOS/RHEL 7 则已经完全抛弃了 net-tools，只支持iproute2。linux ip 命令类似于 ifconfig，但功能更强大，旨在替代它。更多详情请阅读如何在 Linux 中使用 IP 命令和示例 shutdown： shutdown -h now： 指定现在立即关机；shutdown +5 “System will shutdown after 5 minutes”：指定 5 分钟后关机，同时送出警告信息给登入用户。 reboot： reboot： 重开机。reboot -w： 做个重开机的模拟（只有纪录并不会真的重开机）。 参考Linux 基本命令","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://xmmarlowe.github.io/tags/Linux/"},{"name":"命令","slug":"命令","permalink":"https://xmmarlowe.github.io/tags/%E5%91%BD%E4%BB%A4/"}],"author":"Marlowe"},{"title":"进程状态与僵尸进程、孤儿进程","slug":"操作系统/进程状态与僵尸进程、孤儿进程","date":"2021-05-06T12:18:12.000Z","updated":"2021-05-07T05:20:42.945Z","comments":true,"path":"2021/05/06/操作系统/进程状态与僵尸进程、孤儿进程/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E4%B8%8E%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E3%80%81%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/","excerpt":"","text":"进程状态一个进程的生命周期可以划分为一组状态，这些状态刻画了整个进程。进程状态即体现一个进程的生命状态 一般来说，进程有五种状态： 创建状态： 进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 就绪状态： 进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行 执行状态： 进程处于就绪状态被调度后，进程进入执行状态 阻塞状态： 正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止状态： 进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 这五种状态的转换如图： 上面所说的是一个概念性质的，而具体在Linux里，进程的状态是如何定义的？在Linux内核里，进程有时候也叫做任务，下面是状态在kernel源码里的定义： 123456789101112131415/** The task state array is a strange &quot;bitmap&quot; of* reasons to sleep. Thus &quot;running&quot; is zero, and* you can test for combinations of others with* simple bit tests.*/static const char * const task_state_array[] = &#123;&quot;R (running)&quot;, /* 0 */&quot;S (sleeping)&quot;, /* 1 */&quot;D (disk sleep)&quot;, /* 2 */&quot;T (stopped)&quot;, /* 4 */&quot;t (tracing stop)&quot;, /* 8 */&quot;X (dead)&quot;, /* 16 */&quot;Z (zombie)&quot;, /* 32 */&#125;; 这些状态的具体含义是： R运行状态(running): 并不意味着进程一定在运行中，它表明进程要么是在运行中要么在运行队列 里。 S睡眠状态(sleeping): 意味着进程在等待事件完成（这里的睡眠有时候也叫做可中断睡眠 (interruptible sleep))。 D磁盘休眠状态(Disk sleep): 有时候也叫不可中断睡眠状态（uninterruptible sleep），在这个状态的 进程通常会等待IO的结束。 T停止状态(stopped)： 可以通过发送 SIGSTOP 信号给进程来停止（T）进程。这个被暂停的进程可 以通过发送 SIGCONT 信号让进程继续运行。 X死亡状态(dead)： 这个状态只是一个返回状态，你不会在任务列表里看到这个状态。 Z僵死状态(zombie)： 下文具体了解 父进程与子进程在学习接下来的内容之前，需要对父进程和子进程有一个清晰的认识 在Linux里，除了进程0（即PID=0的进程）以外的所有进程都是由其他进程使用系统调用fork创建的，这里调用fork创建新进程的进程即为父进程，而相对应的为其创建出的进程则为子进程，因而除了进程0以外的进程都只有一个父进程，但一个进程可以有多个子进程。 fork函数包含在unistd.h库中，其最主要的特点是，调用一次，返回两次，当父进程fork()创建子进程失败时，fork()返回-1，当父进程fork()创建子进程成功时，此时，父进程会返回子进程的pid，而子进程返回的是0。所以可以根据返回值的不同让父进程和子进程执行不同的代码 如上图所示，当fork()函数调用后，父进程中的变量pid赋值成子进程的pid(pid&gt;0)，所以父进程会执行else里的代码，打印出”This is the parent”，而子进程的变量pid赋值成0，所以子进程执行if(pid == 0)里的代码，打印出”This is the child” 现在我们知道，在Linux中，正常情况下，子进程是通过父进程创建的，子进程再创建新的子进程。但是子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态 知道了这些，我们再来了解两种特殊的进程。 僵尸进程简介一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 上文中提到的进程的僵死状态Z(zombie)就是僵尸进程对应的状态 我们可以写一个程序来查看一下僵尸进程： 1234567891011121314151617181920212223242526#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;int main()&#123; printf(&quot;pid = %d\\n&quot;,getpid()); pid_t pid = fork(); if(pid &lt; 0)&#123; printf(&quot;fork error\\n&quot;); return -1; &#125;else if(pid == 0)&#123; //这段代码只有子进程能够运行到，因为在子进程中fork的返回值为0 printf(&quot;This is the child!pid = %d\\n&quot;,getpid()); sleep(5); exit(0); //退出进程 &#125;else if(pid &gt; 0)&#123; //这段代码只有父进程能运行到 printf(&quot;This is the parent!pid = %d\\n&quot;,getpid()); &#125; //当fork成功时下面的代码父子进程都会运行到 while(1)&#123; printf(&quot;-------------pid = %d\\n&quot;,getpid()); sleep(1); &#125; return 0;&#125; 程序的运行结果： 12345678ubuntu@VM-0-7-ubuntu:~/c_practice$ ./zombie pid = 24816This is the parent!pid = 24816-------------pid = 24816This is the child!pid = 24817-------------pid = 24816-------------pid = 24816..... 在程序开始运行时立即查看进程： (这里我分别运行了两次，分别使用ps -ef和ps -aux查看了进程状态，所以两次的进程PID是不同的) 1234567ubuntu@VM-0-7-ubuntu:~$ ps -ef | grep -v grep | grep zombieubuntu 23797 15818 0 14:53 pts/0 00:00:00 ./zombieubuntu 23798 23797 0 14:53 pts/0 00:00:00 ./zombieubuntu@VM-0-7-ubuntu:~$ ps -aux | grep -v grep | grep zombieubuntu 24288 0.0 0.0 4352 648 pts/0 S+ 14:56 0:00 ./zombieubuntu 24289 0.0 0.0 4352 80 pts/0 S+ 14:56 0:00 ./zombie 在进程运行五秒后再次查看进程： 1234567ubuntu@VM-0-7-ubuntu:~$ ps -ef | grep -v grep | grep zombieubuntu 23797 15818 0 14:53 pts/0 00:00:00 ./zombieubuntu 23798 23797 0 14:53 pts/0 00:00:00 [zombie] &lt;defunct&gt;ubuntu@VM-0-7-ubuntu:~$ ps -aux | grep -v grep | grep zombieubuntu 24288 0.0 0.0 4352 648 pts/0 S+ 14:56 0:00 ./zombieubuntu 24289 0.0 0.0 0 0 pts/0 Z+ 14:56 0:00 [zombie] &lt;defunct&gt; 可以看出当进程运行五秒后，子进程状态变成Z，就是僵死状态，子进程就成了僵尸进程 其实，僵尸进程是有危害的。进程的退出状态必须被维持下去，因为它要告诉关心它的进程（父进程），你交给我的任务，我办的怎么样了。可父进程如果一直不读取，那子进程就一直处于Z状态。维护退出状态本身就是要用数据维护，也属于进程基本信息，所以保存在task_struct(PCB)中，换句话说，当一个进程一直处于Z状态，那么它的PCB也就一直都要被维护。因为PCB本身就是一个结构体会占用空间，僵尸进程也就会造成资源浪费，所以我们应该避免僵尸进程的产生。 孤儿进程简介孤儿进程则是指当一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 代码示例： 123456789101112131415161718192021222324#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;unistd.h&gt;#include&lt;errno.h&gt;int main()&#123; pid_t pid; pid = fork(); if(pid &lt; 0)&#123; perror(&quot;fork error&quot;); exit(1); &#125; if(pid == 0)&#123; printf(&quot;This is the child!\\n&quot;); printf(&quot;pid = %d,ppid = %d\\n&quot;,getpid(),getppid());//父进程退出前的pid和ppid sleep(5); printf(&quot;\\npid = %d,ppid = %d\\n&quot;,getpid(),getppid());//父进程退出后的pid和ppid &#125;else&#123; printf(&quot;This is the father!\\n&quot;); sleep(1); printf(&quot;father process is exited!\\n&quot;); &#125; return 0;&#125; 运行结果： 1234567ubuntu@VM-0-7-ubuntu:~/c_practice$ ./orphan This is the father!This is the child!pid = 2338,ppid = 2337father process is exited!ubuntu@VM-0-7-ubuntu:~/c_practice$ pid = 2338,ppid = 1 我们可以看到结果和我们预见的是一样的，孤儿进程在父进程退出后会被init进程领养，直到自己运行结束为止。这个程序很容易理解,先输出子进程的pid和父进程的pid，再然后子进程开始睡眠父进程退出，这时候子进程变成孤儿进程，再次输出时，该进程的父进程变为init 孤儿进程由于有init进程循环的wait()回收资源，因此并没有什么危害 问题及危害僵尸进程unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 孤儿进程孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上， init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。 这是每个子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 僵尸进程危害场景 例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。 僵尸进程解决办法通过信号机制子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;static void sig_child(int signo);int main()&#123; pid_t pid; //创建捕捉子进程退出信号 signal(SIGCHLD,sig_child); pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am child process,pid id %d.I am exiting.\\n&quot;,getpid()); exit(0); &#125; printf(&quot;I am father process.I will sleep two seconds\\n&quot;); //等待子进程先退出 sleep(2); //输出进程信息 system(&quot;ps -o pid,ppid,state,tty,command&quot;); printf(&quot;father process is exiting.\\n&quot;); return 0;&#125;static void sig_child(int signo)&#123; pid_t pid; int stat; //处理僵尸进程 while ((pid = waitpid(-1, &amp;stat, WNOHANG)) &gt;0) printf(&quot;child %d terminated.\\n&quot;, pid);&#125; 测试结果如下所示： fork两次原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;int main()&#123; pid_t pid; //创建第一个子进程 pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //第一个子进程 else if (pid == 0) &#123; //子进程再创建子进程 printf(&quot;I am the first child process.pid:%d\\tppid:%d\\n&quot;,getpid(),getppid()); pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //第一个子进程退出 else if (pid &gt;0) &#123; printf(&quot;first procee is exited.\\n&quot;); exit(0); &#125; //第二个子进程 //睡眠3s保证第一个子进程退出，这样第二个子进程的父亲就是init进程里 sleep(3); printf(&quot;I am the second child process.pid: %d\\tppid:%d\\n&quot;,getpid(),getppid()); exit(0); &#125; //父进程处理第一个子进程退出 if (waitpid(pid, NULL, 0) != pid) &#123; perror(&quot;waitepid error:&quot;); exit(1); &#125; exit(0); return 0;&#125; 测试结果如下图所示： 参考进程3.0——进程状态与僵尸进程、孤儿进程 孤儿进程与僵尸进程[总结]","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"僵尸进程","slug":"僵尸进程","permalink":"https://xmmarlowe.github.io/tags/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/"},{"name":"孤儿进程","slug":"孤儿进程","permalink":"https://xmmarlowe.github.io/tags/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/"}],"author":"Marlowe"},{"title":"Redis分布式锁","slug":"NoSQL/Redis分布式锁","date":"2021-05-06T08:55:54.000Z","updated":"2021-05-06T14:47:22.417Z","comments":true,"path":"2021/05/06/NoSQL/Redis分布式锁/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/06/NoSQL/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"问题描述随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！ 分布式锁主流的实现方案 基于数据库实现分布式锁 基于缓存（Redis等） 基于Zookeeper 每一种分布式锁解决方案都有各自的优缺点： 性能：redis最高 可靠性：zookeeper最高 使用redis实现分布式锁redis:命令1# set sku:1:info “OK” NX PX 10000 EX second：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。PX millisecond：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。NX：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。XX：只在键已经存在时，才对键进行设置操作。 多个客户端同时获取锁（setnx） 获取成功，执行业务逻辑{从db获取数据，放入缓存}，执行完成释放锁（del） 其他客户端等待重试 代码测试12345678910111213141516171819202122232425262728@GetMapping(&quot;testLock&quot;)public void testLock()&#123; //1获取锁，setne Boolean lock = redisTemplate.opsForValue().setIfAbsent(&quot;lock&quot;, &quot;111&quot;); //2获取锁成功、查询num的值 if(lock)&#123; Object value = redisTemplate.opsForValue().get(&quot;num&quot;); //2.1判断num为空return if(StringUtils.isEmpty(value))&#123; return; &#125; //2.2有值就转成成int int num = Integer.parseInt(value+&quot;&quot;); //2.3把redis的num加1 redisTemplate.opsForValue().set(&quot;num&quot;, ++num); //2.4释放锁，del redisTemplate.delete(&quot;lock&quot;); &#125;else&#123; //3获取锁失败、每隔0.1秒再获取 try &#123; Thread.sleep(100); testLock(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 重启，服务集群，通过网关压力测试：ab -n 1000 -c 100 http://192.168.140.1:8080/test/testLock 查看redis中num的值： 基本实现。问题：setnx刚好获取到锁，业务逻辑出现异常，导致锁无法释放解决：设置过期时间，自动释放锁。 优化之设置锁的过期时间设置过期时间有两种方式： 首先想到通过expire设置过期时间（缺乏原子性：如果在setnx和expire之间出现异常，锁也无法释放） 在set时指定过期时间（推荐） 设置过期时间： 问题： 可能会释放其他服务器的锁。 场景： 如果业务逻辑的执行时间是7s。执行流程如下 index1业务逻辑没执行完，3秒后锁被自动释放。 index2获取到锁，执行业务逻辑，3秒后锁被自动释放。 index3获取到锁，执行业务逻辑 index1业务逻辑执行完成，开始调用del释放锁，这时释放的是index3的锁，导致index3的业务只执行1s就被别人释放。最终等于没锁的情况。 解决： setnx获取锁时，设置一个指定的唯一值（例如：uuid）；释放前获取这个值，判断是否自己的锁 优化之UUID防误删 问题： 删除操作缺乏原子性。场景： index1执行删除时，查询到的lock值确实和uuid相等uuid=v1set(lock,uuid)； index1执行删除前，lock刚好过期时间已到，被redis自动释放在redis中没有了lock，没有了锁。 index2获取了lockindex2线程获取到了cpu的资源，开始执行方法uuid=v2set(lock,uuid)； index1执行删除，此时会把index2的lock删除index1 因为已经在方法中了，所以不需要重新上锁。index1有执行的权限。index1已经比较完成了，这个时候，开始执行 删除的index2的锁！ 优化之LUA脚本保证删除的原子性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@GetMapping(&quot;testLockLua&quot;)public void testLockLua() &#123; //1 声明一个uuid ,将做为一个value 放入我们的key所对应的值中 String uuid = UUID.randomUUID().toString(); //2 定义一个锁：lua 脚本可以使用同一把锁，来实现删除！ String skuId = &quot;25&quot;; // 访问skuId 为25号的商品 100008348542 String locKey = &quot;lock:&quot; + skuId; // 锁住的是每个商品的数据 // 3 获取锁 Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid, 3, TimeUnit.SECONDS); // 第一种： lock 与过期时间中间不写任何的代码。 // redisTemplate.expire(&quot;lock&quot;,10, TimeUnit.SECONDS);//设置过期时间 // 如果true if (lock) &#123; // 执行的业务逻辑开始 // 获取缓存中的num 数据 Object value = redisTemplate.opsForValue().get(&quot;num&quot;); // 如果是空直接返回 if (StringUtils.isEmpty(value)) &#123; return; &#125; // 不是空 如果说在这出现了异常！ 那么delete 就删除失败！ 也就是说锁永远存在！ int num = Integer.parseInt(value + &quot;&quot;); // 使num 每次+1 放入缓存 redisTemplate.opsForValue().set(&quot;num&quot;, String.valueOf(++num)); /*使用lua脚本来锁*/ // 定义lua 脚本 String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; // 使用redis执行lua执行 DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(); redisScript.setScriptText(script); // 设置一下返回值类型 为Long // 因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String 类型， // 那么返回字符串与0 会有发生错误。 redisScript.setResultType(Long.class); // 第一个要是script 脚本 ，第二个需要判断的key，第三个就是key所对应的值。 redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid); &#125; else &#123; // 其他线程等待 try &#123; // 睡眠 Thread.sleep(1000); // 睡醒了之后，调用方法。 testLockLua(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Lua 脚本详解： 项目中正确使用： 定义key，key应该是为每个sku定义的，也就是每个sku有一把锁。String locKey =”lock:”+skuId; // 锁住的是每个商品的数据Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid,3,TimeUnit.SECONDS); 总结1、加锁 1234// 1. 从redis中获取锁,set k1 v1 px 20000 nxString uuid = UUID.randomUUID().toString();Boolean lock = this.redisTemplate.opsForValue() .setIfAbsent(&quot;lock&quot;, uuid, 2, TimeUnit.SECONDS); 2、使用lua释放锁 12345678// 2. 释放锁 delString script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;;// 设置lua脚本返回的数据类型DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;();// 设置lua脚本返回类型为LongredisScript.setResultType(Long.class);redisScript.setScriptText(script);redisTemplate.execute(redisScript, Arrays.asList(&quot;lock&quot;),uuid); 3、重试 12Thread.sleep(500);testLock(); 为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 加锁和解锁必须具有原子性。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"URI和URL的区别是什么?","slug":"计算机网络/URI和URL的区别是什么","date":"2021-05-06T08:29:14.000Z","updated":"2021-05-06T14:47:22.421Z","comments":true,"path":"2021/05/06/计算机网络/URI和URL的区别是什么/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/URI%E5%92%8CURL%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/","excerpt":"","text":"URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。 URL(Uniform Resource Location) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"URL","slug":"URL","permalink":"https://xmmarlowe.github.io/tags/URL/"},{"name":"URI","slug":"URI","permalink":"https://xmmarlowe.github.io/tags/URI/"}],"author":"Marlowe"},{"title":"Java学习推荐书籍","slug":"随笔/Java学习推荐书籍","date":"2021-05-05T09:09:18.000Z","updated":"2021-05-05T14:55:09.555Z","comments":true,"path":"2021/05/05/随笔/Java学习推荐书籍/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/05/%E9%9A%8F%E7%AC%94/Java%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E4%B9%A6%E7%B1%8D/","excerpt":"列举一些接下来要读的书单…","text":"列举一些接下来要读的书单… 总《Java编程思想》《Java核心技术》卷1卷2《Go语言实战》 or《Go In Action》《算法导论》 不适合初学者《算法》第四版 红色《TCP/IP详解》《计算机网络 自顶向下》《私房菜》 工具书《Unix环境高级编程》《Spring实战》《Spring Boot实战》《Spring技术内幕》 很难《MySQL必知必会》 涵盖 《SQL必知必会》的内容《高性能MySQL》《重构 改善既有代码的设计》 需要一些经验，拔高内容 参考bilibili Video 必读计算机编程好书推荐！程序员小伙搬出了他的书架！","categories":[{"name":"随笔","slug":"随笔","permalink":"https://xmmarlowe.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"学习","slug":"学习","permalink":"https://xmmarlowe.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"书籍","slug":"书籍","permalink":"https://xmmarlowe.github.io/tags/%E4%B9%A6%E7%B1%8D/"}],"author":"Marlowe"},{"title":"海量数据下，如何快速查找一条记录？","slug":"NoSQL/海量数据下，如何快速查找一条记录？","date":"2021-05-04T14:27:41.000Z","updated":"2021-05-05T14:45:39.215Z","comments":true,"path":"2021/05/04/NoSQL/海量数据下，如何快速查找一条记录？/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/04/NoSQL/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%8B%EF%BC%8C%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E6%9F%A5%E6%89%BE%E4%B8%80%E6%9D%A1%E8%AE%B0%E5%BD%95%EF%BC%9F/","excerpt":"","text":"1、使用布隆过滤器，快速过滤不存在的记录。 使用Redis的bitmap结构来实现布隆过滤器。 2、在Redis中建立数据缓存。将我们对Redis使用场景的理解尽量表达出来。 以普通字符串的形式来存储，(userld -&gt; user.json)。 以一个hash来存储一条记录(userld key-&gt; username field-&gt; ，userAge-&gt;)。以一个整的hash来存储所有的数据，Userlnfo-&gt; field就用userld ，value就用user.jison。一个hash最多能支持2^32-1(40多个亿)个键值对。 缓存击穿: 对不存在的数据也建立key。这些key都是经过布隆过滤器过滤的，所以一般不会太多。 缓存过期: 将热点数据设置成永不过期，定期重建缓存。使用分布式锁重建缓存。 3、查询优化。 按槽位分配数据。 自己实现槽位计算，找到记录应该分配在哪台机器上，然后直接去目标机器上找。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis 如何配置Key的过期时间？他的实现原理是什么？","slug":"NoSQL/Redis-如何配置Key的过期时间？他的实现原理是什么？","date":"2021-05-04T13:11:54.000Z","updated":"2021-05-06T10:58:18.322Z","comments":true,"path":"2021/05/04/NoSQL/Redis-如何配置Key的过期时间？他的实现原理是什么？/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/04/NoSQL/Redis-%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEKey%E7%9A%84%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%EF%BC%9F%E4%BB%96%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"Redis设置key的过期时间 EXPIRE SETEX 实现原理定期删除每隔一段时间， 执行一次删除过期key的操作。 懒汉式删除当使用get、getset等指令 去获取数据时，判断key是否过期。 过期后，就先把key删除，再执行后面的操作。 Redis是将两种方式结合来使用。 定期删除：平衡执行频率和执行时长。 定期删除时会遍历每个datapase(默认16个),检查当前库中指定个数的key(默认是20个)。随机抽查这些key,如果有过期的，就删除。 程序中有一个全局变量记录到扫描到了哪个数据库。|","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"如何设计一个分布式锁？如何对锁的性能进行优化？","slug":"并发/如何设计一个分布式锁？如何对锁的性能进行优化？","date":"2021-05-04T12:49:09.000Z","updated":"2021-05-04T14:38:59.918Z","comments":true,"path":"2021/05/04/并发/如何设计一个分布式锁？如何对锁的性能进行优化？/","link":"","permalink":"https://xmmarlowe.github.io/2021/05/04/%E5%B9%B6%E5%8F%91/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F%E5%A6%82%E4%BD%95%E5%AF%B9%E9%94%81%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9B%E8%A1%8C%E4%BC%98%E5%8C%96%EF%BC%9F/","excerpt":"","text":"分布式锁的本质就是在所有进程都能访问到的一个地方，设置一一个锁资源， 让这些进程都来竞争锁资源。数据库、zookeeper, Redis。 通常对于分布式锁，会要求响应快、性能高、与业务无关。 Redis实现分布式锁 SETNX key value: 当key不存在时，就将key设置为value,并返回1。如果key存在，就返回0。 EXPIRE key locktime: 设置key的有效时长。 DEL key: 删除。 GETSET key value: 先GET, 再SET， 先返回key对应的值，如果没有就返回空。然后再将key设 置成value。 简单的分布式锁SETNX加锁， DEL解锁。 问题: 如果获取到锁的进程执行失败，他就永远不会主动解锁，那这个锁就被锁死了。 解决方法： 给锁设置过期时长。 问题： SETNX 和EXPIRE并不是原子性的，所以获取到锁的进程有可能还没有执行EXPIRE指令，就挂了，这时锁还是会被锁死。 解决方法： 将锁的内容设置为过期时间(客户端时间+过期时长),SETNX获取锁失败时，拿这个时间跟当前时间比对，如果是过期的锁，就先删除锁，再重新上锁。 问题： 在高并发场景下，会产生多个进程同时拿到锁的情况。 解决方法： SETNX失败后，获取锁上的时间戳，然后用GETSET, 将自己的过期时间更新上去，并获取旧值。如果这个旧值，跟之前获得的时间戳是不一致的，就表示这个锁已经被其他进程占用了，自己就要放弃竞争锁。 123456789101112131415161718192021public boolean tryLock(RedisConnection conn)&#123; long nowTime = System.currentTimeMills(); long expireTime = nowTime + 1000; if(conn.SETNX(&quot;mykey&quot;,expireTime) == 1)&#123; // 给锁设置过期时间 conn.EXPIRE(&quot;mykey&quot;,1000); return true; &#125;else&#123; // 类似CAS操作 long oldVal = conn.get(&quot;mykey&quot;); if(oldVal != null &amp;&amp; oldVal &lt; nowTime&gt;)&#123; long currentVal = conn.GETSET(&quot;mykey&quot;,expireTime); if(oldVal == currentVal)&#123; conn.EXPIRE(&quot;mykey&quot;,1000); return true; &#125; return false; &#125; return false; &#125;&#125; 分析一下： 上面各种优化的根本问题在于SETNX和EXPIRE两个指令 无法保证原子性。Redis2.6提供了 直接执行Lua脚本的方式，通过Lua脚本来保证原子性。redission。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://xmmarlowe.github.io/tags/%E9%94%81/"}],"author":"Marlowe"},{"title":"MySQL redo log、binlog、undo log 区别与作用","slug":"数据库/MySQL-redo-log、binlog、undo-log-区别与作用","date":"2021-04-29T14:06:33.000Z","updated":"2021-04-29T14:35:23.879Z","comments":true,"path":"2021/04/29/数据库/MySQL-redo-log、binlog、undo-log-区别与作用/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/29/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL-redo-log%E3%80%81binlog%E3%80%81undo-log-%E5%8C%BA%E5%88%AB%E4%B8%8E%E4%BD%9C%E7%94%A8/","excerpt":"日志系统主要有redo log(重做日志)和binlog(归档日志)。redo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）。","text":"日志系统主要有redo log(重做日志)和binlog(归档日志)。redo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）。 MySQL逻辑架构 重做日志（redo log）作用确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。 内容物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。 什么时候产生事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。 什么时候释放当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。 对应的物理文件默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&amp;ib_logfile2 innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。 innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2 关于文件的大小和数量，由以下两个参数配置innodb_log_file_size 重做日志文件的大小。 innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1 其他很重要一点，redo log是什么时候写盘的？前面说了是在事物开始之后逐步写盘的。 之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。 然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘 Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。每个事务提交时会将重做日志刷新到重做日志文件。当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件 由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。 因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。 另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话： 即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。 这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。 回滚日志（undo log）作用保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读 内容逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。 什么时候产生事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性 什么时候释放当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。 对应的物理文件MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。 MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。 关于MySQL5.7之后的独立undo 表空间配置参数如下 innodb_undo_directory = /data/undospace/ –undo独立表空间的存放目录 innodb_undo_logs = 128 –回滚段为128KB innodb_undo_tablespaces = 4 –指定有4个undo log文件 如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。 其他undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。 默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。 因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。 因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。 二进制日志（binlog）作用用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。用于数据库的基于时间点的还原。 内容逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。 但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。 在使用mysqlbinlog解析binlog之后一些都会真相大白。 因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。 什么时候产生事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。 这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。 因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。 这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。 什么时候释放binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。 对应的物理文件配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。 对于每个binlog日志文件，通过一个统一的index文件来组织。 其他二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同 作用不同：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog 关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。 redo log日志模块redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。在实例和介质失败（media failure）时，redo log文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。 在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术，他的关键点是先写日志，再写磁盘。 有了redo log日志，那么在数据库进行异常重启的时候，可以根据redo log日志进行恢复，也就达到了crash-safe。 redo log日志的大小是固定的，即记录满了以后就从头循环写。 该图展示了一组4个文件的redo log日志，checkpoint之前表示擦除完了的，即可以进行写的，擦除之前会更新到磁盘中，write pos是指写的位置，当write pos和checkpoint相遇的时候表明redo log已经满了，这个时候数据库停止进行数据库更新语句的执行，转而进行redo log日志同步到磁盘中。 binlog日志模块binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑，依靠binlog是没有crash-safe能力的 redo log和binlog区别 redo log是属于innoDB层面，binlog属于MySQL Server层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。 redo log是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑 redo log是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。 binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。 参考MySQL中的六种日志文件 MySQL日志系统：redo log、binlog、undo log 区别与作用","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redo log","slug":"redo-log","permalink":"https://xmmarlowe.github.io/tags/redo-log/"},{"name":"binlog","slug":"binlog","permalink":"https://xmmarlowe.github.io/tags/binlog/"},{"name":"undo log","slug":"undo-log","permalink":"https://xmmarlowe.github.io/tags/undo-log/"}],"author":"Marlowe"},{"title":"SQL执行过慢，如何排查以及调优","slug":"数据库/SQL执行过慢，如何排查以及调优","date":"2021-04-29T13:37:24.000Z","updated":"2021-04-29T14:35:23.883Z","comments":true,"path":"2021/04/29/数据库/SQL执行过慢，如何排查以及调优/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/29/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL%E6%89%A7%E8%A1%8C%E8%BF%87%E6%85%A2%EF%BC%8C%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E4%BB%A5%E5%8F%8A%E8%B0%83%E4%BC%98/","excerpt":"","text":"导致SQL执行慢的原因 硬件问题。如网络速度慢，内存不足，I/O吞吐量小，磁盘空间满了等。 没有索引或者索引失效。（一般在互联网公司，DBA会在半夜把表锁了，重新建立一遍索引，因为当你删除某个数据的时候，索引的树结构就不完整了。所以互联网公司的数据做的是假删除，一是为了做数据分析,二是为了不破坏索引 ） 数据过多（分库分表） 服务器调优及各个参数设置（调整my.cnf） 查询出的数据量过大（可以采用多次查询，其他的方法降低数据量） 锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷) sp_lock,sp_who,活动的用户查看,原因是读写竞争资源。 返回了不必要的行和列 分析原因时，一定要找切入点 先观察，开启慢查询日志，设置相应的阈值（比如超过3秒就是慢SQL），在生产环境跑上个一天过后，看看哪些SQL比较慢。 Explain和慢SQL分析。比如SQL语句写的烂，索引没有或失效，关联查询太多（有时候是设计缺陷或者不得以的需求）等等。 Show Profile是比Explain更近一步的执行细节，可以查询到执行每一个SQL都干了什么事，这些事分别花了多少秒。 找DBA或者运维对MySQL进行服务器的参数调优。 解析： (1)、explain出来的各种item的意义 id: 每个被独立执行的操作的标志，表示对象被操作的顺序。一般来说， id 值大，先被执行；如果 id 值相同，则顺序从上到下。select_type： 查询中每个 select 子句的类型。table: 名字，被操作的对象名称，通常的表名(或者别名)，但是也有其他格式。partitions: 匹配的分区信息。type: join 类型。possible_keys： 列出可能会用到的索引。key: 实际用到的索引。key_len: 用到的索引键的平均长度，单位为字节。ref: 表示本行被操作的对象的参照对象，可能是一个常量用 const 表示，也可能是其他表的key 指向的对象，比如说驱动表的连接列。rows: 估计每次需要扫描的行数。filtered: rows*filtered/100 表示该步骤最后得到的行数(估计值)。extra: 重要的补充信息。 (2)、profile的意义以及使用场景 Profile 用来分析 sql 性能的消耗分布情况。当用 explain 无法解决慢 SQL 的时候，需要用profile 来对 sql 进行更细致的分析，找出 sql 所花的时间大部分消耗在哪个部分，确认 sql的性能瓶颈。 (3)、explain 中的索引问题 Explain 结果中，一般来说，要看到尽量用 index(type 为 const、 ref 等， key 列有值)，避免使用全表扫描(type 显式为 ALL)。比如说有 where 条件且选择性不错的列，需要建立索引。被驱动表的连接列，也需要建立索引。被驱动表的连接列也可能会跟 where 条件列一起建立联合索引。当有排序或者 group by 的需求时，也可以考虑建立索引来达到直接排序和汇总的需求。 如何优化 查看sql是否涉及多表的联表或者子查询，如果有，看是否能进行业务拆分，相关字段冗余或者合并成临时表（业务和算法的优化） 涉及链表的查询，是否能进行分表查询，单表查询之后的结果进行字段整合 如果以上两种都不能操作，非要链表查询，那么考虑对相对应的查询条件做索引。加快查询速度 针对数量大的表进行历史表分离（如交易流水表） 数据库主从分离，读写分离，降低读写针对同一表同时的压力，至于主从同步，mysql有自带的binlog实现 主从同步 explain分析sql语句，查看执行计划，分析索引是否用上，分析扫描行数等等 查看mysql执行日志，看看是否有其他方面的问题 总结从根本上来说，查询慢是占用sql内存比较多，那么可以从这方面去酌手考虑。 参考sql执行慢的原因有哪些，如何进行sql优化？ SQL优化 | sql执行过长的时间，如何优化?","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://xmmarlowe.github.io/tags/SQL/"},{"name":"调优","slug":"调优","permalink":"https://xmmarlowe.github.io/tags/%E8%B0%83%E4%BC%98/"}],"author":"Marlowe"},{"title":"初识HTTP2.0","slug":"计算机网络/初识HTTP2-0","date":"2021-04-29T13:02:52.000Z","updated":"2021-04-29T14:35:23.886Z","comments":true,"path":"2021/04/29/计算机网络/初识HTTP2-0/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%88%9D%E8%AF%86HTTP2-0/","excerpt":"HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议。由互联网工程任务组(IETF) 的Hypertext Transfer Protocol Bis (httpbis) 工作小组进行开发。该组织于2014年12月将HTTP/2标准提议递交至IESG进行讨论，于2015年2月17日被批准。HTTP/2标准于2015年5月以RFC 7540正式发表。","text":"HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议。由互联网工程任务组(IETF) 的Hypertext Transfer Protocol Bis (httpbis) 工作小组进行开发。该组织于2014年12月将HTTP/2标准提议递交至IESG进行讨论，于2015年2月17日被批准。HTTP/2标准于2015年5月以RFC 7540正式发表。 简介HTTP/2（超文本传输协议第2版，最初命名为HTTP 2.0），是HTTP协议的的第二个主要版本，使用于万维网。HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议（是Google开发的基于TCP的应用层协议，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验）。 相对于HTTP/1.1的改进二进制分帧HTTP/2（超文本传输协议第2版，最初命名为HTTP 2.0），是HTTP协议的的第二个主要版本，使用于万维网。HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议（是Google开发的基于TCP的应用层协议，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验）。 在二进制分帧层中，HTTP/2 会将所有传输的信息分割为更小的消息和帧(frame)，并对它们采用二进制格式的编码。这种单连接多资源的方式，减少了服务端的压力，使得内存占用更少，连接吞吐量更大。而且,TCP连接数的减少使得网络拥塞状况得以改善，同时慢启动时间的减少，使拥塞和丢包恢复速度更快。 多路复用多路复用允许同时通过单一的HTTP/2.0连接发起多重 的请求-响应消息。在HTTP1.1协议中,浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制， 超过了这个限制的请求就会被阻塞。而多路复用允许同时通过单一的HTTP2.0连接发起多重的“请求-响应”消息。 HTTP2的请求的TCP的connection一旦建立，后续请求以stream的方式发送。每个stream的基本组成单位是frame (二进制帧)。客户端和服务器可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来。 也就是说，HTTP2.0 通信都在一个连接 上完成，这个连接可以承载任意数量的双向数据流。就好比，我请求一个页面baidu.com。页面上所有的资源请求都是客户端与服务器上的一条TCP上请求和响应的! header压缩HTTP/1.1的header带有大量信息，而且每次都要重复发送。HTTP/2 为了减少这部分开销，采用了HPACK头部压缩算法对Header进行压缩。 服务端推送简单来讲就是当用户的浏览器和服务器在建立连接后，服务器主动将一些资源推送给浏览器并缓存起来的机制。有了缓存，当浏览器想要访问已缓存的资源的时候就可以直接从缓存中读取了。 一些问题HTTP/2为什么是二进制？比起像HTTP/1.x这样的文本协议，二进制协议解析起来更高效、“线上”更紧凑，更重要的是错误更少。 为什么 HTTP/2 需要多路传输?HTTP/1.x 有个问题叫线端阻塞(head-of-line blocking), 它是指一个连接(connection)一次只提交一个请求的效率比较高, 多了就会变慢。 HTTP/1.1 试过用流水线(pipelining)来解决这个问题, 但是效果并不理想(数据量较大或者速度较慢的响应, 会阻碍排在他后面的请求). 此外, 由于网络媒介(intermediary )和服务器不能很好的支持流水线, 导致部署起来困难重重。而多路传输(Multiplexing)能很好的解决这些问题, 因为它能同时处理多个消息的请求和响应; 甚至可以在传输过程中将一个消息跟另外一个掺杂在一起。所以客户端只需要一个连接就能加载一个页面。 消息头为什么需要压缩?假定一个页面有80个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1400字节的消息头（着同样也并不少见，因为Cookie和引用等东西的存在）, 至少要7到8个来回去“在线”获得这些消息头。这还不包括响应时间——那只是从客户端那里获取到它们所花的时间而已。这全都由于TCP的慢启动机制，它会基于对已知有多少个包，来确定还要来回去获取哪些包 – 这很明显的限制了最初的几个来回可以发送的数据包的数量。相比之下，即使是头部轻微的压缩也可以是让那些请求只需一个来回就能搞定——有时候甚至一个包就可以了。这种开销是可以被节省下来的，特别是当你考虑移动客户端应用的时候，即使是良好条件下，一般也会看到几百毫秒的来回延迟。 服务器推送的好处是什么？当浏览器请求一个网页时，服务器将会发回HTML，在服务器开始发送JavaScript、图片和CSS前，服务器需要等待浏览器解析HTML和发送所有内嵌资源的请求。服务器推送服务通过“推送”那些它认为客户端将会需要的内容到客户端的缓存中，以此来避免往返的延迟。 参考HTTP 2.0 和 HTTP 1.1 相比有哪些优势呢？ HTTP 2.0与HTTP 1.1区别","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://xmmarlowe.github.io/tags/HTTP/"}],"author":"Marlowe"},{"title":"as-if-serial规则和happens-before规则","slug":"并发/as-if-serial规则和happens-before规则","date":"2021-04-28T12:41:41.000Z","updated":"2021-04-28T13:53:59.283Z","comments":true,"path":"2021/04/28/并发/as-if-serial规则和happens-before规则/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/28/%E5%B9%B6%E5%8F%91/as-if-serial%E8%A7%84%E5%88%99%E5%92%8Chappens-before%E8%A7%84%E5%88%99/","excerpt":"我们知道为了提高并行度，优化程序性能，编译器和处理器会对代码进行指令重排序。但为了不改变程序的执行结果，尽可能地提高程序执行的并行度，我们需要了解as-if-serial规则和happens-before规则。","text":"我们知道为了提高并行度，优化程序性能，编译器和处理器会对代码进行指令重排序。但为了不改变程序的执行结果，尽可能地提高程序执行的并行度，我们需要了解as-if-serial规则和happens-before规则。 as-if-serial规则as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。 编译器、runtime和处理器都必须遵守as-if-serial语义。为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。 但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。示例代码如下： 123int a=1;int b=2;int c=a+b; a和c之间存在数据依赖关系，同时b和c之间也存在数据依赖关系。因此在最终执行的指令序列中，c不能被重排序到A和B的前面（c排到a和b的前面，程序的结果将会被改变）。但a和b之间没有数据依赖关系，编译器和处理器可以重排序a和b之间的执行顺序。 happens-before（先行发生）规则定义JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见）。具体的定义为： 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM允许这种重排序。 八大规则|规则| 解释||:—-:|:—-:|:—-:||程序次序规则| 在一个线程内，代码按照书写的控制流顺序执行||管程锁定规则| 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作||volatile 变量规则| volatile 变量的写操作先行发生于后面对这个变量的读操作||线程启动规则| Thread 对象的 start() 方法先行发生于此线程的每一个动作||线程终止规则| 线程中所有的操作都先行发生于对此线程的终止检测(通过 Thread.join() 方法结束、 Thread.isAlive() 的返回值检测)||线程中断规则| 对线程 interrupt() 方法调用优先发生于被中断线程的代码检测到中断事件的发生 (通过 Thread.interrupted() 方法检测)||对象终结规则| 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始||传递性| 如果操作 A 先于 操作 B 发生，操作 B 先于 操作 C 发生，那么操作 A 先于 操作 C| as-if-serial规则和happens-before规则的区别 as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 as-if-serial语义给编写单线程程序的程序员创造了一个幻觉：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻觉：正确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。 参考Java并发理论（二）：as-if-serial规则和happens-before规则详解","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"as-if-serial","slug":"as-if-serial","permalink":"https://xmmarlowe.github.io/tags/as-if-serial/"},{"name":"happens-before","slug":"happens-before","permalink":"https://xmmarlowe.github.io/tags/happens-before/"}],"author":"Marlowe"},{"title":"对象在内存中的内存布局","slug":"Java/对象在内存中的内存布局","date":"2021-04-28T07:27:19.000Z","updated":"2021-04-28T13:53:59.240Z","comments":true,"path":"2021/04/28/Java/对象在内存中的内存布局/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/28/Java/%E5%AF%B9%E8%B1%A1%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/","excerpt":"","text":"对象的内存布局HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 从上面的这张图里面可以看出，对象在内存中的结构主要包含以下几个部分： Mark Word(标记字段)：对象的Mark Word部分占4个字节，其内容是一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。 Klass Pointer（Class对象指针）：Class对象指针的大小也是4个字节，其指向的位置是对象对应的Class对象（其对应的元数据对象）的内存地址 对象实际数据：这里面包括了对象的所有成员变量，其大小由各个成员变量的大小决定，比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节 对齐：最后一部分是对齐填充的字节，按8个字节填充。 对象头Mark Word（标记字段）HotSpot虚拟机的对象头包括两部分信息，第一部分是“Mark Word”，用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等，这部分数据的长度在32位和64位的虚拟机（暂 不考虑开启压缩指针的场景）中分别为32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额 外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志 位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示。 但是如果对象是数组类型，则需要三个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数组的大小，所以用一块来记录数组长度。 对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化，变化状态如下（32位虚拟机）： HotSpot虚拟机对象头Mark Word： 存储内容 标志位 状态 对象哈希码、对象分代年龄 01 未锁定 指向锁记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀（重量级锁定） 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 注意偏向锁、轻量级锁、重量级锁等都是jdk 1.6以后引入的。 其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示: 由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因(关于这点稍后还会进行分析)，ok~，有了上述知识基础后，下面我们将进一步分析synchronized在字节码层面的具体语义实现。 对象头的另外一部分是类型指针，即是对象指向它的类的元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说查找对象的元数据信息并不一定要经过对象本身。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中无法确定数组的大小。以下是HotSpot虚拟机markOop.cpp中的C++代码（注释）片段，它描述了32bits下MarkWord的存储状态： 12345678// Bit-format of an object header (most significant first, big endian layout below): // // 32 bits: // -------- // hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object) // JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object) // size:32 ------------------------------------------&gt;| (CMS free block) // PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object) 实例数据（Instance Data）接下来实例数据部分是对象真正存储的有效信息，也既是我们在程序代码里面所定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类中定义的都需要记录下来。 这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中定义顺序的影响。HotSpot虚拟机 默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers），从分配策略中可以看出，相同宽度的字段总是被分配到一起。在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果 CompactFields参数值为true（默认为true），那子类之中较窄的变量也可能会插入到父类变量的空隙之中。 对齐填充（Padding）第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。对象头正好是8字节的倍数（1倍或者2倍），因此当对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。 对象的创建过程见本站Java对象创建的过程 对象的访问定位Java是通过虚拟机栈中的局部变量表中的reference数据来操作Java堆上的具体对象。但reference只是虚拟机规范中规定指向一个对象的引用，它并没有定义这个引用通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方法也取决于虚拟机的实现而定的。目前主流的访问方式有使用句柄和直接指针两种。 句柄访问 如果使用句柄访问，Java堆中将会划分出一块儿内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和对象类型数据的具体地址信息。实际上是采用了句柄池这样一个中间介质进行了两次指针定位，有效的避免了对象的移动或改变直接导致reference本身发生改变。句柄访问方式如下图所示： 使用句柄访问最大的好处就是reference中存储的是稳定的句柄地址，在对象回收过程中或者其它对象需要移动的时，只会改变句柄中的实例数据的指针，而reference本身不需要做任何修改。 直接指针访问如果使用直接指针访问，那么Java堆对象的布局必须考虑如何放置访问类型的数据的相关信息，而reference中存储的直接就是对象地址，而不再是句柄地址信息，相当于在reference与对象地址信息直接少了句柄池这样一个中间地址，reference中直接存储的就是对象地址。 这种定位方式也就导致了在对象被移动时，reference本身必须发生改变。但是我们都知道，使用句柄访问方式时，相当于进行了两次指针定位，而直接指针访问方式恰好节省了这一次指针定位的时间开销，由于对象的访问在Java中非常的频繁，时间开销的减少也是一种可观的执行成本。例如，常见的HotSpot虚拟机就使用的是直接指针访问方式。 示例在Hotspot JVM中，32位机器下，Integer对象的大小是int的几倍？我们都知道在Java语言规范已经规定了int的大小是4个字节，那么Integer对象的大小是多少呢？要知道一个对象的大小，那么必须需要知道对象在虚拟机中的结构是怎样的，根据上面的图，那么我们可以得出Integer的对象的结构如下： Integer只有一个int类型的成员变量value，所以其对象实际数据部分的大小是4个字节，然后再在后面填充4个字节达到8字节的对齐，所以可以得出Integer对象的大小是16个字节。 因此，我们可以得出Integer对象的大小是原生的int类型的4倍。 关于对象的内存结构，需要注意数组的内存结构和普通对象的内存结构稍微不同，因为数据有一个长度length字段，所以在对象头后面还多了一个int类型的length字段，占4个字节，接下来才是数组中的数据，如下图： Object o = new Object()在内存中占了多少字节?想要知道 Object o = new Object();在内存中占用了多少字节，可以使用如下方法直观的看到。 maven中添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 写一个测试类123456public class ObjectLayOutTest &#123; public static void main(String[] args) &#123; Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 结果 可以直观的看到 new Object()在内存中占用16个字节。为什么是16个字节呢，就需要了解对象在内存中的存储布局。 MarkWord：对象头，8字节。包括了对象的hashCode、对象的分代年龄、锁标志位等。结构如下图所示： classPointer：对象指向它的类元素的指针。在不开启对象指针压缩的情况下是8字节。压缩后变为4字节，默认压缩。 1通过命令：java -XX:+PrintCommandLineFlags -version 查看classPointer是否开启压缩 padding ：用于对象在内存中占用的字节数不能被8整除的情况下，进行补充。 因此，Object o = new Object()在内存中占的字节数计算如下： markword 8字节，因为java默认使用了calssPointer压缩，classpointer 4字节，padding 4字节 因此是16字节。如果没开启classpointer默认压缩，markword 8字节，classpointer 8字节，padding 0字节 也是16字节。 参考java对象在内存中的结构（HotSpot虚拟机）对象的访问定位","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"内存布局","slug":"内存布局","permalink":"https://xmmarlowe.github.io/tags/%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"}],"author":"Marlowe"},{"title":"为什么AQS底层是CAS + volatile","slug":"为什么AQS底层是CAS-volatile","date":"2021-04-28T07:13:44.000Z","updated":"2021-04-28T13:53:59.235Z","comments":true,"path":"2021/04/28/为什么AQS底层是CAS-volatile/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/28/%E4%B8%BA%E4%BB%80%E4%B9%88AQS%E5%BA%95%E5%B1%82%E6%98%AFCAS-volatile/","excerpt":"","text":"","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"https://xmmarlowe.github.io/tags/volatile/"},{"name":"AQS","slug":"AQS","permalink":"https://xmmarlowe.github.io/tags/AQS/"},{"name":"CAS","slug":"CAS","permalink":"https://xmmarlowe.github.io/tags/CAS/"}],"author":"Marlowe"},{"title":"Synchronized与ReentrantLock","slug":"并发/Synchronized与ReentrantLock","date":"2021-04-28T06:19:05.000Z","updated":"2021-04-28T13:53:59.280Z","comments":true,"path":"2021/04/28/并发/Synchronized与ReentrantLock/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/28/%E5%B9%B6%E5%8F%91/Synchronized%E4%B8%8EReentrantLock/","excerpt":"Java 里面，最基本的互斥同步手段就是 synchronized 关键字，这是一种块结构( Block Structured ）的同步语法。还有就是 Java 类库中新提供了 java. util.concurrent 包，其中的 java.util.concurrent.locks.Lock 接口便成了 Java 另一 全新的互斥 同步手段。","text":"Java 里面，最基本的互斥同步手段就是 synchronized 关键字，这是一种块结构( Block Structured ）的同步语法。还有就是 Java 类库中新提供了 java. util.concurrent 包，其中的 java.util.concurrent.locks.Lock 接口便成了 Java 另一 全新的互斥 同步手段。 Synchronized 被 synchronized 修饰的同步块对同一条线程来说是可重人的 这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。 被synchronized 修饰的同步块在持有锁的线程执行完毕并释放锁之前，会元条件地阻塞后面其他线程的进入 意味着无法像处理某些数据库中 的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。 三种使⽤⽅式 修饰实例⽅法: 作⽤于当前对象实例加锁，进⼊同步代码前要获得当前对象实例的锁 修饰静态⽅法: 也就是给当前类加锁，会作⽤于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员（ static 表明这是该类的⼀个静态资源，不管new了多少个对象，只有⼀份）。所以如果⼀个线程A调⽤⼀个实例对象的⾮静态 synchronized ⽅法，⽽线程B需要调⽤这个实例对象所属类的静态 synchronized ⽅法，是允许的，不会发⽣互斥现象，因为访问静态synchronized ⽅法占⽤的锁是当前类的锁，⽽访问⾮静态 synchronized ⽅法占⽤的锁是当前实例对象锁。 修饰代码块： 指定加锁对象，对给定对象加锁，进⼊同步代码库前要获得给定对象的锁。 总结： synchronized 关键字加到 static 静态⽅法和 synchronized(class)代码块上都是是给 Class类上锁。synchronized 关键字加到实例⽅法上是给对象实例上锁。尽量不要使⽤synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 底层实现作用于对象的时候 当synchronized作用于对象时候（即代码块方式），JVM会使用字节码monitorenter，monitorexit来进行同步代码块区分: 123456 4: monitorenter 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: sipush 66611: invokevirtual #4 // Method java/io/PrintStream.println:(I)V14: aload_115: monitorexit 在执行 monitorenter 指令时，首先要去尝试获取对象的锁 如果这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行 monitorexit 指令时会将锁计数器的值减一 一旦计数器的值为零，锁随即就被释放了 如果获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止。 锁的优化Java HotSpot 虚拟机中，每个对象都有对象头（包括 class 指针和 Mark Word）。Mark Word 平时存储这个对象的 哈希码 、 分代年龄 ，当加锁时，这些信息就根据情况被替换为 标记位 、 线程锁记录指 针 、 重量级锁指针 、 线程ID 等内容。 高效并发是从 JDK 升级到 JDK 后一项重要的改进项， Hotspot 虚拟机开发团队在这个版本上花费了大 的资源去实现各种锁优化技术，如适应性自旋（ Adaptive Spinning锁消除（ Lock Elimination ）、锁膨胀（ Lock Coarsening 、轻量级锁（ Lightweight Locking）、偏向锁（ Biased Locking ）等，这些技术都是为了在线程之间更高效地共享数据及解决竞争问题，从而提高程序的执行效率。 对象头 Mark Word 锁之间的转换 偏向锁轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量，而偏向锁在无竞争的情况下会把整个同步都会消除掉。 偏向锁中的“偏”，就是偏心的“偏”、偏袒的“偏” 它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。 一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“ 0”），撤销后标志位恢复到未锁定（标志位为“01 ”）或轻量级锁定（标志位为“00 ”）的状态 注意： 撤销偏向锁这个过程中所有线程需要暂停（STW） 访问对象的 hashCode 时候，如果对象处于偏向锁，也会撤销偏向锁，并且转换为重量级锁 如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2，重偏向会重置对象的 Thread ID 撤销偏向和重偏向都是批量进行的，以类为单位 如果撤销偏向到达某个阈值，整个类的所有对象都会变为不可偏向的 可以主动使用 -XX:-UseBiasedLocking 禁用偏向锁 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。 加锁：在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01 ”状态），那么虚拟机就会在当前线程栈帧中创建一个名字为Lock Record的空间，用于存储当前对象的MarK Word的拷贝（方便后期比较），虚拟机将会使用CAS把对象的Mark Word更新为指向Lock Recod的指针。 转化之前的对象头 转换之后的对象头 如果这个更新操作成功了，则代表这个对象获得了这个对象的锁，锁状态变成轻量级锁的“00”。如果失败了，则代表有多个线程正在竞争这个对象的锁，这个时候虚拟机再检查对象的Mark Word的指针是不是指向了当前线程存的Lock Record，如果是则直接进入同步代码块（锁重入）。如果不是则代表锁已经被其他线程占用了。当线程数量两个及以上时候，则可能进行锁膨胀。 解锁将Lock Recod存的Mark Word替换回去，同样是使用CAS操作，假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。 轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则 如果没有竞争，轻量级锁便通过 CAS 操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销 ，还额外发生了CAS作的开销 因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。 锁膨胀如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有竞争），如果出现两条及以上的线程争用同一个锁的情况，后来的那条会自旋（循环等待）一定次数来等待锁，如果还是获取不到锁，这时需要进行锁膨胀，将轻量级锁变为重量级锁。 重量级锁重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 synchronized的其他优化 减少上锁时间： 同步代码块中尽量短 减少锁的粒度： 将一个锁拆分为多个锁提高并发度 锁粗化： 多次循环进入同步块不如同步块内多次循环 另外 JVM 可能会做如下优化，把多次 append 的加锁操作粗化为一次（因为都是对同一个对象加锁，没必要重入多次） 锁消除： JVM 会进行代码的逃逸分析，例如某个加锁对象是方法内局部变量，不会被其它线程所访问到，这时候就会被即时编译器忽略掉所有同步操作。 读写分离： CopyOnWriteArrayList、ConyOnWriteSet等 ReentrantLock重人锁（ ReentrantLock ）是 Lock 接口最常见的一种实现，顾名思义，它与 synchronized样是可重人的 在基本用法上， ReentrantLock 也与 synchronized 很相似，只是代码写法上稍有区别而已 不过， ReentrantLock synchronized 相比增加了一些高级功能，主要有以下 等待可中断、可实现公平锁及锁可以绑定多个条件 等待可中断： 是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情 可中断特性对处理执行时间非常长的同步块很有帮助 公平锁： 是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何－个等待锁的线程都有机会获得锁 synchronized 中的锁是非公平的， ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁 不过一旦使用了公平锁，将会导致 ReentrantLock 的性能急剧下降，会明显 吞吐量 锁绑定多个条件： 是指一个 ReentrantLock 象可以同时绑定多个 Condition 对象synchronized 中，锁对象的 wait() 跟的 notify()或者 notifyAll ()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而 ReentrantLock 则无须这样做，多次调用 newCondition（）方法即可 Synchronized 和 ReentrantLock 的对比① 两者都是可重入锁 两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 ② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 ③ ReenTrantLock 比 synchronized 增加了一些高级功能 相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件） ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair) 构造方法来制定是否是公平的。 synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ， 这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 如果你想使用上述功能，那么选择ReenTrantLock是一个不错的选择。 ④ 性能已不是选择标准 在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量随线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。 图解 参考Synchronized与ReentrantLock","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Synchronized","slug":"Synchronized","permalink":"https://xmmarlowe.github.io/tags/Synchronized/"},{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"https://xmmarlowe.github.io/tags/ReentrantLock/"}],"author":"Marlowe"},{"title":"两个线程交替打印数字和字母","slug":"并发/两个线程交替打印数字和字母","date":"2021-04-28T05:58:53.000Z","updated":"2021-04-28T13:53:59.322Z","comments":true,"path":"2021/04/28/并发/两个线程交替打印数字和字母/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/28/%E5%B9%B6%E5%8F%91/%E4%B8%A4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E6%95%B0%E5%AD%97%E5%92%8C%E5%AD%97%E6%AF%8D/","excerpt":"使用LockSupport的 park() 和 unpark() 方法 使用wait()和notify()方法","text":"使用LockSupport的 park() 和 unpark() 方法 使用wait()和notify()方法 使用LockSupport的 park() 和 unpark() 方法代码如下： 123456789101112131415161718192021222324252627282930313233public class LockSupportTest &#123; static Thread t1 = null; static Thread t2 = null; public static void main(String[] args) &#123; char[] a1 = &quot;1234567&quot;.toCharArray(); char[] a2 = &quot;ABCDEFG&quot;.toCharArray(); t1 = new Thread(() -&gt; &#123; for (char c : a1) &#123; System.out.println(c); // 叫醒t2 LockSupport.unpark(t2); // t1阻塞，当前线程阻塞 LockSupport.park(); &#125; &#125;); t2 = new Thread(() -&gt; &#123; for (char c : a2) &#123; // t2阻塞 LockSupport.park(); System.out.println(c); // 叫醒t1 LockSupport.unpark(t1); &#125; &#125;); t1.start(); t2.start(); &#125;&#125; 使用wait()和notify()方法代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class WaitNotifyTest &#123; public static void main(String[] args) &#123; final Object o = new Object(); char[] a1 = &quot;1234567&quot;.toCharArray(); char[] a2 = &quot;ABCDEFG&quot;.toCharArray(); new Thread(() -&gt; &#123; synchronized (o) &#123; for (char c : a1) &#123; System.out.println(c); try &#123; o.notify(); // 让出锁 o.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 必须唤醒，不然程序无法终止 o.notify(); &#125; &#125;, &quot;t1&quot;).start(); new Thread(() -&gt; &#123; synchronized (o) &#123; for (char c : a2) &#123; System.out.println(c); try &#123; o.notify(); // 让出锁 o.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 必须唤醒，不然程序无法终止 o.notify(); &#125; &#125;, &quot;t2&quot;).start(); &#125;&#125; 结果： 123456789101112131415161A2B3C4D5E6F7GProcess finished with exit code 0","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"Java如何开启线程?怎么保证线程安全?","slug":"并发/Java如何开启线程-怎么保证线程安全","date":"2021-04-26T13:57:17.000Z","updated":"2021-04-26T15:01:56.380Z","comments":true,"path":"2021/04/26/并发/Java如何开启线程-怎么保证线程安全/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/26/%E5%B9%B6%E5%8F%91/Java%E5%A6%82%E4%BD%95%E5%BC%80%E5%90%AF%E7%BA%BF%E7%A8%8B-%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","excerpt":"","text":"线程和进程的区别进程是操作系统进行资源分配的最小单元。线程是操作系统进行任务调度分配的最小单元，线程隶属于进程。 如何开启线程？ 继承Thread类,重写run方法。 实现Runnable接口， 实现run方法。 实现Callable接口， 实现call方法。通过FutureTask创建一个线程，获取到线程执行的返回值。 通过线程池来开启线程。 怎么保证线程安全？加锁 JVM提供的锁，也就是Synchronized关键字。 JDK提供的各种锁。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"线程安全","slug":"线程安全","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"}],"author":"Marlowe"},{"title":"聊聊对关系型数据库和非关系型数据库的理解","slug":"数据库/聊聊对关系型数据库和非关系型数据库的理解","date":"2021-04-25T03:28:55.000Z","updated":"2021-04-25T14:18:30.493Z","comments":true,"path":"2021/04/25/数据库/聊聊对关系型数据库和非关系型数据库的理解/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/25/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%81%8A%E8%81%8A%E5%AF%B9%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"","text":"关系型数据库关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织 优点 易于维护：都是使用表结构，格式一致； 使用方便：SQL语言通用，可用于复杂查询； 复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。 缺点 读写性能比较差，尤其是海量数据的高效率读写； 固定的表结构，灵活度稍欠； 高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 非关系型数据库非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。 优点 格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。 速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘； 高扩展性； 成本低：nosql数据库部署简单，基本都是开源软件。 缺点 不提供sql支持，学习和使用成本较高； 无事务处理； 数据结构相对复杂，复杂查询方面稍欠。 区别1. 数据存储方式不同关系型和非关系型数据库的主要差异是数据存储的方式。关系型数据天然就是表格式的，因此存储在数据表的行和列中。数据表可以彼此关联协作存储，也很容易提取数据。 与其相反，非关系型数据不适合存储在数据表的行和列中，而是大块组合在一起。非关系型数据通常存储在数据集中，就像文档、键值对或者图结构。你的数据及其特性是选择数据存储和提取方式的首要影响因素。 2. 扩展方式不同SQL和NoSQL数据库最大的差别可能是在扩展方式上，要支持日益增长的需求当然要扩展。 要支持更多并发量，SQL数据库是纵向扩展，也就是说提高处理能力，使用速度更快速的计算机，这样处理相同的数据集就更快了。 因为数据存储在关系表中，操作的性能瓶颈可能涉及很多个表，这都需要通过提高计算机性能来客服。虽然SQL数据库有很大扩展空间，但最终肯定会达到纵向扩展的上限。而NoSQL数据库是横向扩展的。 而非关系型数据存储天然就是分布式的，NoSQL数据库的扩展可以通过给资源池添加更多普通的数据库服务器(节点)来分担负载。 3. 对事务性的支持不同如果数据操作需要高事务性或者复杂数据查询需要控制执行计划，那么传统的SQL数据库从性能和稳定性方面考虑是你的最佳选择。SQL数据库支持对事务原子性细粒度控制，并且易于回滚事务。 虽然NoSQL数据库也可以使用事务操作，但稳定性方面没法和关系型数据库比较，所以它们真正闪亮的价值是在操作的扩展性和大数据量处理方面。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[],"author":"Marlowe"},{"title":"同一线程组下的线程，一个线程的异常会影响其他线程运行么？","slug":"操作系统/同一线程组下的线程，一个线程的异常会影响其他线程运行么？","date":"2021-04-23T14:33:15.000Z","updated":"2021-04-24T15:05:29.966Z","comments":true,"path":"2021/04/23/操作系统/同一线程组下的线程，一个线程的异常会影响其他线程运行么？/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%90%8C%E4%B8%80%E7%BA%BF%E7%A8%8B%E7%BB%84%E4%B8%8B%E7%9A%84%E7%BA%BF%E7%A8%8B%EF%BC%8C%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BC%9A%E5%BD%B1%E5%93%8D%E5%85%B6%E4%BB%96%E7%BA%BF%E7%A8%8B%E8%BF%90%E8%A1%8C%E4%B9%88%EF%BC%9F/","excerpt":"","text":"当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行！ 一个线程溢出后，进程里的其他线程还能照常运行。 同一线程组下的线程，一个线程出现异常不会影响其他线程的运行。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"}],"author":"Marlowe"},{"title":"线程崩溃必会使进程崩溃吗？","slug":"操作系统/线程崩溃必会使进程崩溃吗？","date":"2021-04-23T14:30:18.000Z","updated":"2021-04-23T14:39:37.116Z","comments":true,"path":"2021/04/23/操作系统/线程崩溃必会使进程崩溃吗？/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BA%BF%E7%A8%8B%E5%B4%A9%E6%BA%83%E5%BF%85%E4%BC%9A%E4%BD%BF%E8%BF%9B%E7%A8%8B%E5%B4%A9%E6%BA%83%E5%90%97%EF%BC%9F/","excerpt":"","text":"结论：线程崩溃不一定导致进程崩溃。 线程崩溃的本质就是内存出错。而内存出错有时不会引起其他线程出错的，因为崩溃的线程，也就是出错的内存有时侯没有被其他线程访问，也就不会产生问题，但有时候会打乱其他线程的内存。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"}],"author":"Marlowe"},{"title":"Object类中常用方法","slug":"Java/Object类中常用方法","date":"2021-04-23T14:04:31.000Z","updated":"2021-04-23T14:23:09.521Z","comments":true,"path":"2021/04/23/Java/Object类中常用方法/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/23/Java/Object%E7%B1%BB%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"取得对象信息的方法：toString()该方法在打印对象时被调用，将对象信息变为字符串返回，默认输出对象地址。 编译器默认调用toString()方法输出对象，但输出的是对象的地址，我们并不能看懂它的意思。那么就要通过重写Object类的toString()方法来输出对象属性信息。 对象相等判断方法：equals()public boolean equals(Object obj);用于比较当前对象与目标对象是否相等，默认是比较引用是否指向同一对象。为public方法，子类可重写。 12345public class Object&#123; public boolean equals(Object obj) &#123; return (this == obj); &#125;&#125; 为什么需要重写equals方法？ 因为如果不重写equals方法，当将自定义对象放到map或者set中时；如果这时两个对象的hashCode相同，就会调用equals方法进行比较，这个时候会调用Object中默认的equals方法，而默认的equals方法只是比较了两个对象的引用是否指向了同一个对象，显然大多数时候都不会指向，这样就会将重复对象存入map或者set中。这就 破坏了map与set不能存储重复对象的特性，会造成内存溢出 。 重写equals方法的几条约定： 自反性：即x.equals(x)返回true，x不为null； 对称性：即x.equals(y)与y.equals(x）的结果相同，x与y不为null； 传递性：即x.equals(y)结果为true, y.equals(z)结果为true，则x.equals(z)结果也必须为true； 一致性：即x.equals(y)返回true或false，在未更改equals方法使用的参数条件下，多次调用返回的结果也必须一致。x与y不为null。 如果x不为null, x.equals(null)返回false。 建议equals及hashCode两个方法，需要重写时，两个都要重写，一般都是将自定义对象放至Set中，或者Map中的key时，需要重写这两个方法。 对象签名:hashCode()该方法用来返回其所在对象的物理地址（哈希码值），常会和equals方法同时重写，确保相等的两个对象拥有相等的.hashCode。 public native int hashCode();这是一个public的方法，所以 子类可以重写 它。这个方法返回当前对象的hashCode值，这个值是一个整数范围内的（-2^31 ~ 2^31 - 1）数字。 对于hashCode有以下几点约束： 在 Java 应用程序执行期间，在对同一对象多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是将对象进行 equals 比较时所用的信息没有被修改； 如果两个对象 x.equals(y) 方法返回true，则x、y这两个对象的hashCode必须相等。 如果两个对象x.equals(y) 方法返回false，则x、y这两个对象的hashCode可以相等也可以不等。 但是，为不相等的对象生成不同整数结果可以提高哈希表的性能。 默认的hashCode是将内存地址转换为的hash值，重写过后就是自定义的计算方式；也可以通过System.identityHashCode(Object)来返回原本的hashCode。 12345678910111213public class HashCodeTest &#123; private int age; private String name; @Override public int hashCode() &#123; Object[] a = Stream.of(age, name).toArray(); int result = 1; for (Object element : a) &#123; result = 31 * result + (element == null ? 0 : element.hashCode()); &#125; return result; &#125;&#125; 推荐使用Objects.hash(Object… values)方法。相信看源码的时候，都看到计算hashCode都使用了31作为基础乘数， 为什么使用31呢？我比较赞同与理解result * 31 = (result&lt;&lt;5) - result。JVM底层可以自动做优化为位运算，效率很高；还有因为31计算的hashCode冲突较少，利于hash桶位的分布。 getClass()public final native ClassgetClass()：这是一个public的方法，我们可以直接通过对象调用。 类加载的第一阶段类的加载就是将.class文件加载到内存，并生成一个java.lang.Class对象的过程。getClass()方法就是获取这个对象，这是当前类的对象在运行时类的所有信息的集合。这个方法是反射三种方式之一。 反射三种方式： 对象的getClass() 类名.class Class.forName() clone()protected native Object clone() throws CloneNotSupportedException; 此方法返回当前对象的一个副本。 这是一个protected方法，提供给子类重写。但需要实现Cloneable接口，这是一个标记接口，如果没有实现，当调用object.clone()方法，会抛出CloneNotSupportedException。 1234567891011121314151617181920public class CloneTest implements Cloneable &#123; private int age; private String name; //省略get、set、构造函数等 @Override protected CloneTest clone() throws CloneNotSupportedException &#123; return (CloneTest) super.clone(); &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; CloneTest cloneTest = new CloneTest(23, &quot;9龙&quot;); CloneTest clone = cloneTest.clone(); System.out.println(clone == cloneTest); System.out.println(cloneTest.getAge()==clone.getAge()); System.out.println(cloneTest.getName()==clone.getName()); &#125;&#125;//输出结果//false//true//true 从输出我们看见，clone的对象是一个新的对象；但原对象与clone对象的 String类型 的name却是同一个引用，这表明，super.clone方法对成员变量如果是引用类型，进行是浅拷贝。 那什么是浅拷贝？对应的深拷贝？ 浅拷贝：拷贝的是引用。 深拷贝：新开辟内存空间，进行值拷贝。 那如果我们要进行深拷贝怎么办呢？看下面的例子。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Person implements Cloneable&#123; private int age; private String name; //省略get、set、构造函数等 @Override protected Person clone() throws CloneNotSupportedException &#123; Person person = (Person) super.clone(); //name通过new开辟内存空间 person.name = new String(name); return person; &#125;&#125;public class CloneTest implements Cloneable &#123; private int age; private String name; //增加了person成员变量 private Person person; //省略get、set、构造函数等 @Override protected CloneTest clone() throws CloneNotSupportedException &#123; CloneTest clone = (CloneTest) super.clone(); clone.person = person.clone(); return clone; &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; CloneTest cloneTest = new CloneTest(23, &quot;9龙&quot;); Person person = new Person(22, &quot;路飞&quot;); cloneTest.setPerson(person); CloneTest clone = cloneTest.clone(); System.out.println(clone == cloneTest); System.out.println(cloneTest.getAge() == clone.getAge()); System.out.println(cloneTest.getName() == clone.getName()); Person clonePerson = clone.getPerson(); System.out.println(person == clonePerson); System.out.println(person.getName() == clonePerson.getName()); &#125;&#125;//输出结果//false//true//true//false//false 可以看到，即使成员变量是引用类型，我们也实现了深拷贝。 如果成员变量是引用类型，想实现深拷贝，则成员变量也要实现Cloneable接口，重写clone方法。 wait()/ wait(long)/ wait(long,int)这三个方法是用来 线程间通信用 的，作用是 阻塞当前线程 ，等待其他线程调用notify()/notifyAll()方法将其唤醒。这些方法都是public final的，不可被重写。 注意： 此方法只能在当前线程获取到对象的锁监视器之后才能调用，否则会抛出IllegalMonitorStateException异常。 调用wait方法，线程会将锁监视器进行释放；而Thread.sleep，Thread.yield()并不会释放锁 。 wait方法会一直阻塞，直到其他线程调用当前对象的notify()/notifyAll()方法将其唤醒；而wait(long)是等待给定超时时间内（单位毫秒），如果还没有调用notify()/nofiyAll()会自动唤醒；waite(long,int)如果第二个参数大于0并且小于999999，则第一个参数+1作为超时时间； 1234567891011121314151617public final void wait() throws InterruptedException &#123; wait(0); &#125; public final native void wait(long timeout) throws InterruptedException;public final void wait(long timeout, int nanos) throws InterruptedException &#123; if (timeout &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException( &quot;nanosecond timeout value out of range&quot;); &#125; if (nanos &gt; 0) &#123; timeout++; &#125; wait(timeout); &#125; notify()/notifyAll()前面说了， 如果当前线程获得了当前对象锁，调用wait方法，将锁释放并阻塞；这时另一个线程获取到了此对象锁，并调用此对象的notify()/notifyAll()方法将之前的线程唤醒。 这些方法都是public final的，不可被重写。 public final native void notify(); 随机唤醒之前在当前对象上调用wait方法的一个线程 public final native void notifyAll(); 唤醒所有之前在当前对象上调用wait方法的线程 finalize()protected void finalize() throws Throwable ; 此方法是在垃圾回收之前，JVM会调用此方法来清理资源。此方法可能会将对象重新置为可达状态，导致JVM无法进行垃圾回收。 我们知道java相对于C++很大的优势是程序员不用手动管理内存，内存由jvm管理；如果我们的引用对象在堆中没有引用指向他们时，当内存不足时，JVM会自动将这些对象进行回收释放内存，这就是我们常说的垃圾回收。但垃圾回收没有讲述的这么简单。 finalize()方法具有如下4个特点： 永远不要主动调用某个对象的finalize()方法，该方法由垃圾回收机制自己调用； finalize()何时被调用，是否被调用具有不确定性； 当JVM执行可恢复对象的finalize()可能会将此对象重新变为可达状态； 当JVM执行finalize()方法时出现异常，垃圾回收机制不会报告异常，程序继续执行。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Object","slug":"Object","permalink":"https://xmmarlowe.github.io/tags/Object/"}],"author":"Marlowe"},{"title":"broadcast hash join和sort merge join","slug":"数据库/broadcast-hash-join和sort-merge-join","date":"2021-04-23T06:01:46.000Z","updated":"2021-04-23T14:23:09.528Z","comments":true,"path":"2021/04/23/数据库/broadcast-hash-join和sort-merge-join/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/23/%E6%95%B0%E6%8D%AE%E5%BA%93/broadcast-hash-join%E5%92%8Csort-merge-join/","excerpt":"","text":"Join背景介绍Join是数据库查询永远绕不开的话题，传统查询SQL技术总体可以分为简单操作（过滤操作-where、排序操作-limit等），聚合操作-groupby以及Join操作等。其中Join操作是最复杂、代价最大的操作类型，也是OLAP场景中使用相对较多的操作。因此很有必要对其进行深入研究。 另外，从业务层面来讲，用户在数仓建设的时候也会涉及Join使用的问题。通常情况下，数据仓库中的表一般会分为“低层次表”和“高层次表”。 所谓“低层次表”，就是数据源导入数仓之后直接生成的表，单表列值较少，一般可以明显归为维度表或事实表，表和表之间大多存在外健依赖，所以查询起来会遇到大量Join运算，查询效率很差。而“高层次表”是在“低层次表”的基础上加工转换而来，通常做法是使用SQL语句将需要Join的表预先进行合并形成“宽表”，在宽表上的查询不需要执行大量Join，效率很高。但宽表缺点是数据会有大量冗余，且相对生成较滞后，查询结果可能并不及时。 为了获得时效性更高的查询结果，大多数场景都需要进行复杂的Join操作。Join操作之所以复杂，主要是通常情况下其时间空间复杂度高，且有很多算法，在不同场景下需要选择特定算法才能获得最好的优化效果。本文将介绍SparkSQL所支持的几种常见的Join算法及其适用场景。 Join常见分类以及基本实现机制当前SparkSQL支持三种Join算法：shuffle hash join、broadcast hash join以及sort merge join。其中前两者归根到底都属于hash join，只不过在hash join之前需要先shuffle还是先broadcast。其实，hash join算法来自于传统数据库，而shuffle和broadcast是大数据的皮（分布式），两者一结合就成了大数据的算法了。因此可以说，大数据的根就是传统数据库。既然hash join是“内核”，那就刨出来看看，看完把“皮”再分析一下。 hash join先来看看这样一条SQL语句：select * from order,item where item.id = order.i_id，很简单一个Join节点，参与join的两张表是item和order，join key分别是item.id以及order.i_id。现在假设这个Join采用的是hash join算法，整个过程会经历三步： 确定Build Table以及Probe Table：这个概念比较重要，Build Table使用join key构建Hash Table，而Probe Table使用join key进行探测，探测成功就可以join在一起。通常情况下，小表会作为Build Table，大表作为Probe Table。此事例中item为Build Table，order为Probe Table。 构建Hash Table：依次读取Build Table（item）的数据，对于每一行数据根据join key(item.id)进行hash，hash到对应的Bucket，生成hash table中的一条记录。数据缓存在内存中，如果内存放不下需要dump到外存。 探测：再依次扫描Probe Table（order）的数据，使用相同的hash函数映射Hash Table中的记录，映射成功之后再检查join条件（item.id = order.i_id），如果匹配成功就可以将两者join在一起。 基本流程可以参考上图，这里有两个小问题需要关注： hash join性能如何？很显然，hash join基本都只扫描两表一次，可以认为o(a+b)，较之最极端的笛卡尔集运算a*b，不知甩了多少条街。 为什么Build Table选择小表？道理很简单，因为构建的Hash Table最好能全部加载在内存，效率最高；这也决定了hash join算法只适合至少一个小表的join场景，对于两个大表的join场景并不适用。 上文说过，hash join是传统数据库中的单机join算法，在分布式环境下需要经过一定的分布式改造，就是尽可能利用分布式计算资源进行并行化计算，提高总体效率。hash join分布式改造一般有两种经典方案： broadcast hash join：将其中一张小表广播分发到另一张大表所在的分区节点上，分别并发地与其上的分区记录进行hash join。broadcast适用于小表很小，可以直接广播的场景。 shuffler hash join：一旦小表数据量较大，此时就不再适合进行广播分发。这种情况下，可以根据join key相同必然分区相同的原理，将两张表分别按照join key进行重新组织分区，这样就可以将join分而治之，划分为很多小join，充分利用集群资源并行化。 下面分别进行详细讲解。 broadcast hash join如下图所示，broadcast hash join可以分为两步： broadcast阶段：将小表广播分发到大表所在的所有主机。广播算法可以有很多，最简单的是先发给driver，driver再统一分发给所有executor；要不就是基于BitTorrent的TorrentBroadcast。 hash join阶段：在每个executor上执行单机版hash join，小表映射，大表试探。 SparkSQL规定broadcast hash join执行的基本条件为被广播小表必须小于参数spark.sql.autoBroadcastJoinThreshold，默认为10M。 shuffle hash join在大数据条件下如果一张表很小，执行join操作最优的选择无疑是broadcast hash join，效率最高。但是一旦小表数据量增大，广播所需内存、带宽等资源必然就会太大，broadcast hash join就不再是最优方案。此时可以按照join key进行分区，根据key相同必然分区相同的原理，就可以将大表join分而治之，划分为很多小表的join，充分利用集群资源并行化。如下图所示，shuffle hash join也可以分为两步： shuffle阶段：分别将两个表按照join key进行分区，将相同join key的记录重分布到同一节点，两张表的数据会被重分布到集群中所有节点。这个过程称为shuffle。 hash join阶段：每个分区节点上的数据单独执行单机hash join算法。 看到这里，可以初步总结出来如果两张小表join可以直接使用单机版hash join；如果一张大表join一张极小表，可以选择broadcast hash join算法；而如果是一张大表join一张小表，则可以选择shuffle hash join算法；那如果是两张大表进行join呢？ sort merge joinSparkSQL对两张大表join采用了全新的算法－sort-merge join，如下图所示，整个过程分为三个步骤： shuffle阶段：将两张大表根据join key进行重新分区，两张表数据会分布到整个集群，以便分布式并行处理。 sort阶段：对单个分区节点的两表数据，分别进行排序。 merge阶段：对排好序的两张分区表数据执行join操作。join操作很简单，分别遍历两个有序序列，碰到相同join key就merge输出，否则取更小一边。如下图所示： 经过上文的分析，很明显可以得出来这几种Join的代价关系：cost(broadcast hash join) &lt; cost(shuffle hash join) &lt; cost(sort merge join)，数据仓库设计时最好避免大表与大表的join查询，SparkSQL也可以根据内存资源、带宽资源适量将参数spark.sql.autoBroadcastJoinThreshold调大，让更多join实际执行为broadcast hash join。 参考broadcast hash join和sort merge join","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"join","slug":"join","permalink":"https://xmmarlowe.github.io/tags/join/"}],"author":"Marlowe"},{"title":"操作系统之内存管理","slug":"操作系统/操作系统之内存管理","date":"2021-04-22T11:58:34.000Z","updated":"2021-04-23T14:26:19.817Z","comments":true,"path":"2021/04/22/操作系统/操作系统之内存管理/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","excerpt":"","text":"虚拟地址转换为物理地址 第一步，先将虚拟地址转换为逻辑地址： 根据程序中的虚拟地址得出其所在的段，然后加上段偏移，我们就能得到一个逻辑地址 第二步，再将逻辑地址转换为线型地址： 有了逻辑地址之后，我们需要将逻辑地址转换为线型地址（因为线型地址是逻辑地址转换到物理地址的一个中间层），只需要把逻辑地址加上段的基地址就能生成一个线型地址 第三步，再将线型地址再转换为物理地址： 如果启用了分页机制，那么就需要将需要找到段中对应页的地址，然后再找到页内偏移地址，最后得到物理地址 如果没有启用分页机制，那么线型地址直接就是物理地址了 常见的几种内存管理机制简单分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如块式管理。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理、段式管理、段页式管理。 块式管理: 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。 如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 页式管理: 把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率,减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理: 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如，有主程序段MAIN、子程序段X、数据段D及栈段S等。段式管理通过段表对应逻辑地址和物理地址。 段页式管理: 结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说段页式管理机制中段与段之间以及段的内部的都是离散的。 参考操作系统之内存管理 常见的几种内存管理机制","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内存管理","slug":"内存管理","permalink":"https://xmmarlowe.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}],"author":"Marlowe"},{"title":"Java并发之Unsafe类","slug":"并发/Java并发之Unsafe类","date":"2021-04-21T14:07:17.000Z","updated":"2021-04-21T14:58:33.218Z","comments":true,"path":"2021/04/21/并发/Java并发之Unsafe类/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/21/%E5%B9%B6%E5%8F%91/Java%E5%B9%B6%E5%8F%91%E4%B9%8BUnsafe%E7%B1%BB/","excerpt":"","text":"Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 这个类尽管里面的方法都是 public 的，但是并没有办法使用它们，JDK API 文档也没有提供任何关于这个类的方法的解释。总而言之，对于 Unsafe 类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然 JDK 库里面的类是可以随意使用的。 参考Java并发之Unsafe类","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Unsafe","slug":"Unsafe","permalink":"https://xmmarlowe.github.io/tags/Unsafe/"}],"author":"Marlowe"},{"title":"继承Thread和实现Runnable的区别","slug":"并发/继承Thread和实现Runnable的区别","date":"2021-04-19T14:42:00.000Z","updated":"2021-04-26T13:54:30.374Z","comments":true,"path":"2021/04/19/并发/继承Thread和实现Runnable的区别/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/19/%E5%B9%B6%E5%8F%91/%E7%BB%A7%E6%89%BFThread%E5%92%8C%E5%AE%9E%E7%8E%B0Runnable%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"当使用继承的时候，主要是为了不必重新开发，并且在不必了解实现细节的情况下拥有了父类我所需要的特征。它也有一个很大的缺点，那就是如果我们的类已经从一个类继承（如小程序必须继承自 Applet 类），则无法再继承 Thread 类， Java只能单继承，因此如果是采用继承Thread的方法，那么在以后进行代码重构的时候可能会遇到问题，因为你无法继承别的类了，在其他的方面，两者之间并没什么太大的区别。 implement Runnable是面向接口，扩展性等方面比继承Thread好。 使用 Runnable 接口来实现多线程使得我们能够在一个类中包容所有的代码，有利于封装，它的缺点在于，我们只能使用一套代码，若想创建多个线程并使各个线程执行不同的代码，则仍必须额外创建类，如果这样的话，在大多数情况下也许还不如直接用多个类分别继承 Thread 来得紧凑。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"https://xmmarlowe.github.io/tags/Thread/"},{"name":"Runnable","slug":"Runnable","permalink":"https://xmmarlowe.github.io/tags/Runnable/"}],"author":"Marlowe"},{"title":"多线程Future的用法","slug":"并发/多线程Future的用法","date":"2021-04-17T08:49:20.000Z","updated":"2021-04-19T12:10:56.916Z","comments":true,"path":"2021/04/17/并发/多线程Future的用法/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/17/%E5%B9%B6%E5%8F%91/%E5%A4%9A%E7%BA%BF%E7%A8%8BFuture%E7%9A%84%E7%94%A8%E6%B3%95/","excerpt":"","text":"在并发编程时，一般使用runnable，然后扔给线程池完事，这种情况下不需要线程的结果。 所以run的返回值是void类型。 如果是一个多线程协作程序，比如斐波那契数列，1，1，2，3，5，8…使用多线程来计算。但后者需要前者的结果，就需要用callable接口了。callable用法和runnable一样，只不过调用的是call方法，该方法有一个泛型返回值类型，你可以任意指定。 线程是属于异步计算模型，所以你不可能直接从别的线程中得到函数返回值。这时候，Future就出场了。Futrue可以监视目标线程调用call的情况，当你调用Future的get()方法以获得结果时，当前线程就开始阻塞，直接call方法结束返回结果。 下面三段简单的代码可以很简明的揭示这个意思： runnable接口实现的没有返回值的并发编程。 callable实现的存在返回值的并发编程。（call的返回值String受泛型的影响） 同样是callable，使用Future获取返回值。 参考多线程Future的用法","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Future","slug":"Future","permalink":"https://xmmarlowe.github.io/tags/Future/"}],"author":"Marlowe"},{"title":"Redis哨兵模式","slug":"NoSQL/Redis哨兵模式","date":"2021-04-17T07:43:36.000Z","updated":"2021-04-25T13:52:51.401Z","comments":true,"path":"2021/04/17/NoSQL/Redis哨兵模式/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/17/NoSQL/Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/","excerpt":"主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式…","text":"主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式… 概述哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 这里的哨兵有两个作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 用文字描述一下故障切换（failover） 的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。 当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。 这样对于客户端而言，一切都是透明的。 工作原理三个定时任务一、每10秒每个 sentinel 对master 和 slave 执行info 命令 :该命令第一个是用来发现slave节点,第二个是确定主从关系。 二、每2秒每个 sentinel 通过 master 节点的 channel(名称为sentinel:hello) 交换信息(pub/sub):用来交互对节点的看法(后面会介绍的节点主观下线和客观下线)以及自身信息。 三、每1秒每个 sentinel 对其他 sentinel 和 redis 执行 ping 命令,用于心跳检测,作为节点存活的判断依据。 主观下线和客观下线一、主观下线SDOWN:subjectively down,直接翻译的为”主观”失效,即当前sentinel实例认为某个redis服务为”不可用”状态。 二、客观下线 ODOWN:objectively down,直接翻译为”客观”失效,即多个sentinel实例都认为master处于”SDOWN”状态,那么此时master将处于ODOWN,ODOWN可以简单理解为master已经被集群确定为”不可用”,将会开启故障转移机制。 主从切换时,kill掉Redis主节点,然后查看 sentinel 日志,如下: 发现有类似 sdown 和 odown 的日志.在结合我们配置 sentinel 时的配置文件来看: 12#监控的IP 端口号 名称 sentinel通过投票后认为mater宕机的数量，此处为至少2个sentinel monitor mymaster 192.168.14.101 6379 2 最后的 2 表示投票数,也就是说当一台 sentinel 发现一个 Redis 服务无法 ping 通时,就标记为 主观下线 sdown;同时另外的 sentinel 服务也发现该 Redis 服务宕机,也标记为 主观下线,当多台 sentinel (大于等于2,上面配置的最后一个)时,都标记该Redis服务宕机,这时候就变为客观下线了,然后进行故障转移。 故障转移故障转移是由 sentinel 领导者节点来完成的(只需要一个sentinel节点),关于 sentinel 领导者节点的选取也是每个 sentinel 向其他 sentinel 节点发送我要成为领导者的命令,超过半数sentinel 节点同意,并且也大于quorum ,那么他将成为领导者,如果有多个sentinel都成为了领导者,则会过段时间再进行选举。 sentinel 领导者节点选举出来后,会通过如下几步进行故障转移: 一、从 slave 节点中选出一个合适的 节点作为新的master节点.这里的合适包括如下几点: 选择 slave-priority(slave节点优先级,也即priority最小的)最高的slave节点,如果存在则返回,不存在则继续下一步判断。 选择复制偏移量最大的 slave 节点(复制的最完整),如果存在则返回,不存在则继续。 选择runId最小的slave节点(启动最早的节点) 二、对上面选出来的 slave 节点执行 slaveof no one 命令让其成为新的 master 节点。 三、向剩余的 slave 节点发送命令,让他们成为新master 节点的 slave 节点,复制规则和前面设置的 parallel-syncs 参数有关。 四、更新原来master 节点配置为 slave 节点,并保持对其进行关注,一旦这个节点重新恢复正常后,会命令它去复制新的master节点信息.(注意:原来的master节点恢复后是作为slave的角色) 可以从 sentinel 日志中出现的几个消息来进行查看故障转移: +switch-master: 表示切换主节点(从节点晋升为主节点) +sdown: 主观下线 +odown: 客观下线 +convert-to-slave: 切换从节点(原主节点降为从节点)","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis主从复制","slug":"NoSQL/Redis主从复制","date":"2021-04-17T07:43:23.000Z","updated":"2021-04-22T06:31:27.513Z","comments":true,"path":"2021/04/17/NoSQL/Redis主从复制/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/17/NoSQL/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"为了分担读压力，Redis支持主从复制，Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步…","text":"为了分担读压力，Redis支持主从复制，Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步… 概念主从复制： 指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（Master/Leader），后者称为从节点（Slave/Follower）， 数据的复制是单向的！只能由主节点复制到从节点（主节点以写为主、从节点以读为主）。 主从复制的作用默认情况下，每台Redis服务器都是主节点，一个主节点可以有0个或者多个从节点，但每个从节点只能由一个主节点。 作用 解释 数据冗余 主从复制实现了数据的热备份 故障恢复 当主节点故障时，从节点可以暂时替代主节点提供服务式 负载均衡 由主节点进行写操作，从节点进行读操作，分担服务器的负载；尤其是在多读少写的场景下，通过多个从节点分担负载，提高并发量 高可用基石 主从复制还是哨兵和集群能够实施的基础 全量复制与增量复制全量复制 Redis 全量复制一般发生在Slave初始化阶段，这时 Slave 需要将 Master 上的所有数据都复制一份。具体步骤如下： 从服务器连接主服务器，发送SYNC命令； 主服务器接收到sYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令。 增量复制 Redis 增量复制是指 Slave 初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。 为什么要搭建集群？一般来说，要将Redis运用于工程项目中，只使用一台Redis是万万不能的（宕机），原因如下： 从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较大； 从容量上，单个Redis服务器内存容量有限，就算一台Redis服务器内存容量为256G，也不能将所有 内存用作Redis存储内存，一般来说，单台Redis大使用内存不应该超过20G。复制原理 当启动一个 slave node 的时候，它会发送一个 psync 命令给 master node。如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据；如果slave node 跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 过程原理 当从库和主库建立MS关系后，会向主数据库发送SYNC命令 主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)， 并将期间接收到的 写命令缓存起来 当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis 从Redis接收到后，会载入快照文件并且执行收到的缓存的命令 之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致 主从复制优缺点优点 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成 Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。(层层连接) Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求。 Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据 缺点 Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。 Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。 层层链路上一个M链接下一个 S！ 环境配置只配置从库，不用配置主库! 1234567891011127.0.0.1:6379&gt; info replication # 查看当前库的信息 # Replication role:master # 角色 master connected_slaves:0 # 没有从机master_replid:b63c90e6c501143759cb0e7f450bd1eb0c70882amaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0 second_repl_offset:-1repl_backlog_active:0 repl_backlog_size:1048576repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 复制3个配置文件，然后修改对应的信息 12341端口2pid 名字3log文件名字4dump.rdb 名字 修改完毕之后，启动我们的3个redis服务器，可以通过进程信息查看！ 默认情况下，每台Redis服务器都是主节点；我们一般情况下只用配置从就好了！认老大！ 一主 （79）二从（80，81） 真实的从主配置应该在配置文件中配置，这样的话是永久的，我们这里用的是命令，暂时的！主机可以写，从机不能写只能读！主机中的所有信息和数据，都会自动从机保存！测试：主机断开连接，从机依旧连接到主机的，但是没有写操作，这个候，主机如果回来了，从机依旧可以直接获取到主机写的信息！如果是使用命令行，来配置的主从，这个时候如果重启了，就会变回主机！只要变为从机，立马就会从 主机中获取值！ 参考请你谈谈Redis主从复制的理解？","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"","slug":"NoSQL/如何保证缓存和数据库数据的一致性？","date":"2021-04-17T07:30:13.752Z","updated":"2021-05-04T14:38:59.906Z","comments":true,"path":"2021/04/17/NoSQL/如何保证缓存和数据库数据的一致性？/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/17/NoSQL/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/","excerpt":"title: 如何保证缓存和数据库数据的一致性？author: Marlowedate: 2021-04-17 15:30:13tags: 缓存 数据库categories: NoSQL","text":"title: 如何保证缓存和数据库数据的一致性？author: Marlowedate: 2021-04-17 15:30:13tags: 缓存 数据库categories: NoSQL 如何保证缓存和数据库数据的一致性？当我们对数据进行修改的时候，到底是先删缓存，还是先写数据库?1、如果先删缓存，再写数据库: 在高并发场景下，当第一个线程删除了缓存，还没有来得及写数据库，第二个线程来读取数据，会发现缓存中的数据为空，那就会去读数据库中的数据(旧值，脏数据)，读完之后，把读到的结果写入缓存(此时，第一个线程已经将新的值写到缓存里面了)，这样缓存中的值就会被覆盖为修改前的脏数据。 总结: 在这种方式下，通常要求写操作不会太频繁。 解决方案: 先操作缓存，但是不删除缓存。将缓存修改为一个特殊值(-999)。客户端读缓存时，发现是默认值，就休眠一小会，再去查-次Redis。 问题： 1. 特殊值对业务有侵入。2. 休眠时间， 可能会多次重复，对性能有影响。 延时双删：先删除缓存，然后再写数据库，休眠一小会，再次删除缓存。 问题： 1. 如果数据写操作很频繁， 同样还是会有脏数据的问题。 2、先写数据库，再删缓存: 如果数据库写完了之后， 缓存删除失败，数据就会不一致。 总结: 始终只能保证一定时间内的最终一致性。 解决方案: 给缓存设置一个过期时间。 问题: 过期时间内，缓存数据不会更新。 引入MQ，保证原子操作。 解决方案: 将热点数据缓存设置为永不过期，但是在value当中写入一个逻辑上的过期时间，另外起一个后台线程，扫描这些key,对于已逻辑上过期的缓存，进行删除。 不是严格要求缓存+数据库必须一致性一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况 串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。 严格要求缓存+数据库必须一致性将不一致分为三种情况： 数据库有数据，缓存没有数据； 数据库有数据，缓存也有数据，数据不相等； 数据库没有数据，缓存有数据。 在讨论这三种情况之前，先说明一下使用缓存的策略，叫做 Cache Aside Pattern。简而言之就是 1. 首先尝试从缓存读取，读到数据则直接返回；如果读不到，就读数据库，并将数据会写到缓存，并返回。2. 需要更新数据时，先更新数据库，然后把缓存里对应的数据失效掉（删掉）。 第一种数据库有数据，缓存没有数据： 在读数据的时候，会自动把数据库的数据写到缓存，因此不一致自动消除. 第二种数据库有数据，缓存也有数据，数据不相等： 数据最终变成了不相等，但他们之前在某一个时间点一定是相等的（不管你使用懒加载还是预加载的方式，在缓存加载的那一刻，它一定和数据库一致）。这种不一致，一定是由于你更新数据所引发的。前面我们讲了更新数据的策略，先更新数据库，然后删除缓存。因此，不一致的原因，一定是数据库更新了，但是删除缓存失败了。 第三种数据库没有数据，缓存有数据， 情况和第二种类似，你把数据库的数据删了，但是删除缓存的时候失败了。 因此，最终的结论是，需要解决的不一致，产生的原因是更新数据库成功，但是删除缓存失败。 解决方案大概有以下几种： 对删除缓存进行重试，数据的一致性要求越高，我越是重试得快。 定期全量更新，简单地说，就是我定期把缓存全部清掉，然后再全量加载。 给所有的缓存一个失效期。 第三种方案可以说是一个大杀器，任何不一致，都可以靠失效期解决，失效期越短，数据一致性越高。但是失效期越短，查数据库就会越频繁。因此失效期应该根据业务来定。 并发不高的情况： 读: 读redis-&gt;没有，读mysql-&gt;把mysql数据写回redis，有的话直接从redis中取； 写: 写mysql-&gt;成功，再写redis； 并发高的情况： 读: 读redis-&gt;没有，读mysql-&gt;把mysql数据写回redis，有的话直接从redis中取； 写：异步话，先写入redis的缓存，就直接返回；定期或特定动作将数据保存到mysql，可以做到多次更新，一次保存；","categories":[],"tags":[]},{"title":"布隆过滤器","slug":"NoSQL/布隆过滤器","date":"2021-04-17T02:44:43.000Z","updated":"2021-04-29T14:01:39.145Z","comments":true,"path":"2021/04/17/NoSQL/布隆过滤器/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/17/NoSQL/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"简介布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。 在讲述布隆过滤器的原理之前，我们先思考一个问题，如果想要判断一个元素是否存在，你通常会怎么做？一般的做法都是将其保存起来然后通过比较确认，一共会有如下几种情况： 如果使用线性表或者数组存储，则查找的时间复杂度为 O(n)。 如果使用树存储，则查找的时间复杂度为 O(logn)。 如果使用哈希表存储，则查找的时间复杂度为 O(log(n/m))，m 为哈希分桶数。 对于上述三种情况我相信大部分读者都倾向于哈希表，因为其时间复杂度最低（在极端情况下时间复杂度可以为 O(1) ），但是哈希表也有缺陷，例如存储容量占比高，考虑到负载因子的存在，通常存储空间都不会被用完。当然无论是哈希表、树、线性表，一旦元素的数量极多时，查询的速度会变得很慢，而且占用的空间也会大到无法想象。那么有办法解决没有呢？答案是有，布隆过滤器就是解决该问题的利器。 设计思想布隆过滤器是一个由 一个长度为 M 比特的位数组（bit array）与 K 个哈希函数（hash function） 组成的数据结构。布隆过滤器主要用于用于检索一个元素是否在一个集合中。 位数组中的元素初始值都是 0 ，所有哈希函数可以把输入的数据均匀低散列。图例如下： 当要插入一个元素时，将其输入 K 个哈希函数，产生 K 个哈希值，同时以这些哈希值作为位数组的下标，将这些下标对应的比特值设置为 1。 当要查询一个元素时，同样是将其输入 K 个哈希函数，产生 K 个哈希值，然后检查这些哈希值中对应的比特值。如果有任意一个比特值为 0，则表明该元素一定不存在，如果所有比特值都是 1，则表明该元素可能存在，为什么不是一定存在呢？因为一个比特值为 1 有可能会受到其他元素的影响。所以 布隆过滤器是用于检测一个元素是否一定不存在或者有可能存在。 加入我们有一个布隆过滤器长度为 10，有 3 个哈希函数。这时我们我们将 ”死“插入到布隆过滤器中，经过三个哈希函数得到的哈希值为 3、6、9，则如下： 现在我们再存一个值：”磕“，假设得到的哈希值为 1 6 8，如下： 我们再查下 ”Redis“，假设返回的哈希值为 1 5 7，得到的比特值为 1 0 0 ，所以我们可以很确切地说”Redis“这个值一定不存在，如果查询 “Java” 得到的哈希值为 1 6 9，比特值为 1 1 1，那么我们是否可以说一定存在呢？答案是不可以，只能说 “Java” 这个值有可能存在。因为随着数据的增多，越来越多位置的比特值被设置为 1，有可能存在某个值从来没有被存储，但是哈希函数返回的位值都为 1 。 优缺点优点 不需要存储数据，只用比特表示，因此在空间占用率上有巨大的优势 检索效率高，插入和查询的时间复杂度都为 O(K)（K 表示哈希函数的个数） 哈希函数之间相互独立，可以在硬件指令层次并行计算，因此效率较高。 缺点 存在不确定的因素，无法判断一个元素是否一定存在，所以不适合要求 100% 准确率的场景 只能插入和查询元素，不能删除元素。 实例关于布隆过滤器，我们不需要自己实现，Guava 已经帮助我们实现了，使用起来非常简单。 引入 pom 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;25.1-jre&lt;/version&gt;&lt;/dependency&gt; 使用 123456789101112public static void main(String... args)&#123; /** * 创建一个插入对象为一亿，误报率为0.01%的布隆过滤器 */ BloomFilter&lt;CharSequence&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charset.forName(&quot;utf-8&quot;)), 100000000, 0.0001); bloomFilter.put(&quot;死&quot;); bloomFilter.put(&quot;磕&quot;); bloomFilter.put(&quot;Redis&quot;); System.out.println(bloomFilter.mightContain(&quot;Redis&quot;)); System.out.println(bloomFilter.mightContain(&quot;Java&quot;)); &#125; 参考【死磕 Redis】—– 布隆过滤器","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"过滤器","slug":"过滤器","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/"}],"author":"Marlowe"},{"title":"红黑树相比于BST和AVL树有什么优点？","slug":"算法与数据结构/红黑树相比于BST和AVL树有什么优点？","date":"2021-04-16T13:35:31.000Z","updated":"2021-04-22T06:54:04.864Z","comments":true,"path":"2021/04/16/算法与数据结构/红黑树相比于BST和AVL树有什么优点？/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BA%A2%E9%BB%91%E6%A0%91%E7%9B%B8%E6%AF%94%E4%BA%8EBST%E5%92%8CAVL%E6%A0%91%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%82%B9%EF%BC%9F/","excerpt":"","text":"红黑树是牺牲了严格的高度平衡的优越条件为代价，它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。红黑树能够以O(log2 n)的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。当然，还有一些更好的，但实现起来更复杂的数据结构能够做到一步旋转之内达到平衡，但红黑树能够给我们一个比较“便宜”的解决方案。 相比于BST，因为红黑树可以能确保树的最长路径不大于两倍的最短路径的长度，所以可以看出它的查找效果是有最低保证的。在最坏的情况下也可以保证O(logN)的，这是要好于二叉查找树的。因为二叉查找树最坏情况可以让查找达到O(N)。 红黑树的算法时间复杂度和AVL相同，但统计性能比AVL树更高，所以在插入和删除中所做的后期维护操作肯定会比红黑树要耗时好多，但是他们的查找效率都是O(logN)，所以红黑树应用还是高于AVL树的. 实际上插入 AVL 树和红黑树的速度取决于你所插入的数据.如果你的数据分布较好,则比较宜于采用 AVL树(例如随机产生系列数),但是如果你想处理比较杂乱的情况,则红黑树是比较快的。","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://xmmarlowe.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"BST","slug":"BST","permalink":"https://xmmarlowe.github.io/tags/BST/"},{"name":"AVL","slug":"AVL","permalink":"https://xmmarlowe.github.io/tags/AVL/"},{"name":"红黑树","slug":"红黑树","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"}],"author":"Marlowe"},{"title":"Java内存模型-JMM","slug":"Java/Java内存模型-JMM","date":"2021-04-16T13:19:30.000Z","updated":"2021-04-22T07:23:46.027Z","comments":true,"path":"2021/04/16/Java/Java内存模型-JMM/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/Java/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-JMM/","excerpt":"","text":"介绍Java内存模型（Java Memery Model）用来屏蔽掉各种硬件和操作系统的内存访问差异。以至于让Java在各中平台下都能达到一致的内存访问效果。 简单的说，JMM 定义了一套在多线程读写共享数据时（成员变量、数组）时，对数据的可见性、有序性、和原子性的规则和保障. 从硬件角度来看。因为处理器的运算速度很快，比如做一个递增操作，就需要从内存中拿值，操作后再放回内存。这样的I/O是无法避免的，但这I/O速度和处理器的运算速度就不是一个数量级，所以为了解决这个问题，就对每个处理器加一个高速缓存（Cache）来作为处理器与内存之间的缓冲。把需要使用的数据复制到缓存中，运算完成之后在从缓存同步到内存。这样处理器就不用等待缓慢的内存读写了。 Java内存模型图 主存与工作内存的一些交互指令 操作 作用对象 解释 lock 主内存 把一个变量标识为一条线程独占的状态 unlock 主内存 把一个处于锁定状态的变量释放出来，释放后才可被其他线程锁定 read 主内存 把一个变量的值从主内存传输到线程工作内存中，以便 load 操作使用 load 工作内存 把 read 操作从主内存中得到的变量值放入工作内存中 use 工作内存 把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量值的字节码指令时将会执行这个操作 assign 工作内存 把一个从执行引擎接收到的值赋接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作 store 工作内存 把工作内存中的一个变量的值传送到主内存中，以便 write 操作 write 工作内存 把 store 操作从工作内存中得到的变量的值放入主内存的变量中 例子： 对于volatile型变量的特殊规则关键字 volatile 是 Java 虚拟机提供的最轻量级的同步机制。保存了线程可见性与防止指令重排。 一个变量被定义为volatile的特性1.保证此变量对所有线程的可见性。但是对变量的操作如果不是原子操作，那么并发情况下不安全。如果不满足以下条件就，需要加锁保证并发安全。 运算结果并不依赖变量当前值 能够确保只有单一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 2.禁止指令重排序优化。通过插入内存屏障保证一致性。 对于long和double型变量的特殊规则Java 要求对于主内存和工作内存之间的八个操作都是原子性的，但是对于 64 位的数据类型，有一条宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，即允许虚拟机实现选择可以不保证 64 位数据类型的 load、store、read 和 write 这 4 个操作的原子性。这就是 long 和 double 的非原子性协定。 原子性、可见性与有序性原子性(Atomicity)由 Java 内存模型来直接保证的原子性变量操作包括 read、load、assign、use、store 和 write。大致可以认为基本数据类型的操作是原子性的。同时 lock 和 unlock 可以保证更大范围操作的原子性。而 synchronize 同步块操作的原子性是用更高层次的字节码指令 monitorenter 和 monitorexit 来隐式操作的。 可见性(Visibility)是指当一个线程修改了共享变量的值，其他线程也能够立即得知这个通知。主要操作细节就是修改值后将值同步至主内存(volatile 值使用前都会从主内存刷新)，除了 volatile 还有 synchronize 和 final 可以保证可见性。同步块的可见性是由“对一个变量执行unlock 操作之前，必须先把此变量同步会主内存中( store、write 操作)”这条规则获得。而 final 可见性是指：被 final 修饰的字段在构造器中一旦完成，并且构造器没有把 “this” 的引用传递出去( this 引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象)，那在其他线程中就能看见 final 字段的值。 有序性(Ordering)如果在被线程内观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有操作都是无序的。前半句指“线程内表现为串行的语义”，后半句是指“指令重排”现象和“工作内存与主内存同步延迟”现象。Java 语言通过 volatile 和 synchronize 两个关键字来保证线程之间操作的有序性。volatile 自身就禁止指令重排，而 synchronize 则是由“一个变量在同一时刻只允许一条线程对其进行 lock 操作”这条规则获得，这条规则决定了持有同一个锁的两个同步块只能串行的进入。 先行发生原则也就是 happens-before 原则。这个原则是判断数据是否存在竞争、线程是否安全的主要依据。先行发生是 Java 内存模型中定义的两项操作之间的偏序关系。 天然的先行发生关系|规则| 解释||:—-:|:—-:|:—-:||程序次序规则| 在一个线程内，代码按照书写的控制流顺序执行||管程锁定规则| 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作||volatile 变量规则| volatile 变量的写操作先行发生于后面对这个变量的读操作||线程启动规则| Thread 对象的 start() 方法先行发生于此线程的每一个动作||线程终止规则| 线程中所有的操作都先行发生于对此线程的终止检测(通过 Thread.join() 方法结束、 Thread.isAlive() 的返回值检测)||线程中断规则| 对线程 interrupt() 方法调用优先发生于被中断线程的代码检测到中断事件的发生 (通过 Thread.interrupted() 方法检测)||对象终结规则| 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始||传递性| 如果操作 A 先于 操作 B 发生，操作 B 先于 操作 C 发生，那么操作 A 先于 操作 C| 参考Java内存模型JMM","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"JMM","slug":"JMM","permalink":"https://xmmarlowe.github.io/tags/JMM/"}],"author":"Marlowe"},{"title":"线程间通信问题","slug":"并发/线程间通信问题","date":"2021-04-16T13:15:10.000Z","updated":"2021-04-22T07:28:28.102Z","comments":true,"path":"2021/04/16/并发/线程间通信问题/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98/","excerpt":"","text":"wait/notify/notifyAll wait()、notify/notifyAll() 方法是Object的本地final方法，无法被重写。 wait()使当前线程阻塞，前提是 必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。 由于 wait()、notify/notifyAll() 在synchronized 代码块执行，说明当前线程一定是获取了锁的。 当线程执行wait()方法时候，会释放当前的锁，然后让出CPU，进入等待状态。 只有当 notify/notifyAll() 被执行时候，才会唤醒一个或多个正处于等待状态的线程，然后继续往下执行，直到执行完synchronized 代码块的代码或是中途遇到wait() ，再次释放锁。 也就是说，notify/notifyAll() 的执行只是唤醒沉睡的线程，而不会立即释放锁，锁的释放要看代码块的具体执行情况。所以在编程中，尽量在使用了notify/notifyAll() 后立即退出临界区，以唤醒其他线程让其获得锁 wait() 需要被try catch包围，以便发生异常中断也可以使wait等待的线程唤醒。 notify 和wait 的顺序不能错，如果A线程先执行notify方法，B线程在执行wait方法，那么B线程是无法被唤醒的。 notify 和 notifyAll的区别notify方法只唤醒一个等待（对象的）线程并使该线程开始执行。所以如果有多个线程等待一个对象，这个方法只会唤醒其中一个线程，选择哪个线程取决于操作系统对多线程管理的实现。notifyAll 会唤醒所有等待(对象的)线程，尽管哪一个线程将会第一个处理取决于操作系统的实现。如果当前情况下有多个线程需要被唤醒，推荐使用notifyAll 方法。比如在生产者-消费者里面的使用，每次都需要唤醒所有的消费者或是生产者，以判断程序是否可以继续往下执行。 在多线程中要测试某个条件的变化，使用if 还是while？要注意，notify唤醒沉睡的线程后，线程会接着上次的执行继续往下执行。所以在进行条件判断时候，可以先把 wait 语句忽略不计来进行考虑；显然，要确保程序一定要执行，并且要保证程序直到满足一定的条件再执行，要使用while进行等待，直到满足条件才继续往下执行。 Volatile见站内文章volatile关键字 countDownLatch、CyclicBarrier、Semaphore见站内文章countDownLatch、CyclicBarrier、Semaphore 参考Java多线程学习之wait、notify/notifyAll 详解","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"通信","slug":"通信","permalink":"https://xmmarlowe.github.io/tags/%E9%80%9A%E4%BF%A1/"}],"author":"Marlowe"},{"title":"Redis跳跃表","slug":"NoSQL/Redis跳跃表","date":"2021-04-16T12:39:08.000Z","updated":"2021-04-17T14:58:35.358Z","comments":true,"path":"2021/04/16/NoSQL/Redis跳跃表/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/NoSQL/Redis%E8%B7%B3%E8%B7%83%E8%A1%A8/","excerpt":"Redis跳跃表相关问题…","text":"Redis跳跃表相关问题… 什么是跳跃表跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他的几点指针，从而达到快速访问队尾目的。跳跃表的效率可以和平衡树想媲美了，最关键是它的实现相对于平衡树来说，代码的实现上简单很多。 跳跃表用在哪里说真的，跳跃表在 Redis 中使用不是特别广泛，只用在了两个地方：一、是实现有序集合键。二、是集群节点中用作内部数据结构。 跳跃表原理我们先来看一下一张完整的跳跃表的图。 跳跃表的 level 是如何定义的？跳跃表 level 层级完全是随机的。一般来说，层级越多，访问节点的速度越快。 跳跃表的插入首先我们需要插入几个数据。链表开始时是空的。插入 level = 3，key = 1当我们插入 level = 3，key = 1 时，结果如下：插入 level = 1，key = 2当继续插入 level = 1，key = 2 时，结果如下插入 level = 2，key = 3当继续插入 level = 2，key = 3 时，结果如下插入 level = 3，key = 5当继续插入 level = 3，key = 5 时，结果如下插入 level = 1，key = 66当继续插入 level = 1，key = 66 时，结果如下插入 level = 2，key = 100当继续插入 level = 2，key = 100 时，结果如下上述便是跳跃表插入原理，关键点就是层级–使用抛硬币的方式，感觉还真是挺随机的。每个层级最末端节点指向都是为 null，表示该层级到达末尾，可以往下一级跳。 跳跃表的查询现在我们要找键为 66 的节点的值。那跳跃表是如何进行查询的呢？ 跳跃表的查询是从顶层往下找，那么会先从第顶层开始找，方式就是循环比较，如过顶层节点的下一个节点为空说明到达末尾，会跳到第二层，继续遍历，直到找到对应节点。 如下图所示红色框内，我们带着键 66 和 1 比较，发现 66 大于 1。继续找顶层的下一个节点，发现 66 也是大于五的，继续遍历。由于下一节点为空，则会跳到 level 2。 上层没有找到 66，这时跳到 level 2 进行遍历，但是这里有一个点需要注意，遍历链表不是又重新遍历。而是从 5 这个节点继续往下找下一个节点。如下，我们遍历了 level 3 后，记录下当前处在 5 这个节点，那接下来遍历是 5 往后走，发现 100 大于目标 66，所以还是继续下沉。 当到 level 1 时，发现 5 的下一个节点恰恰好是 66 ，就将结果直接返回。 跳跃表删除跳跃表的删除和查找类似，都是一级一级找到相对应的节点，然后将 next 对象指向下下个节点，完全和链表类似。 现在我们来删除 66 这个节点，查找 66 节点和上述类似。 接下来是断掉 5 节点 next 的 66 节点，然后将它指向 100 节点。如上就是跳跃表的删除操作了，和我们平时接触的链表是一致的。当然，跳跃表的修改，也是和删除查找类似，只不过是将值修改罢了，就不继续介绍了。 参考面试准备 – Redis 跳跃表","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？","slug":"NoSQL/假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？","date":"2021-04-16T12:34:16.000Z","updated":"2021-04-17T14:58:35.394Z","comments":true,"path":"2021/04/16/NoSQL/假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/NoSQL/%E5%81%87%E5%A6%82Redis%E9%87%8C%E9%9D%A2%E6%9C%891%E4%BA%BF%E4%B8%AAkey%EF%BC%8C%E5%85%B6%E4%B8%AD%E6%9C%8910w%E4%B8%AAkey%E6%98%AF%E4%BB%A5%E6%9F%90%E4%B8%AA%E5%9B%BA%E5%AE%9A%E7%9A%84%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%89%8D%E7%BC%80%E5%BC%80%E5%A4%B4%E7%9A%84%EF%BC%8C%E5%A6%82%E4%BD%95%E5%B0%86%E5%AE%83%E4%BB%AC%E5%85%A8%E9%83%A8%E6%89%BE%E5%87%BA%E6%9D%A5%EF%BC%9F/","excerpt":"","text":"使用keys指令可以扫出指定模式的key列表。 对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令， scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis事务的CAS(check-and-set)","slug":"NoSQL/Redis事务的CAS-check-and-set","date":"2021-04-16T12:28:46.000Z","updated":"2021-04-22T07:36:13.177Z","comments":true,"path":"2021/04/16/NoSQL/Redis事务的CAS-check-and-set/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/NoSQL/Redis%E4%BA%8B%E5%8A%A1%E7%9A%84CAS-check-and-set/","excerpt":"和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。","text":"和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。 Redis中事务的实现特征： 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为”BEGIN TRANSACTION”语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"为什么redis需要把所有数据放到内存中?","slug":"NoSQL/为什么redis需要把所有数据放到内存中","date":"2021-04-16T12:24:56.000Z","updated":"2021-04-17T14:58:35.364Z","comments":true,"path":"2021/04/16/NoSQL/为什么redis需要把所有数据放到内存中/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/NoSQL/%E4%B8%BA%E4%BB%80%E4%B9%88redis%E9%9C%80%E8%A6%81%E6%8A%8A%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E6%94%BE%E5%88%B0%E5%86%85%E5%AD%98%E4%B8%AD/","excerpt":"","text":"Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis内存淘汰机制","slug":"NoSQL/Redis内存淘汰机制","date":"2021-04-16T12:20:38.000Z","updated":"2021-04-17T14:58:35.336Z","comments":true,"path":"2021/04/16/NoSQL/Redis内存淘汰机制/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/NoSQL/Redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6/","excerpt":"","text":"Redis 提供 6 种数据淘汰策略： volatile-lru（least recently used）： 从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl： 从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random： 从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru（least recently used）： 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的） allkeys-random： 从数据集（server.db[i].dict）中任意选择数据淘汰 no-eviction： 禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！ 4.0 版本后增加以下两种： volatile-lfu（least frequently used）： 从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 allkeys-lfu（least frequently used）： 当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Java反射相关知识点","slug":"Java/Java反射相关知识点","date":"2021-04-16T08:00:16.000Z","updated":"2021-04-22T07:43:39.141Z","comments":true,"path":"2021/04/16/Java/Java反射相关知识点/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/16/Java/Java%E5%8F%8D%E5%B0%84%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"什么是反射？反射是在运行状态中，对于任意一个类， 都能够知道这个类的所有属性和方法；对于任意一个对象， 都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 Java 语言的反射机制。 哪里用到反射机制？ JDBC中，利用反射 (Class.forName(xxx)) 动态加载了数据库驱动程序。 Web服务器中利用反射调用了Sevlet的服务方法。 Eclispe等开发工具利用反射动态刨析对象的类型与结构，动态提示对象的属性和方法。 很多框架都用到反射机制，注入属性，调用方法，如Spring。 什么叫对象序列化，什么是反序列化，实现对象序列化需要做哪些工作？ 对象序列化： 将对象中的数据编码为字节序列的过程。 反序列化： 将对象的编码字节重新反向解码为对象的过程。 JAVA提供了API实现了对象的序列化和反序列化的功能，使用这些API时需要遵守如下约定： 被序列化的对象类型需要实现序列化接口，此接口是标志接口，没有声明任何的抽象方法，JAVA编译器识别这个接口，自动的为这个类添加序列化和反序列化方法。 为了保持序列化过程的稳定，建议在类中添加序列化版本号。 不想让字段放在硬盘上就加transient 以下情况需要使用 Java 序列化： 想把的内存中的对象状态保存到一个文件中或者数据库中时候； 想用套接字在网络上传送对象的时候； 想通过RMI（远程方法调用）传输对象的时候。 反射机制的优缺点？ 优点： 可以动态执行，在运行期间根据业务功能动态执行方法、访问属性，最大限度发挥了java的灵活性。 缺点： 让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。 Java反射机制的作用 在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断任意一个类所具有的成员变量和方法 在运行时调用任意一个对象的方法 获取 Class 对象的四种方式如果我们动态获取到这些信息，我们需要依靠 Class 对象。Class 类对象将一个类的方法、变量等信息告诉运行的程序。Java 提供了四种方式获取 Class 对象: 1. 知道具体类的情况下可以使用： 1Class alunbarClass = TargetObject.class; 但是我们一般是不知道具体类的，基本都是通过遍历包下面的类来获取 Class 对象，通过此方式获取 Class 对象不会进行初始化。 2. 通过 Class.forName()传入类的路径获取： 1Class alunbarClass1 = Class.forName(&quot;cn.javaguide.TargetObject&quot;); 3.通过对象实例instance.getClass()获取： 12TargetObject o = new TargetObject();Class alunbarClass2 = o.getClass(); 4.通过类加载器xxxClassLoader.loadClass()传入类路径获取: 1class clazz = ClassLoader.LoadClass(&quot;cn.javaguide.TargetObject&quot;); 通过类加载器获取 Class 对象不会进行初始化，意味着不进行包括初始化等一些列步骤，静态块和静态对象不会得到执行 反射的一些基本操作简单用代码演示一下反射的一些操作! 1.创建一个我们要使用反射操作的类 TargetObject。 1234567891011121314151617package cn.javaguide;public class TargetObject &#123; private String value; public TargetObject() &#123; value = &quot;JavaGuide&quot;; &#125; public void publicMethod(String s) &#123; System.out.println(&quot;I love &quot; + s); &#125; private void privateMethod() &#123; System.out.println(&quot;value is &quot; + value); &#125;&#125; 2.使用反射操作这个类的方法以及参数 12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.javaguide;import java.lang.reflect.Field;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;public class Main &#123; public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InstantiationException, InvocationTargetException, NoSuchFieldException &#123; /** * 获取TargetObject类的Class对象并且创建TargetObject类实例 */ Class&lt;?&gt; tagetClass = Class.forName(&quot;cn.javaguide.TargetObject&quot;); TargetObject targetObject = (TargetObject) tagetClass.newInstance(); /** * 获取所有类中所有定义的方法 */ Method[] methods = tagetClass.getDeclaredMethods(); for (Method method : methods) &#123; System.out.println(method.getName()); &#125; /** * 获取指定方法并调用 */ Method publicMethod = tagetClass.getDeclaredMethod(&quot;publicMethod&quot;, String.class); publicMethod.invoke(targetObject, &quot;JavaGuide&quot;); /** * 获取指定参数并对参数进行修改 */ Field field = tagetClass.getDeclaredField(&quot;value&quot;); //为了对类中的参数进行修改我们取消安全检查 field.setAccessible(true); field.set(targetObject, &quot;JavaGuide&quot;); /** * 调用 private 方法 */ Method privateMethod = tagetClass.getDeclaredMethod(&quot;privateMethod&quot;); //为了调用private方法我们取消安全检查 privateMethod.setAccessible(true); privateMethod.invoke(targetObject); &#125;&#125; 输出内容： 1234publicMethodprivateMethodI love JavaGuidevalue is JavaGuide 参考Java反射常见面试题","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"反射","slug":"反射","permalink":"https://xmmarlowe.github.io/tags/%E5%8F%8D%E5%B0%84/"}],"author":"Marlowe"},{"title":"Redis 对比 MySQL，为什么 redis 是快的？","slug":"NoSQL/Redis-对比-MySQL，为什么-redis-是快的？","date":"2021-04-15T15:00:53.000Z","updated":"2021-04-21T05:31:42.888Z","comments":true,"path":"2021/04/15/NoSQL/Redis-对比-MySQL，为什么-redis-是快的？/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/15/NoSQL/Redis-%E5%AF%B9%E6%AF%94-MySQL%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88-redis-%E6%98%AF%E5%BF%AB%E7%9A%84%EF%BC%9F/","excerpt":"","text":"1.Redis是基于内存存储的，MySQL是基于磁盘存储的 2.Redis存储的是k-v格式的数据。时间复杂度是O(1),常数阶，而MySQL引擎的底层实现是B+Tree，时间复杂度是O(logn)，对数阶。Redis会比MySQL快一点点。 3.MySQL数据存储是存储在表中，查找数据时要先对表进行全局扫描或者根据索引查找，这涉及到磁盘的查找，磁盘查找如果是按条点查找可能会快点，但是顺序查找就比较慢；而Redis不用这么麻烦，本身就是存储在内存中，会根据数据在内存的位置直接取出。 4.Redis是单线程的多路复用IO，单线程避免了线程切换的开销，而多路复用IO避免了IO等待的开销，在多核处理器下提高处理器的使用效率可以对数据进行分区，然后每个处理器处理不同的数据。 参考Redis为什么会比MySQL快？","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"},{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"}],"author":"Marlowe"},{"title":"设计模式-装饰器","slug":"设计模式/设计模式-装饰器","date":"2021-04-15T13:36:54.000Z","updated":"2021-04-22T07:47:09.032Z","comments":true,"path":"2021/04/15/设计模式/设计模式-装饰器/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/15/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E5%99%A8/","excerpt":"装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。","text":"装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。 介绍意图： 动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 主要解决： 一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用： 在不想增加很多子类的情况下扩展类。 如何解决： 将具体功能职责划分，同时继承装饰者模式。 关键代码： Component 类充当抽象角色，不应该具体实现。 修饰类引用和继承 Component 类，具体扩展类重写父类方法。 应用实例： 孙悟空有 72 变，当他变成”庙宇”后，他的根本还是一只猴子，但是他又有了庙宇的功能。 不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。 使用场景： 扩展一个类的功能。 动态增加功能，动态撤销。 优缺点及注意优点装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点多层装饰比较复杂。 注意可代替继承。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546package test;/** * @program: leecode1 * @description: 设计模式-装饰器模式 * @author: Marlowe * @create: 2021-04-15 21:44 **/public class DecoratorPattern &#123; public static void main(String[] args) &#123; new RobotDecorator(new FirstRobot()).doMoreThing(); &#125;&#125;interface Robot &#123; void doSomething();&#125;class FirstRobot implements Robot &#123; @Override public void doSomething() &#123; System.out.println(&quot;对话&quot;); System.out.println(&quot;唱歌&quot;); &#125;&#125;class RobotDecorator implements Robot &#123; private Robot robot; public RobotDecorator(Robot robot) &#123; this.robot = robot; &#125; @Override public void doSomething() &#123; robot.doSomething(); &#125; public void doMoreThing() &#123; robot.doSomething(); System.out.println(&quot;做饭&quot;); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://xmmarlowe.github.io/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"装饰器","slug":"装饰器","permalink":"https://xmmarlowe.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"}],"author":"Marlowe"},{"title":"线程上下文切换","slug":"操作系统/线程上下文切换","date":"2021-04-14T14:12:07.000Z","updated":"2021-04-14T14:34:42.811Z","comments":true,"path":"2021/04/14/操作系统/线程上下文切换/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BA%BF%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/","excerpt":"","text":"简介多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是： 当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 上下文切换的原因多线程编程中，我们知道线程间的上下文切换会导致性能问题，那么是什么原因造成的线程间的上下文切换。我们先看一下线程的生命周期，从中看一下找找答案。 线程的五种状态我们都非常清楚：NEW、RUNNABLE、RUNNING、BLOCKED、DEAD，对应的Java中的六种状态分别为：NEW、RUNABLE、BLOCKED、WAINTING、TIMED_WAITING、TERMINADTED。 图中，一个线程从RUNNABLE到RUNNING的过程就是线程的上下文切换，RUNNING状态到BLOCKED、再到RUNNABLE、再从RUNNABLE到RUNNING的过程就是一个上下文切换的过程。 一个线程从RUNNING转为BLOCKED状态时，我们叫做线程的暂停，线程暂停了，这个处理器就会有别的线程来占用，操作系统就会保存相应的上下文，为了这个线程以后再进入RUNNABLE状态时可以接着之前的执行进度继续执行。当线程从BLOCKED状态进入到RUNNABLE时，也就是线程的唤醒，此时线程将获取上次保存的上下文信息。 我们看到，多线程的上下文切换实际上就是多线程两个运行状态的相互切换导致的。 我们知道两种情况可以导致上下文切换： 一种是程序本身触发的切换，这种我们一般称为自发性上下文切换。 另一种是系统或者虚拟机导致的上下文切换，我们称之为非自发性上下文切换。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"上下文","slug":"上下文","permalink":"https://xmmarlowe.github.io/tags/%E4%B8%8A%E4%B8%8B%E6%96%87/"}],"author":"Marlowe"},{"title":"操作系统IO模型","slug":"操作系统/操作系统IO模型","date":"2021-04-12T14:55:40.000Z","updated":"2021-04-14T12:42:09.016Z","comments":true,"path":"2021/04/12/操作系统/操作系统IO模型/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9FIO%E6%A8%A1%E5%9E%8B/","excerpt":"IO模型的分类：主要有同步IO、异步IO、阻塞IO、非阻塞IO…","text":"IO模型的分类：主要有同步IO、异步IO、阻塞IO、非阻塞IO… 操作系统的IO交互模型现代的操作系统对于存储空间都有一套访问限制控制，所以将存储空间分成了用户空间和内核空间。用户空间负责给应用程序使用，应用程序可以访问用户空间内的数据，但是不可以访问内核空间中的数据；而内核程序可以访问计算机的所有存储空间，包括用户空间、内核空间以及硬件设备上的数据。所以当应用程序需要访问硬件设备上的数据或者是内核空间的数据时，就必须要通过内核空间的程序来实现。所以内核空间对外也提供了很多的函数，提供给了应用程序使用，让应用程序可以通过内核程序来访问想要的数据。 整体的IO交互模型如下图示： 下面就以应用程序需要从网卡中读取数据为例，整体IO交互流程主要分成如下几个步骤： 1、应用程序调用内核提供的函数发起请求数据（请求内核函数） 2、内核访问网卡存储空间获取数据（内核获取数据） 3、内核将获取的到数据复制到用户空间（内核复制数据） 4、应用程序从用户空间中获取需要的数据（应用程序获取数据） 操作系统的IO模型IO的类型同步IO应用程序调用内核函数到最终应用程序从用户空间中获取数据的整个流程是需要用户线程一次性完成的那么就是同步IO 异步IO应用程序调用内核函数请求获取数据和最终从用户空间中拿到数据不是一次性完成的，而是先请求数据，等数据全部准备好了之后再获取的就是异步IO 阻塞IO应用程序调用内核函数请求数据，如果此时还没有数据，那么应用程序就一直等待着，直到成功拿到数据为止，此时应用程序线程是一直处于等待状态的，那么就是阻塞IO 非阻塞IO应用程序调用内核函数请求数据，如果此时还没有数据，那么应用程序就不等待先去处理其他事情，过一会再重新尝试请求，直到成功拿到数据为止，此时应用程序不会一直处于等待状态，那么就是非阻塞IO 操作系统IO模型操作系统的IO模型也主要分成同步IO和异步IO两大类，而同步IO又分成了阻塞和非阻塞等类，异步IO不会出现阻塞IO情况，所以异步IO肯定是非阻塞的IO，操作系统IO模型主要分成如下几种类型 tips：操作系统给应用程序提供了recv函数，该函数用于从socket套接字中接收数据，默认情况下会等到网络数据接收完成并复制到用户空间之后才返回结果或者失败之后返回结果，可以通过flags参数设置如果没有数据的话立即返回结果 同步阻塞IO应用程序调用操作系统的recv函数，recv函数默认会等待数据接收完成并复制到用户空间之后返回结果，而如果数据没有准备好的话，那么应用程序就一直处于等待状态，直到有数据返回，此时应用程序的线程处于阻塞状态，无法执行其他操作。 同步非阻塞IO应用程序调用操作系统的recv函数，recv函数设置flags值为立即返回，那么如果内核发现没有数据时就立即返回，应用程序得到结果之后不再等待，而是先处理其他业务，然后轮训不断尝试获取数据，直到数据成功返回，此时应用程序不处于阻塞状态，可以先处理其他操作。 同步多路复用IO应用程序先调用操作系统的select函数或者poll函数或者epoll函数，这几个函数的作用是监听网络套接字上的数据状态，如果有数据可读，那么就通知应用程序，此时应用程序再调用recv函数来读取数据，此时肯定是可以读取到数据的。可以发现多路复用IO的特点是不需要尝试获取数据，而是先开启另外一个线程来监控数据的状态，等到有数据的时候再同步获取数据，而在没数据的时候也是不需要等待的。多路复用IO调用select函数之后也会阻塞进程，但是不会真正的IO操作线程没有被阻塞，所以实质上是同步非阻塞IO。 同步信号驱动IO通过调用sigaction函数注册信号函数，等内核数据准备好了之后会执行信号函数通知应用程序，应用程序此时再调用recv函数同步的获取数据。信号驱动IO和异步IO有点类似，都是异步通知，不同的是信号驱动IO的真正读取数据的操作还是同步操作的。 异步非阻塞IO通过调用aio_read函数，那么内核会先将数据读取好，并且复制到用户空间之后，再执行回调函数通知应用程序，此时应用程序就可以直接从用户空间中读取数据，而不需要再从内核中读取数据了。 总结IO操作主要可以分成两个阶段：1、数据准备阶段；2、数据从内核空间复制到用户空间阶段 而阻塞IO、非阻塞IO、多路复用IO和信号驱动IO只是在第一个阶段不同，而第二个阶段是相同的，都是需要阻塞当前线程等待数据复制完成，虽然阻塞的时间足够短，所以只要需要执行第二阶段的都是属于同步IO； 而异步IO模型的第一阶段和第二阶段都是内核主动完成，再两个阶段都不会阻塞当前线程去处理其他事情。 参考整理操作系统IO模型","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"IO","slug":"IO","permalink":"https://xmmarlowe.github.io/tags/IO/"}],"author":"Marlowe"},{"title":"SpringMVC执行流程及工作原理","slug":"Spring/SpringMVC执行流程及工作原理","date":"2021-04-11T02:09:43.000Z","updated":"2021-04-11T14:34:25.989Z","comments":true,"path":"2021/04/11/Spring/SpringMVC执行流程及工作原理/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/11/Spring/SpringMVC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","excerpt":"","text":"图解SpringMVC执行流程: SpringMVC执行流程 SpringMVC执行流程: 用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求调用处理器映射器HandlerMapping。 处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。 DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作 执行处理器Handler(Controller，也叫页面控制器)。 Handler执行完成返回ModelAndView HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。 DispatcherServlet响应用户。 组件说明： DispatcherServlet：前端控制器。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性,系统扩展性提高。由框架实现 HandlerMapping：处理器映射器。HandlerMapping负责根据用户请求的url找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，根据一定的规则去查找,例如：xml配置方式，实现接口方式，注解方式等。由框架实现 Handler：处理器。Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。 HandlAdapter：处理器适配器。通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。由框架实现。 ModelAndView是springmvc的封装对象，将model和view封装在一起。 ViewResolver：视图解析器。ViewResolver负责将处理结果生成View视图，ViewResolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 View:是springmvc的封装对象，是一个接口, springmvc框架提供了很多的View视图类型，包括：jspview，pdfview,jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/categories/Spring/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://xmmarlowe.github.io/tags/SpringMVC/"}],"author":"Marlowe"},{"title":"虚拟内存","slug":"操作系统/虚拟内存","date":"2021-04-10T11:22:21.000Z","updated":"2021-04-10T11:52:31.225Z","comments":true,"path":"2021/04/10/操作系统/虚拟内存/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","excerpt":"","text":"什么是虚拟内存(Virtual Memory)?这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢？ 正是因为 虚拟内存 的存在，通过 虚拟内存 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。 这样会更加有效地管理内存并减少出错。 虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间。 局部性原理局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。 早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。 局部性原理表现在以下两个方面： 时间局部性： 如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性： 一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://xmmarlowe.github.io/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"}],"author":"Marlowe"},{"title":"IO多路复用","slug":"操作系统/IO多路复用","date":"2021-04-10T11:04:10.000Z","updated":"2021-05-03T12:36:34.745Z","comments":true,"path":"2021/04/10/操作系统/IO多路复用/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","excerpt":"","text":"举例现实场景来理解我们试想一下这样的现实场景: 一个餐厅同时有100位客人到店，当然到店后第一件要做的事情就是点菜。但是问题来了，餐厅老板为了节约人力成本目前只有一位大堂服务员拿着唯一的一本菜单等待客人进行服务。 方法A 无论有多少客人等待点餐，服务员都把仅有的一份菜单递给其中一位客人，然后站在客人身旁等待这个客人完成点菜过程。在记录客人点菜内容后，把点菜记录交给后堂厨师。然后是第二位客人。。。。然后是第三位客人。很明显，只有脑袋被门夹过的老板，才会这样设置服务流程。因为随后的80位客人，再等待超时后就会离店(还会给差评)。 方法B 老板马上新雇佣99名服务员，同时印制99本新的菜单。每一名服务员手持一本菜单负责一位客人(关键不只在于服务员，还在于菜单。因为没有菜单客人也无法点菜)。在客人点完菜后，记录点菜内容交给后堂厨师(当然为了更高效，后堂厨师最好也有100名)。这样每一位客人享受的就是VIP服务咯，当然客人不会走，但是人力成本可是一个大头哦(亏死你)。 方法C 当客人到店后，自己申请一本菜单。想好自己要点的才后，就呼叫服务员。服务员站在自己身边后记录客人的菜单内容。将菜单递给厨师的过程也要进行改进，并不是每一份菜单记录好以后，都要交给后堂厨师。服务员可以记录号多份菜单后，同时交给厨师就行了。那么这种方式，对于老板来说人力成本是最低的；对于客人来说，虽然不再享受VIP服务并且要进行一定的等待，但是这些都是可接受的；对于服务员来说，基本上她的时间都没有浪费，基本上被老板压杆了最后一滴油水。 到店情况: 并发量。到店情况不理想时，一个服务员一本菜单，当然是足够了。所以不同的老板在不同的场合下，将会灵活选择服务员和菜单的配置. 客人: 客户端请求 点餐内容: 客户端发送的实际数据 老板: 操作系统 人力成本: 系统资源 菜单: 文件状态描述符。操作系统对于一个进程能够同时持有的文件状态描述符的个数是有限制的，在linux系统中$ulimit -n查看这个限制值，当然也是可以(并且应该)进行内核参数调整的。 服务员: 操作系统内核用于IO操作的线程(内核线程) 厨师: 应用程序线程(当然厨房就是应用程序进程咯) 餐单传递方式: 包括了阻塞式和非阻塞式两种。 方法A: 阻塞式/非阻塞式 同步IO 方法B: 使用线程进行处理的 阻塞式/非阻塞式 同步IO 方法C: 阻塞式/非阻塞式 多路复用IO 多路复用IO实现目前流程的多路复用IO实现主要包括四种: select、poll、epoll、kqueue。 多路复用IO技术最适用的是“高并发”场景，所谓高并发是指1毫秒内至少同时有上千个连接请求准备好。其他情况下多路复用IO技术发挥不出来它的优势。另一方面，使用JAVA NIO进行功能实现，相对于传统的Socket套接字实现要复杂一些，所以实际应用中，需要根据自己的业务需求进行技术选择。 IO多路复用工作模式epoll 的描述符事件有两种触发模式: LT(level trigger)和 ET(edge trigger)。 LT 模式当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 ET 模式和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 应用场景很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。 select 应用场景select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。 select 可移植性更好，几乎被所有主流平台所支持。 poll 应用场景poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。 epoll 应用场景只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。 select、poll、epoll有什么区别？他们是NIO中多路复用的三种实现机制，是由Linux操作系统提供的。 用户空间和内核空间:操作系统为了保护系统安全，将内核划分为两个部分，一个是用户空间，一个是内核空间。用户空间不能直接访问底层的硬件设备，必须通过内核空间。 文件描述符File Descriptor(FD):是一个抽象的概念，形式上是一个整数，实际上是一个索引值。指向内核中为每个进程维护进程所打开的文件的记录表。当程序打开一个文件或者创建一个文件时，内核就会向进程返回一个FD。Unix,Linux select机制: 会维护一个FD的结合 fd_set。将fd_set从用户空间复制到内核空间，激活socket。x64 2048(数组大小) fd_set是一个数组结构。 Poll机制: 和selecter机制是差不多的， 把fd_ set结构进行了优化，FD集合的大小就突破了操作系统的限制。pollfd结构来代替fd_set, 通过链表实现的。 EPoll: Event Poll.Epoll不再扫描所有的FD，只将用户关心的FD的事件存放到内核的一一个事件表当中。 简单总结 操作方式 底层实现 最大连接数 IO效率 select 遍历 数组 受限于内核 一般 poll 遍历 链表 无上限 一般 epoll 事件回调 红黑树 无上限 高 Java的NIO当中使用的是那种机制？ 可以查看 DefaultSelectorProvider源码。在windows 下，WindowsSelectorProvider。而Linux下，根据Linux的内核版本，2.6版本以上，就是EPollSelectorProvider, 否则就是 默认的PollSelectorProvider。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"IO","slug":"IO","permalink":"https://xmmarlowe.github.io/tags/IO/"}],"author":"Marlowe"},{"title":"RESTful相关面试题","slug":"春招面试/RESTful相关面试题","date":"2021-04-10T10:43:48.000Z","updated":"2021-04-10T11:52:31.232Z","comments":true,"path":"2021/04/10/春招面试/RESTful相关面试题/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/10/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/RESTful%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"RESTful也可以称为“面向资源编程”。","text":"RESTful也可以称为“面向资源编程”。 谈谈对RESTful规范的理解 RESTful是一套编写接口的协议，协议规定如何编写，以及如何设置返回值，状态码等信息。 最显著的特点： RESTful：给用户一个url，根据method不同在后端做不同的处理，比如post 创建数据、get 获取数据、put和patch 修改数据、delete 删除数据。 no REST：给调用者很多url，每个url代表一个功能，比如：add_user/delte_user/edit_user/","categories":[{"name":"春招面试","slug":"春招面试","permalink":"https://xmmarlowe.github.io/categories/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"RESTful","slug":"RESTful","permalink":"https://xmmarlowe.github.io/tags/RESTful/"}],"author":"Marlowe"},{"title":"缺页中断及页面置换算法","slug":"操作系统/缺页中断及页面置换算法","date":"2021-04-10T03:05:43.000Z","updated":"2021-04-10T11:52:31.216Z","comments":true,"path":"2021/04/10/操作系统/缺页中断及页面置换算法/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/10/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD%E5%8F%8A%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/","excerpt":"","text":"缺页中断在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。 缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤： 保护CPU现场 分析中断原因 转入缺页中断处理程序进行处理 恢复CPU现场，继续执行 但是缺页中断时由于所要访问的页面不存在与内存时，有硬件所产生的一种特殊的中断，因此，与一般的中断存在区别： 在指令执行期间产生和处理缺页中断信号 一条指令在执行期间，可能产生多次缺页中断 缺页中断返回时，执行产生中断的那一条指令，而一般的中断返回时，执行下一条指令 页面置换算法进程运行过程中，如果发生缺页中断，而此时内存中有没有空闲的物理块是，为了能够把所缺的页面装入内存，系统必须从内存中选择一页调出到磁盘的对换区。但此时应该把那个页面换出，则需要根据一定的页面置换算法（Page Replacement Algorithm)来确定。 1. 先进先出置换算法（First In First Out, FIFO)置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。但是该算法会淘汰经常访问的页面，不适应进程实际运行的规律，目前已经很少使用。 2.最近最久未使用置换算法（Least Recently Used， LRU)置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。 LRU算法普偏地适用于各种类型的程序，但是系统要时时刻刻对各页的访问历史情况加以记录和更新，开销太大，因此LRU算法必须要有硬件的支持。 Belady异常 一般来说，分配给进程的物理块越多，运行时的缺页次数应该越少，使用FIFO时，可能存在相反情况，分配4个物理块的缺页竟然比3个物理块的缺页次数还多！ 3.最佳置换（Optimal, OPT)置换以后不再被访问，或者在将来最迟才回被访问的页面，缺页中断率最低。但是该算法需要依据以后各业的使用情况，而当一个进程还未运行完成是，很难估计哪一个页面是以后不再使用或在最长时间以后才会用到的页面。所以该算法是不能实现的。但该算法仍然有意义，作为很亮其他算法优劣的一个标准。 4. 最少使用页面置换算法(Least Frequently Used, LFU)该置换算法选择在之前时期使用最少的页面作为淘汰页。 参考缺页中断及页面置换算法","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"缺页中断","slug":"缺页中断","permalink":"https://xmmarlowe.github.io/tags/%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD/"},{"name":"页面置换算法","slug":"页面置换算法","permalink":"https://xmmarlowe.github.io/tags/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"}],"author":"Marlowe"},{"title":"多线程和多进程及其应用场景","slug":"操作系统/多线程和多进程及其应用场景","date":"2021-04-09T14:45:58.000Z","updated":"2021-04-14T13:27:51.154Z","comments":true,"path":"2021/04/09/操作系统/多线程和多进程及其应用场景/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"","text":"多进程多线程的区别 进程是分配资源的基本单位；线程是系统调度和分派的基本单位。 属于同一进程的线程，堆是共享的，栈是私有的。 属于同一进程的所有线程都具有相同的地址空间。 多进程的优点：①编程相对容易；通常不需要考虑锁和同步资源的问题。 ②更强的容错性：比起多线程的一个好处是一个进程崩溃了不会影响其他进程。 ③有内核保证的隔离：数据和错误隔离。 对于使用如C/C++这些语言编写的本地代码，错误隔离是非常有用的：采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。 多线程的优点：①创建速度快，方便高效的数据共享 共享数据：多线程间可以共享同一虚拟地址空间；多进程间的数据共享就需要用到共享内存、信号量等IPC技术。②较轻的上下文切换开销,不用切换地址空间，不用更改寄存器，不用刷新TLB。 ③提供非均质的服务。如果全都是计算任务，但每个任务的耗时不都为1s，而是1ms-1s之间波动；这样，多线程相比多进程的优势就体现出来，它能有效降低“简单任务被复杂任务压住”的概率。 应用场景1. 多进程应用场景 nginx主流的工作模式是多进程模式（也支持多线程模型） 几乎所有的web server服务器服务都有多进程的，至少有一个守护进程配合一个worker进程，例如apached,httpd等等以d结尾的进程包括init.d本身就是0级总进程，所有你认知的进程都是它的子进程； chrome浏览器也是多进程方式。 （原因：①可能存在一些网页不符合编程规范，容易崩溃，采用多进程一个网页崩溃不会影响其他网页；而采用多线程会。②网页之间互相隔离，保证安全，不必担心某个网页中的恶意代码会取得存放在其他网页中的敏感信息。） redis也可以归类到“多进程单线程”模型（平时工作是单个进程，涉及到耗时操作如持久化或aof重写时会用到多个进程） 2. 多线程应用场景 线程间有数据共享，并且数据是需要修改的（不同任务间需要大量共享数据或频繁通信时）。 提供非均质的服务（有优先级任务处理）事件响应有优先级。 单任务并行计算，在非CPU Bound的场景下提高响应速度，降低时延。 与人有IO交互的应用，良好的用户体验（键盘鼠标的输入，立刻响应） 案例：桌面软件，响应用户输入的是一个线程，后台程序处理是另外的线程memcached 3. 如何选择？①需要频繁创建销毁的优先用线程（进程的创建和销毁开销过大）这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的。 ②需要进行大量计算的优先使用线程（CPU频繁切换）所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。这种原则最常见的是图像处理、算法处理。 ③强相关的处理用线程，弱相关的处理用进程什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。 ④可能要扩展到多机分布的用进程，多核分布的用线程 ⑤都满足需求的情况下，用你最熟悉、最拿手的方式至于“数据共享、同步”、“编程、调试”、“可靠性”这几个维度的所谓的“复杂、简单”应该怎么取舍，我只能说：没有明确的选择方法。但我可以告诉你一个选择原则：如果多进程和多线程都能够满足要求，那么选择你最熟悉、最拿手的那个。 实际应用中基本上都是“进程+线程”的结合方式，千万不要真的陷入一种非此即彼的误区。 参考多线程和多进程及其应用场景","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"}],"author":"Marlowe"},{"title":"进程间的通信方式","slug":"操作系统/进程间的通信方式","date":"2021-04-09T14:13:41.000Z","updated":"2021-04-20T14:14:10.757Z","comments":true,"path":"2021/04/09/操作系统/进程间的通信方式/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/","excerpt":"进程间的7种通信方式概述…","text":"进程间的7种通信方式概述… 进程间通信的概念每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication） 进程间通信模型 进程间通信的七种方式管道/匿名管道(Pipes)一句话介绍大白话来说，就是只能在父子间单向传递数据的方式，数据放在内核缓冲区，像FIFO的方式循环队列来存取。管道单独构成一种文件系统，并且只存在与内存中。 特点 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程); 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。 进程间管道通信模型 实质管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。 局限性 只支持单向数据流； 只能用于具有亲缘关系的进程之间； 没有名字； 管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小）； 管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，比如多少字节算作一个消息（或命令、或记录）等等； 有名管道(Names Pipes)一句话介绍与匿名管道一样，但是存在有一个名字，这个名字就是文件路径，存在于文件系统中，但是内容还是在内存，这样就可以非父子进程通信了。 介绍匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道不同于匿名管道之处在于它提供了一个路径名与之关联，以有名管道的文件形式存在于文件系统中，这样，即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循先进先出(first in first out),对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。有名管道的名字存在于文件系统中，内容存放在内存中。 匿名管道和有名管道总结 管道是特殊类型的文件，在满足先入先出的原则条件下可以进行读写，但不能进行定位读写。 匿名管道是单向的，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。 无名管道阻塞问题：无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。 有名管道阻塞问题：有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。 信号信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程回复执行并传递给它为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。 SIGINT：程序终止信号。程序运行过程中，按Ctrl+C键将产生该信号。 信号的生命周期 消息队列(Message Queuing) 消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。 与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。 另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。 特点 消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识. 消息队列允许一个或多个进程向它写入与读取消息. 管道和消息队列的通信数据都是先进先出的原则。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。 消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。 目前主要有两种类型的消息队列：POSIX消息队列以及System V消息队列，系统V消息队列目前被大量使用。系统V消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。 信号量(Semaphores)一句话介绍信号量是⼀个计数器，⽤于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。 实际过程信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。 为了获得共享资源，进程需要执行下列操作： 创建一个信号量：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。 等待一个信号量：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。 挂出一个信号量：该操作将信号量的值加1，也称为V操作。 为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。 信号量与普通整型变量的区别 信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap) ; 来进行访问； 操作也被成为PV原语（P来源于荷兰语proberen”测试”，V来源于荷兰语verhogen”增加”，P表示通过的意思，V表示释放的意思），而普通整型变量则可以在任何语句块中被访问； 信号量与互斥量之间的区别： 互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。 互斥： 是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。 同步： 是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源 互斥量值只能为0/1，信号量值可以为非负整数。也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。 两个进程使用一个二值信号量 两个进程所以用一个Posix有名二值信号量 一个进程两个线程共享基于内存的信号量 共享内存(Shared memory) 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。 套接字(Sockets)套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。 Socket是应用层和传输层之间的桥梁 套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。 参考进程间通信IPC (InterProcess Communication) 操作系统之进程通讯IPC","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程通信","slug":"进程通信","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1/"}],"author":"Marlowe"},{"title":"死锁产生的原因以及产生的必要条件","slug":"操作系统/死锁产生的原因以及产生的必要条件","date":"2021-04-09T05:41:29.000Z","updated":"2021-04-23T14:26:41.304Z","comments":true,"path":"2021/04/09/操作系统/死锁产生的原因以及产生的必要条件/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%AD%BB%E9%94%81%E4%BA%A7%E7%94%9F%E7%9A%84%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E4%BA%A7%E7%94%9F%E7%9A%84%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6/","excerpt":"","text":"死锁产生的原因 系统资源不足。 进程运行推进的顺序不合适。 资源分配不当。 死锁产生的四个必要条件 互斥条件：一个资源每次只能被一个进程使用。 请求与保持条件：一个进程因请求资源而阻塞时，对已经获得的资源保持不放。 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。 如何避免死锁？1. 避免嵌套锁如果您已经持有一个资源，请避免锁定另一个资源。如果只使用一个对象锁，则几乎不可能出现死锁情况。 2. 只锁需要的部分只获对需要的资源加锁，例如在程序中，我们锁定了完整的对象资源，但是如果我们只需要其中一个字段，那么我们应该只锁定那个特定的字段而不是完整的对象。 3. 避免无限期等待如果两个线程使用 thread join 无限期互相等待也会造成死锁，我们可以设定等待的最大时间来避免这种情况。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"死锁","slug":"死锁","permalink":"https://xmmarlowe.github.io/tags/%E6%AD%BB%E9%94%81/"}],"author":"Marlowe"},{"title":"研发高频算法题","slug":"题解/研发高频算法题","date":"2021-04-01T09:08:20.000Z","updated":"2021-05-07T14:34:19.830Z","comments":true,"path":"2021/04/01/题解/研发高频算法题/","link":"","permalink":"https://xmmarlowe.github.io/2021/04/01/%E9%A2%98%E8%A7%A3/%E7%A0%94%E5%8F%91%E9%AB%98%E9%A2%91%E7%AE%97%E6%B3%95%E9%A2%98/","excerpt":"牛客研发最爱考、剑指offer经典题目","text":"牛客研发最爱考、剑指offer经典题目 字符串进制转换题目链接 代码如下： 1234567891011121314151617181920212223242526272829303132333435import java.util.*;public class Solution &#123; /** * 进制转换 * @param M int整型 给定整数 * @param N int整型 转换到的进制 * @return string字符串 */ public String solve (int M, int N) &#123; if(M == 0)&#123; return &quot;0&quot;; &#125; // 存储各进制转换后的字符 String s = &quot;0123456789ABCDEF&quot;; // 判断是否为负数，如果为负数，则需要添加负号 boolean f = false; if(M &lt; 0)&#123; f = true; M = -M; &#125; StringBuilder sb = new StringBuilder(); // 得到进制转换逆序的结果 while(M != 0)&#123; sb.append(s.charAt(M%N)); M /= N; &#125; // 如果是负数，则添加负号 if(f)&#123; sb.append(&quot;-&quot;); &#125; return sb.reverse().toString(); &#125;&#125; 字符串解码题目链接 代码如下： 123456789101112131415161718192021222324252627282930class Solution &#123; public String decodeString(String s) &#123; char[] chars = s.toCharArray(); Deque&lt;Integer&gt; stackNum = new ArrayDeque&lt;&gt;(); Deque&lt;String&gt; stack = new ArrayDeque&lt;&gt;(); StringBuilder sb = new StringBuilder(); int num = 0; for (int i = 0; i &lt; chars.length ; i++) &#123; if (chars[i] &gt;= &#x27;0&#x27; &amp;&amp; chars[i] &lt;= &#x27;9&#x27;) &#123; num = num * 10 + Integer.parseInt(chars[i] + &quot;&quot;); //两位数以上的数字计算 &#125; else if (chars[i] == &#x27;[&#x27;) &#123; stackNum.addLast(num); //不能在上一步加入数字队列，可能会有两位数以上的数字 stack.addLast(sb.toString()); //第一个待处理的字符串 sb = new StringBuilder(); //清空结果 num = 0; &#125; else if (chars[i] == &#x27;]&#x27;) &#123; StringBuilder temp = new StringBuilder(); int n = stackNum.removeLast(); //上一步的结果，从栈弹出 while (n &gt; 0) &#123; temp.append(sb); n--; &#125; sb = new StringBuilder(stack.removeLast() + temp); //更新原来的字符串结果 &#125; else &#123; sb.append(chars[i]); &#125; &#125; return sb.toString(); &#125;&#125; 数组数组中未出现的最小正整数题目链接 代码如下： 12345678910111213141516171819202122232425262728293031public class Solution &#123; /** * return the min number * @param arr int整型一维数组 the array * @return int整型 */ public int minNumberdisappered (int[] arr) &#123; if(arr == null)&#123; return 1; &#125; // 找到连续区间的最小值和最大值 int min = arr[0]; int max = arr[0]; // 求出当前数组和 int sum1 = arr[0]; for(int i = 1; i &lt; arr.length; i++)&#123; min = Math.min(min,arr[i]); max = Math.max(max,arr[i]); sum1 += arr[i]; &#125; // 求出连续区间的和 int sum2 = 0; for(int i = min; i &lt;= max; i++)&#123; sum2 += i; &#125; // 判断两次的值是否相等，相等返回最大值+1，否则计算差值 int num = sum2 - sum1 == 0? max + 1 : sum2 - sum1; // 返回最小正整数 return Math.max(1,num); &#125;&#125; 顺时针旋转矩阵题目链接 代码如下： 12345678910111213141516public class Solution &#123; public int[][] rotateMatrix(int[][] mat, int n) &#123; // 原地旋转，注意循环结束条件 for(int i = 0; i &lt; n / 2; i++)&#123; for(int j = 0; j &lt; (n+1) / 2; j++)&#123; // 依次交换四个位置的值 int tmp = mat[i][j]; mat[i][j] = mat[n - j - 1][i]; mat[n - j - 1][i] = mat[n - i - 1][n - j - 1]; mat[n - i - 1][n - j - 1] = mat[j][n - i - 1]; mat[j][n - i - 1] = tmp; &#125; &#125; return mat; &#125;&#125; 二分查找在转动过的有序数组中寻找目标值题目链接 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.*;public class Solution &#123; /** * * @param A int整型一维数组 * @param target int整型 * @return int整型 */ public int search (int[] A, int target) &#123; // 如果没有翻转，则直接二分查找 if(A[0] &lt; A[A.length - 1])&#123; return bsearch(A,target,0,A.length - 1); &#125; int left = 0; int right = A.length - 1; int mid; // 找到翻转点 while(left &lt;= right)&#123; mid = (left + right) / 2; if(A[mid] &gt;= A[0])&#123; left = mid + 1; &#125;else&#123; right = mid - 1; &#125; &#125; // 如果要查找的值比最左边的大，则在翻转点左边二分查找 if(target &gt;= A[0])&#123; return bsearch(A,target,0,right); &#125;else&#123;// 反之 return bsearch(A,target,left,A.length - 1); &#125; &#125; // 二分查找标准代码 public int bsearch(int[] A,int target,int left, int right)&#123; int mid; while(left &lt;= right)&#123; mid = (left + right) / 2; if(target == A[mid])&#123; return mid; &#125;else if(target &gt; A[mid])&#123; left = mid + 1; &#125;else&#123; right = mid - 1; &#125; &#125; return -1; &#125;&#125; 搜索旋转排序数组题目链接 代码如下： 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; public int search(int[] nums, int target) &#123; int n = nums.length; if(nums == null || n == 0)&#123; return -1; &#125; if(n == 1)&#123; return nums[0] == target ? 0 : -1; &#125; int left = 0; int right = n - 1; while(left &lt;= right)&#123; int mid = left + (right - left) / 2; if(nums[mid] == target)&#123; return mid; &#125; // 左边是有序的 if(nums[0] &lt;= nums[mid])&#123; if(nums[mid] &gt; target &amp;&amp; target &gt;= nums[0])&#123; right = mid - 1; &#125;else&#123; left = mid + 1; &#125; &#125;else&#123; // 右边是有序的 if(nums[mid] &lt; target &amp;&amp; target &lt;= nums[n-1])&#123; left = mid + 1; &#125;else&#123; right = mid - 1; &#125; &#125; &#125; return -1; &#125;&#125; 搜索旋转排序数组 II题目链接 代码如下： 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123; public boolean search(int[] nums, int target) &#123; if(nums == null || nums.length == 0)&#123; return false; &#125; int start = 0; int end = nums.length - 1; while(start &lt;= end)&#123; int mid = start + (end - start) / 2; if(nums[mid] == target)&#123; return true; &#125; // 去掉重复的 if(nums[start] == nums[mid])&#123; start++; continue; &#125; // 左边部分有序 if(nums[start] &lt; nums[mid])&#123; // target在左边 if(nums[mid] &gt; target &amp;&amp; nums[start] &lt;= target)&#123; end = mid - 1; &#125;else&#123; start = mid + 1; &#125; &#125;else&#123; // target在右边 if(nums[mid] &lt; target &amp;&amp; target &lt;= nums[end])&#123; start = mid + 1; &#125;else&#123; end = mid - 1; &#125; &#125; &#125; return false; &#125;&#125; 寻找旋转排序数组中的最小值 II题目链接 代码如下： 12345678910111213141516171819class Solution &#123; public int findMin(int[] nums) &#123; int left= 0; int right = nums.length - 1; while(left &lt;= right)&#123; int mid = left + (right - left) / 2; if(nums[mid] == nums[right])&#123; right--; &#125;else if(nums[mid] &lt; nums[right])&#123; // 中间值比最右边的值小，而中间这个值可能是最小值，所以右指针为mid，不能为mid - 1 right = mid; &#125;else&#123; // 中间值比最右边的值大，因此左指针为mid + 1 left = mid + 1; &#125; &#125; return nums[left]; &#125;&#125; 双指针删除排序数组中的重复项题目链接 代码如下： 1234567891011public int removeDuplicates(int[] nums) &#123; if (nums.length == 0) return 0; int i = 0; for (int j = 1; j &lt; nums.length; j++) &#123; if (nums[j] != nums[i]) &#123; i++; nums[i] = nums[j]; &#125; &#125; return i + 1;&#125; 链表两个链表生成相加链表 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * &#125; */public class Solution &#123; /** * * @param head1 ListNode类 * @param head2 ListNode类 * @return ListNode类 */ public ListNode addInList (ListNode head1, ListNode head2) &#123; // write code here // 将两个链表反转 ListNode p1 = reverse(head1); ListNode p2 = reverse(head2); // 定义结果链表 ListNode res = new ListNode(-1); ListNode curr = res; // 进位 int carry = 0; while(p1 != null || p2 != null)&#123; int sum = 0; if(p1 != null)&#123; sum += p1.val; p1 = p1.next; &#125; if(p2 != null)&#123; sum += p2.val; p2 = p2.next; &#125; // 低位+进位 sum += carry; curr.next = new ListNode(sum % 10); // 从新计算进位 carry = sum / 10; curr = curr.next; &#125; // 如果有进位，直接加到结果链表尾部 if(carry &gt; 0)&#123; curr.next = new ListNode(carry); &#125; // 将结果链表反转 return reverse(res.next); &#125; // 翻转链表 public ListNode reverse(ListNode head)&#123; ListNode pre = null; ListNode next = null; while(head != null)&#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125; 合并k个已排序的链表题目链接 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839import java.util.*;public class Solution &#123; public ListNode mergeKLists(ArrayList&lt;ListNode&gt; lists) &#123; if(lists == null || lists.size() == 0)&#123; return null; &#125; return mergeKList(lists,0,lists.size() - 1); &#125; public ListNode mergeKList(ArrayList&lt;ListNode&gt; lists,int low, int high) &#123; // 左右相等说明不能再分 if(low &gt;= high)&#123; return lists.get(low); &#125; // 计算mid int mid = low + (high - low) / 2; ListNode l1 = mergeKList(lists,low,mid); ListNode l2 = mergeKList(lists,mid + 1,high); return merge(l1,l2); &#125; // 合并两个有序链表 public ListNode merge(ListNode node1,ListNode node2)&#123; ListNode node = new ListNode(-1); ListNode tmp = node; while(node1!=null &amp;&amp; node2!=null)&#123; if(node1.val &lt;= node2.val)&#123; tmp.next = node1; node1 = node1.next; &#125;else&#123; tmp.next = node2; node2 = node2.next; &#125; tmp = tmp.next; &#125; tmp.next = node1!=null?node1:node2; return node.next; &#125;&#125; 单链表的排序题目链接 代码如下(方法1 归并排序)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * &#125; */public class Solution &#123; /** * * @param head ListNode类 the head node * @return ListNode类 */ public ListNode sortInList (ListNode head) &#123; if(head == null || head.next == null)&#123; return head; &#125; // 使用快慢指针找到链表中间部分 ListNode slow = head; ListNode fast = head.next; while(fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; &#125; // 截取第二部分链表 ListNode newList = slow.next; slow.next = null; // 递归继续分割两个链表 ListNode left = sortInList(head); ListNode right = sortInList(newList); // 合并两个有序链表 ListNode dummy = new ListNode(-1); ListNode res = dummy; while(left != null &amp;&amp; right != null)&#123; if(left.val &lt; right.val)&#123; res.next = left; left = left.next; &#125;else&#123; res.next = right; right = right.next; &#125; res = res.next; &#125; res.next = left == null? right : left; return dummy.next; &#125;&#125; 代码如下(方法2 插入排序)： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode insertionSortList(ListNode head) &#123; // 如果头节点为空，直接返回 if(head == null)&#123; return head; &#125; // 新建哑节点，保存头结点信息 ListNode dummy = new ListNode(0); dummy.next = head; // 排序好部分最后一个元素 ListNode lastSorted = head; // 当前节点（待排序元素） ListNode curr = head.next; while(curr != null)&#123; // 如果当前元素不用排序，将排序链表增长，也即lastSorted后移 if(lastSorted.val &lt;= curr.val)&#123; lastSorted = lastSorted.next; &#125;else&#123; // 从头结点开始找，pre保存前一个元素 ListNode pre = dummy; while(pre.next.val &lt;= curr.val)&#123; pre = pre.next; &#125; // 将curr节点插入到对应位置 lastSorted.next = curr.next; curr.next = pre.next; pre.next = curr; &#125; // 更新当前节点为排序好链表下一个节点 curr = lastSorted.next; &#125; return dummy.next; &#125;&#125; 链表内指定区间反转题目链接 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * &#125; */public class Solution &#123; /** * * @param head ListNode类 * @param m int整型 * @param n int整型 * @return ListNode类 */ public ListNode reverseBetween (ListNode head, int m, int n) &#123; ListNode dummy = new ListNode(-1); dummy.next = head; ListNode pre = dummy; for(int i = 0; i &lt; m-1; i++)&#123; pre = pre.next; &#125; // 先获得翻转链表pre部分的头指针 head = pre.next; ListNode next = null; for(int i = m; i &lt; n; i++)&#123; next = head.next; // head节点连接next节点之后链表部分，也就是向后移动一位 head.next = next.next; // next 每次移动到头结点位置 next.next = pre.next; // 翻转部分头结点的前驱指向当前节点 pre.next = next; &#125; return dummy.next; &#125;&#125; 删除有序链表中重复出现的元素题目链接 代码如下： 123456789101112131415161718192021222324252627282930313233public class Solution &#123; /** * * @param head ListNode类 * @return ListNode类 */ public ListNode deleteDuplicates (ListNode head) &#123; ListNode dummy = new ListNode(-1); dummy.next = head; // 前驱结点 ListNode pre = dummy; // 当前结点 ListNode curr = head; while(curr != null &amp;&amp; curr.next != null)&#123; // 如果两个结点相等，说明结点重复 if(curr.val == curr.next.val)&#123; // 找到最后一个不重复的结点 ListNode tmp = curr.next; while(tmp != null &amp;&amp; tmp.val == curr.val)&#123; tmp = tmp.next; &#125; // 将当前前驱结点接最后一个不重复的结点后面 pre.next = tmp; // 更新当前结点 curr = tmp; &#125;else&#123; pre = pre.next; curr = curr.next; &#125; &#125; return dummy.next; &#125;&#125; 链表的奇偶重排题目链接 代码如下： 12345678910111213141516171819202122232425262728public class Solution &#123; /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param head ListNode类 * @return ListNode类 */ public ListNode oddEvenList (ListNode head) &#123; if(head == null)&#123; return head; &#125; ListNode evenHead = head.next; ListNode odd = head; ListNode even = evenHead; while(even != null &amp;&amp; even.next != null)&#123; // 获得奇数结点 odd.next = even.next; odd = odd.next; // 获得偶数结点 even.next = odd.next; even = even.next; &#125; // 将奇数结点和偶数结点链接起来 odd.next = evenHead; return head; &#125;&#125; 重排链表题目链接 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; public void reorderList(ListNode head) &#123; if(head == null || head.next == null || head.next.next == null) return; // 将链表分成两个部分 ListNode slow = head; ListNode fast = head.next; while(fast != null &amp;&amp; fast.next != null)&#123; slow = slow.next; fast = fast.next.next; &#125; ListNode newList = slow.next; slow.next = null; // 将第二部分链表反转 ListNode newHead = reverse(newList); // 合并两个链表 while(newHead != null)&#123; ListNode temp = newHead.next; newHead.next = head.next; head.next = newHead; head = newHead.next; newHead = temp; &#125; &#125; // 反转链表 public ListNode reverse(ListNode head)&#123; ListNode pre = null; while(head != null)&#123; ListNode next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125; K 个一组翻转链表题目链接 代码如下： 1234567891011121314151617181920212223242526272829class Solution &#123; public ListNode reverseKGroup(ListNode head, int k) &#123; if(head == null || head.next == null)&#123; return head; &#125; ListNode tail = head; for(int i = 0; i &lt; k; i++)&#123; if(tail == null)&#123; return head; &#125; tail = tail.next; &#125; ListNode newNode = reverse(head,tail); head.next = reverseKGroup(tail,k); return newNode; &#125; public ListNode reverse(ListNode head,ListNode tail)&#123; ListNode pre = null; ListNode next = null; while(head != tail)&#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125; 大数加法 代码如下： 123456789101112131415161718192021222324252627import java.util.*;public class Solution &#123; /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * 计算两个数之和 * @param s string字符串 表示第一个整数 * @param t string字符串 表示第二个整数 * @return string字符串 */ public String solve (String s, String t) &#123; // write code here int i = s.length() - 1; int j = t.length() - 1; int carry = 0; StringBuilder sb = new StringBuilder(); while(i &gt;= 0 || j &gt;= 0 || carry != 0)&#123; int x = i &lt; 0 ? 0 : s.charAt(i--) - &#x27;0&#x27;; int y = j &lt; 0 ? 0 : t.charAt(j--) - &#x27;0&#x27;; int sum = x + y + carry; sb.append(sum % 10); carry = sum / 10; &#125; return sb.reverse().toString(); &#125;&#125; 二叉树重建二叉树 代码如下： 123456789101112131415161718192021222324import java.util.*;public class Solution &#123; public TreeNode reConstructBinaryTree(int [] pre,int [] in) &#123; Map&lt;Integer,Integer&gt; map = new HashMap(); for(int i = 0; i &lt; in.length; i++)&#123; map.put(in[i],i); &#125; return dfs(0,pre.length - 1,0,in.length - 1,pre,in,map); &#125; public TreeNode dfs(int pl,int pr,int il,int ir,int[] pre,int[] in,Map&lt;Integer,Integer&gt; map)&#123; if(pl &gt; pr)&#123; return null; &#125; // 根据先序遍历获得根节点 int k = map.get(pre[pl]); TreeNode root = new TreeNode(pre[pl]); // 递归构造左子树 root.left = dfs(pl + 1,pl + k -il,il,k-1,pre,in,map); // 递归构造右子树 root.right = dfs(pl + k- il + 1,pr,k+1,ir,pre,in,map); return root; &#125;&#125; 在二叉树中找到两个节点的最近公共祖先 以下图片来自于牛客￥ABCDEF题解代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.*;/* * public class TreeNode &#123; * int val = 0; * TreeNode left = null; * TreeNode right = null; * &#125; */public class Solution &#123; /** * * @param root TreeNode类 * @param o1 int整型 * @param o2 int整型 * @return int整型 */ public int lowestCommonAncestor (TreeNode root, int o1, int o2) &#123; // write code here return dfs(root,o1,o2).val; &#125; public TreeNode dfs(TreeNode root ,int o1,int o2)&#123; // 如果当前节点为空，或者当前节点等于o1或者等于o2就返回值给父亲节点 if(root == null || root.val == o1 || root.val == o2)&#123; return root; &#125; // 递归遍历左子树 TreeNode left = dfs(root.left,o1,o2); // 递归遍历右子树 TreeNode right = dfs(root.right,o1,o2); // 如果left、right都不为空，那么代表o1、o2在root的两侧，所以root为他们的公共祖先 if(left != null &amp;&amp; right != null)&#123; return root; &#125; // 如果left、right有一个为空，那么就返回不为空的那一个 return left == null? right : left; &#125;&#125; 对称的二叉树题目链接 代码如下： 123456789101112131415161718192021222324252627/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; return root == null ? true : recur(root.left,root.right); &#125; public boolean recur(TreeNode A,TreeNode B)&#123; // 左右子树都为空，则树是对称的 if(A == null &amp;&amp; B == null)&#123; return true; &#125; // 只有一边为空，且值不相等，则不对称 if(A == null || B == null || A.val != B.val)&#123; return false; &#125; // 递归判断左右子树，如果都对称，则树对称 return recur(A.left,B.right) &amp;&amp; recur(A.right,B.left); &#125;&#125; 二叉树的右视图题目链接 代码如下： 123456789101112131415161718192021222324252627class Solution &#123; public List&lt;Integer&gt; rightSideView(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList(); if(root == null)&#123; return res; &#125; Queue&lt;TreeNode&gt; q = new LinkedList(); q.offer(root); while(!q.isEmpty())&#123; int size = q.size(); for(int i = 0; i &lt; size; i++)&#123; TreeNode node = q.poll(); if(node.left != null)&#123; q.offer(node.left); &#125; if(node.right != null)&#123; q.offer(node.right); &#125; // 将每一层的最后一个加入结果集,即为右视图 if(i == size - 1)&#123; res.add(node.val); &#125; &#125; &#125; return res; &#125;&#125; 二叉树根节点到叶子节点和为指定值的路径题目链接 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.*;/* * public class TreeNode &#123; * int val = 0; * TreeNode left = null; * TreeNode right = null; * &#125; */public class Solution &#123; /** * * @param root TreeNode类 * @param sum int整型 * @return int整型ArrayList&lt;ArrayList&lt;&gt;&gt; */ ArrayList&lt;ArrayList&lt;Integer&gt;&gt; res = new ArrayList(); ArrayList&lt;Integer&gt; tmp = new ArrayList(); public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; pathSum (TreeNode root, int sum) &#123; dfs(root,sum,0); return res; &#125; public void dfs(TreeNode root, int sum,int cnt)&#123; if(root == null)&#123; return; &#125; // 如果节点为空结束当前递归 tmp.add(root.val); // 把当前节点加入到路径和中 cnt += root.val; // 如果找到叶子节点 if(root.left == null &amp;&amp; root.right == null)&#123; // 如果找到结果，将tmp加入结果集res if(sum == cnt)&#123; res.add(new ArrayList(tmp)); &#125; &#125;else&#123; // 递归左子树 dfs(root.left,sum,cnt); // 递归右子树 dfs(root.right,sum,cnt); &#125; // 移除最后一个元素 tmp.remove(tmp.size() - 1); &#125;&#125; 二叉树根节点到叶子结点的所有路径和题目链接 代码如下： 12345678910111213141516171819202122232425262728public class Solution &#123; /** * * @param root TreeNode类 * @return int整型 */ public int sumNumbers (TreeNode root) &#123; if(root == null)&#123; return 0; &#125; return dfs(root,0); &#125; public int dfs(TreeNode root, int sum)&#123; if(root == null)&#123; return 0; &#125;else&#123; sum = sum * 10 + root.val; if(root.left == null &amp;&amp; root.right == null)&#123; return sum; &#125;else&#123; // 直接将同级的叶子结点加起来 return dfs(root.left,sum) + dfs(root.right,sum); &#125; &#125; &#125;&#125; 二叉树从根节点到叶子结点路径问题使用回溯求出所有路径，再根据具体题目要求筛选结果代码如下： 12345678910111213141516171819202122232425class Solution &#123; List&lt;List&lt;Integer&gt;&gt; ret = new LinkedList&lt;List&lt;Integer&gt;&gt;(); Deque&lt;Integer&gt; path = new LinkedList&lt;Integer&gt;(); public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root) &#123; dfs(root); return ret; &#125; public void dfs(TreeNode root) &#123; if (root == null) &#123; return; &#125; // 将当前结点加入路径中 path.offerLast(root.val); // 如果到达最底部，说明该路径 if (root.left == null &amp;&amp; root.right == null) &#123; ret.add(new LinkedList&lt;Integer&gt;(path)); &#125; dfs(root.left); dfs(root.right); // 回到上一状态 path.pollLast(); &#125;&#125; 二叉树的最大路径和题目链接 代码如下： 123456789101112131415161718192021222324252627282930313233public class Solution &#123; /** * * @param root TreeNode类 * @return int整型 */ private int Max = Integer.MIN_VALUE; public int maxPathSum (TreeNode root) &#123; dfs(root); return Max; &#125; public int dfs(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; int left = dfs(root.left); int right = dfs(root.right); int curr = root.val; // 如果左右子树大于0，则更新当前最大值 if(left &gt; 0)&#123; curr += left; &#125; if(right &gt; 0)&#123; curr += right; &#125; // 更新当前最大值 Max = Math.max(Max,curr); // 返回最大值 return Math.max(root.val,Math.max(left,right) + root.val); &#125;&#125; 动态规划子数组的最大累加和问题 以下图片来自于牛客￥ABCDEF题解 代码如下： 123456789101112131415161718192021222324252627import java.util.*;public class Solution &#123; /** * max sum of the subarray * @param arr int整型一维数组 the array * @return int整型 */ public int maxsumofSubarray (int[] arr) &#123; // write code here //dp[i]代表到第i位的时侯,以arr[i]结尾的连续子数组最大累加和 int[] dp = new int[arr.length]; dp[0] = arr[0]; int res = arr[0]; for(int i = 1; i&lt; arr.length; i++)&#123; // 如果前面的子数组和大于0，则更新当前位置 if(dp[i-1] &gt; 0)&#123; dp[i] = dp[i-1] + arr[i]; &#125;else&#123; // 否则，更新当前dp值为当前数组值 dp[i] = arr[i]; &#125; res = Math.max(res,dp[i]); &#125; return res; &#125;&#125; 最长递增子序列1. 题目链接 代码如下: 1 2.题目链接 代码如下： 123456789101112131415161718192021222324class Solution &#123; public int lengthOfLIS(int[] nums) &#123; int n = nums.length; // dp数组表示以nums[1]结尾的“最长上升子序列”的长度 int[] dp = new int[n]; // 初始化dp数组为1 Arrays.fill(dp,1); for(int i = 1; i &lt; n; i++)&#123; // 下标为i以前上升子序列 for(int j= 0; j &lt; i; j++)&#123; if(nums[j] &lt; nums[i])&#123; // 根据状态转换图更新最长上升子序列的长度 dp[i] = Math.max(dp[i],dp[j] + 1); &#125; &#125; &#125; // 找到最大值 int max = 0; for(int i = 0; i &lt; n; i++)&#123; max = Math.max(max,dp[i]); &#125; return max; &#125;&#125; 最长公共子序列（返回值为子序列的长度）题目链接 代码如下： 12345678910111213141516171819class Solution &#123; public int longestCommonSubsequence(String text1, String text2) &#123; int m = text1.length(); int n = text2.length(); int[][] dp = new int[m+1][n+1]; for(int i = 1; i &lt;= m; i++)&#123; char ch1 = text1.charAt(i-1); for(int j = 1; j &lt;= n; j++)&#123; char ch2 = text2.charAt(j-1); if(ch1 == ch2)&#123; dp[i][j] = dp[i-1][j-1] + 1; &#125;else&#123; dp[i][j] = Math.max(dp[i-1][j],dp[i][j-1]); &#125; &#125; &#125; return dp[m][n]; &#125;&#125; 最长公共子序列（返回值为子序列）题目链接 代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.*;public class Solution &#123; /** * longest common subsequence * @param s1 string字符串 the string * @param s2 string字符串 the string * @return string字符串 */ public String LCS (String s1, String s2) &#123; int len1 = s1.length(); int len2 = s2.length(); int[][] dp = new int[len1 + 1][len2 + 1]; for(int i = 1; i &lt;= len1; i++)&#123; for(int j = 1; j &lt;= len2; j++)&#123; if(s1.charAt(i-1) == s2.charAt(j-1))&#123; dp[i][j] = dp[i-1][j-1] + 1; &#125;else&#123; dp[i][j] = Math.max(dp[i-1][j],dp[i][j-1]); &#125; &#125; &#125; // 从末尾开始向前找 StringBuilder sb = new StringBuilder(); int a = len1; int b = len2; while(a != 0 &amp;&amp; b != 0)&#123; // 如果是公共子串 if(s1.charAt(a-1) == s2.charAt(b-1))&#123; // 加入结果集 sb.append(s1.charAt(a-1)); a--; b--; &#125;else&#123; // 从上面来 if(dp[a-1][b] &gt; dp[a][b-1])&#123; a--; &#125;else&#123; // 从下面来 b--; &#125; &#125; &#125; if(sb.length() == 0)&#123; return &quot;-1&quot;; &#125;else&#123; return sb.reverse().toString(); &#125; &#125;&#125; 买卖股票的最佳时机题目链接 123456789101112131415161718192021222324import java.util.*;public class Solution &#123; /** * * @param prices int整型一维数组 * @return int整型 */ public int maxProfit (int[] prices) &#123; int min = Integer.MAX_VALUE; int maxProfit = 0; for(int i = 0; i &lt; prices.length; i++)&#123; // 记录历史最低价 if(prices[i] &lt; min)&#123; min = prices[i]; &#125;else if(prices[i] - min &gt; maxProfit)&#123; // 更新最大收益 maxProfit = prices[i] - min; &#125; &#125; return maxProfit; &#125;&#125; 买卖股票的最佳时机 II题目链接 代码如下： 1 编辑距离题目链接 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.*;public class Solution &#123; /** * min edit cost * @param str1 string字符串 the string * @param str2 string字符串 the string * @param ic int整型 insert cost * @param dc int整型 delete cost * @param rc int整型 replace cost * @return int整型 */ public int minEditCost (String str1, String str2, int ic, int dc, int rc) &#123; int m = str1.length(); int n = str2.length(); int[][] dp = new int[m+1][n+1]; // 初始化第一行 for(int j = 1; j &lt;= n; j++)&#123; dp[0][j] = j * ic; &#125; // 初始化第一列 for(int i = 1; i &lt;= m; i++)&#123; dp[i][0] = i * dc; &#125; for(int i = 1; i &lt;= m; i++)&#123; for(int j = 1; j &lt;= n; j++)&#123; if(str1.charAt(i-1) == str2.charAt(j-1))&#123; dp[i][j] = dp[i-1][j-1]; &#125;else&#123; // 将i个字符串转变为前j-1个字符串在插入第j个字符 int insert = dp[i][j-1] + ic; // 将i-1个字符串转换为前j个字符串删除第i个字符 int delete = dp[i-1][j] + dc; int replace = dp[i-1][j-1] + rc; dp[i][j] = Math.min(Math.min(insert,delete),replace); &#125; &#125; &#125; return dp[m][n]; &#125;&#125; 零钱兑换题目链接 中心扩散法最长回文子串 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.*;public class Solution &#123; public int getLongestPalindrome(String A, int n) &#123; int len = A.length(); if(len &lt; 2)&#123; return A.length(); &#125; int max = 0; for(int i = 0; i &lt; len - 1; i++)&#123; // 回文类型为奇数型 String s1 = helper(A,i,i); // 回文类型为偶数型 String s2 = helper(A,i,i+1); // 求出最长的回文串 String s3 = s1.length() &gt; s2.length()? s1: s2; if(max &lt; s3.length())&#123; max = s3.length(); &#125; &#125; return max; &#125; public String helper(String s, int left, int right)&#123; int len = s.length(); int i = left; int j = right; // 从中间向两边扩散 while(i &gt;= 0 &amp;&amp; j &lt; len)&#123; if(s.charAt(i) == s.charAt(j))&#123; i--; j++; &#125;else&#123; break; &#125; &#125; // 截取回文串 return s.substring(i+1,j); &#125; &#125; 单调栈直方图的水量(接雨水)题目链接 代码如下(双指针)： 12345678910111213141516171819202122232425class Solution &#123; public int trap(int[] height) &#123; int left = 0; int right = height.length - 1; int ans = 0; int leftMax = 0; int rightMax = 0; while(left &lt; right)&#123; // 更新左边的最大值 leftMax = Math.max(leftMax,height[left]); // 更新右边的最大值 rightMax = Math.max(rightMax,height[right]); if(height[left] &lt; height[right])&#123; // 用左边的最大值减去当前高度 ans += leftMax - height[left]; left++; &#125;else&#123; // 用右边的最大值减去当前高度 ans += rightMax - height[right]; right--; &#125; &#125; return ans; &#125;&#125; 代码如下(单调栈): 1234567891011121314151617181920class Solution &#123; public int trap(int[] height) &#123; int ans = 0; Deque&lt;Integer&gt; stack = new LinkedList(); for(int i = 0; i &lt; height.length; i++)&#123; while(!stack.isEmpty() &amp;&amp; height[i] &gt; height[stack.peek()] )&#123; int top = stack.pop(); if(stack.isEmpty())&#123; break; &#125; int left = stack.peek(); int width = i - left - 1; int currHeight = Math.min(height[i],height[left]) - height[top]; ans += currHeight * width; &#125; stack.push(i); &#125; return ans; &#125;&#125; 柱状图中最大的矩形题目链接 123456789101112131415161718192021222324252627282930313233343536public int largestRectangleArea(int[] heights) &#123; // 初始化最终结果为0 int res = 0; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); // 将给定的原数组左右各添加一个元素0 int[] newHeights = new int[heights.length + 2]; newHeights[0] = 0; newHeights[newHeights.length-1] = 0; for (int i = 1; i &lt; heights.length + 1; i++) &#123; newHeights[i] = heights[i - 1]; &#125; // 开始遍历 for (int i = 0; i &lt; newHeights.length; i++) &#123; // 如果栈不为空且当前考察的元素值小于栈顶元素值， // 则表示以栈顶元素值为高的矩形面积可以确定 while (!stack.isEmpty() &amp;&amp; newHeights[i] &lt; newHeights[stack.peek()]) &#123; // 弹出栈顶元素 int cur = stack.pop(); // 获取栈顶元素对应的高 int curHeight = newHeights[cur]; // 栈顶元素弹出后，新的栈顶元素就是其左侧边界 int leftIndex = stack.peek(); // 右侧边界是当前考察的索引 int rightIndex = i; // 计算矩形宽度 int curWidth = rightIndex - leftIndex - 1; // 计算面积 res = Math.max(res, curWidth * curHeight); &#125; // 当前考察索引入栈 stack.push(i); &#125; return res; &#125; 去除重复字母题目链接 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; public String removeDuplicateLetters(String s) &#123; int len = s.length(); char[] ss = s.toCharArray(); // 记录当前字符是否在栈中出现 boolean[] visited = new boolean[26]; // 记录每个元素最后出现的位置，用来判断当前元素是否可能在后面的元素中出现，如果出现则丢弃当前元素 int[] lastIndex = new int[26]; for(int i = 0; i &lt; len; i++)&#123; lastIndex[ss[i] - &#x27;a&#x27;] = i; &#125; Deque&lt;Character&gt; stack = new ArrayDeque(); for(int i = 0; i &lt; len; i++)&#123; // 判断当前元素是否在栈中出现，如果出现则跳过 if(visited[ss[i] - &#x27;a&#x27;])&#123; continue; &#125; // 如果栈不为空且不满足递增且栈顶元素会在后面出现 while(!stack.isEmpty() &amp;&amp; stack.peekLast() &gt; ss[i] &amp;&amp; lastIndex[stack.peekLast() - &#x27;a&#x27;] &gt; i)&#123; char ch = stack.pollLast(); // 栈中不存在该元素 visited[ch - &#x27;a&#x27;] = false; &#125; stack.offerLast(ss[i]); // 栈中存在该元素 visited[ss[i] - &#x27;a&#x27;] = true; &#125; StringBuilder sb = new StringBuilder(); for(char c : stack)&#123; sb.append(c); &#125; return sb.toString(); &#125;&#125; 拼接最大数拼接最大数 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990class Solution &#123; public int[] maxNumber(int[] nums1, int[] nums2, int k) &#123; int len1 = nums1.length; int len2 = nums2.length; int[] preMax = new int[k]; for(int i = 0; i &lt;= k; i++)&#123; if(i &gt; len1 || k - i &gt; len2)&#123; continue; &#125; // 用单调栈求出最优子序列 int[] max1 = minStack(nums1,i); // 用单调栈求出最优子序列 int[] max2 = minStack(nums2,k-i); // 合并两个数组 int[] tmp = mergeArray(max1,max2); // 更新最优解 if(compare(tmp,0,preMax,0) &gt; 0)&#123; System.arraycopy(tmp, 0, preMax, 0, k); &#125; &#125; return preMax; &#125; // 用单调栈求出最优子序列（核心部分） public static int[] minStack(int[] nums, int k) &#123; int n = nums.length; int[] res = new int[k]; Deque&lt;Integer&gt; stack = new ArrayDeque(); int index = 0; while (index &lt; n) &#123; // 如果栈为空或者栈顶元素大于当前元素 while (index &lt; n &amp;&amp; (stack.isEmpty() || stack.peekLast() &gt;= nums[index])) &#123; // 将当前元素入栈 stack.offerLast(nums[index++]); &#125; // 如果元素已经使用完，跳出循环 if (index == n) &#123; break; &#125; // 当栈不为空且栈顶元素小于当前元素并且栈内元素加上未使用的元素大于等于k while (!stack.isEmpty() &amp;&amp; stack.peekLast() &lt; nums[index] &amp;&amp; stack.size() + n - index - 1 &gt;= k) &#123; // 弹出栈顶元素 stack.pollLast(); &#125; // 将当前元素加入栈 stack.offerLast(nums[index++]); &#125; // 获得结果集 for (int i = 0; i &lt; k; i++) &#123; res[i] = stack.pollFirst(); &#125; return res; &#125; // 合并两个数组 public int[] mergeArray(int[] subsequence1, int[] subsequence2) &#123; int x = subsequence1.length, y = subsequence2.length; if (x == 0) &#123; return subsequence2; &#125; if (y == 0) &#123; return subsequence1; &#125; int mergeLength = x + y; int[] merged = new int[mergeLength]; int index1 = 0, index2 = 0; for (int i = 0; i &lt; mergeLength; i++) &#123; if (compare(subsequence1, index1, subsequence2, index2) &gt; 0) &#123; merged[i] = subsequence1[index1++]; &#125; else &#123; merged[i] = subsequence2[index2++]; &#125; &#125; return merged; &#125; // 比较方法 public int compare(int[] subsequence1, int index1, int[] subsequence2, int index2) &#123; int x = subsequence1.length, y = subsequence2.length; while (index1 &lt; x &amp;&amp; index2 &lt; y) &#123; int difference = subsequence1[index1] - subsequence2[index2]; if (difference != 0) &#123; return difference; &#125; index1++; index2++; &#125; return (x - index1) - (y - index2); &#125;&#125; 栈设计getMin功能的栈题目链接 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.*;public class Solution &#123; public Deque&lt;Integer&gt; s = new LinkedList(); public Deque&lt;Integer&gt; min_s = new LinkedList(); /** * return a array which include all ans for op3 * @param op int整型二维数组 operator * @return int整型一维数组 */ public int[] getMinStack (int[][] op) &#123; List&lt;Integer&gt; res = new ArrayList(); for(int i = 0; i &lt; op.length; i++)&#123; if(op[i][0] == 1)&#123; Push(op[i][1]); &#125;else if(op[i][0] == 2)&#123; Pop(); &#125;else&#123; res.add(getMin()); &#125; &#125; int[] ans = new int[res.size()]; for(int i = 0; i &lt; ans.length; i++)&#123; ans[i] = res.get(i); &#125; return ans; &#125; // 如果最小栈为空，或者栈顶元素大于x，则加入最小栈 public void Push(int x)&#123; s.push(x); if(min_s.isEmpty() || min_s.peek() &gt; x)&#123; min_s.push(x); &#125; &#125; // 如果最小栈栈顶元素和栈s中要出栈的元素相等，那么也需要出栈 public void Pop()&#123; if(!s.isEmpty())&#123; if(s.peek().equals(min_s.peek()))&#123; min_s.pop(); &#125; s.pop(); &#125; &#125; // 获得最小栈栈顶元素 public int getMin()&#123; return min_s.peek(); &#125;&#125; 用两个栈实现队列题目链接 12345678910111213141516171819202122232425262728class CQueue &#123; Deque&lt;Integer&gt; stack1; Deque&lt;Integer&gt; stack2; public CQueue() &#123; stack1 = new LinkedList&lt;Integer&gt;(); stack2 = new LinkedList&lt;Integer&gt;(); &#125; public void appendTail(int value) &#123; stack1.push(value); &#125; public int deleteHead() &#123; // 如果第二个栈为空 if (stack2.isEmpty()) &#123; while (!stack1.isEmpty()) &#123; stack2.push(stack1.pop()); &#125; &#125; if (stack2.isEmpty()) &#123; return -1; &#125; else &#123; int deleteItem = stack2.pop(); return deleteItem; &#125; &#125;&#125; 回溯字符串的排列题目链接 代码入下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.util.*;public class Solution &#123; public ArrayList&lt;String&gt; Permutation(String str) &#123; int len = str.length(); char[] strs = str.toCharArray(); // 对字符数组排序 Arrays.sort(strs); ArrayList&lt;String&gt; res = new ArrayList(); // 存放路径 Deque&lt;Character&gt; path = new ArrayDeque(); // 保存该字符是否用过 boolean[] used = new boolean[len]; // 深度有限遍历求得所有结果集 dfs(strs,len,0,used,res,path); return res; &#125; public void dfs(char[] strs,int len,int depth,boolean[] used,ArrayList&lt;String&gt; res,Deque&lt;Character&gt; path)&#123; // 如果到达最深的一层 if(len == depth)&#123; // 封装结果 StringBuilder sb = new StringBuilder(); for(char ch : path)&#123; sb.append(ch); &#125; res.add(new String(sb)); return; &#125; for(int i = 0; i &lt; len; i++)&#123; // 判断当前字符是否用过 if(used[i])&#123; continue; &#125; // 因为有重复元素，所以在下一层碰到相同元素将会使结果重复，相对于全排列，进一步剪枝 if(i &gt; 0 &amp;&amp; strs[i] == strs[i-1] &amp;&amp; !used[i-1])&#123; continue; &#125; // 回溯算法经典步骤 // 先将当前字符加入栈，并将使用过的元素标记为true path.addLast(strs[i]); used[i] = true; dfs(strs,len,depth + 1,used,res,path); // 回到之前的状态 path.removeLast(); used[i] = false; &#125; &#125;&#125; 全排列 II题目链接 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123; // 数组长度 int len = nums.length; Arrays.sort(nums); // 结果集 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 双端队列，保存临时路径 Deque&lt;Integer&gt; path = new ArrayDeque(); // 布尔数组，保存改数字是否使用过 boolean[] used = new boolean[len]; // 深度优先遍历求所有结果集 dfs(nums,len,0,used,path,res); return res; &#125; public void dfs(int[] nums,int len,int depth,boolean[] used,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; // 如果到达最深的一层 if(depth == len)&#123; // 将当前路径加入结果集 res.add(new ArrayList(path)); return; &#125; for(int i = 0 ; i &lt; len; i++)&#123; // 判断当前数字是否用过 if(used[i])&#123; continue; &#125; // 因为有重复元素，所以在下一层碰到相同元素将会使结果重复，相对于全排列，进一步剪枝 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) &#123; continue; &#125; // 回溯算法经典步骤 // 先将当前数字加入栈，并将使用过的元素标记为true path.addLast(nums[i]); used[i] = true; dfs(nums,len,depth + 1,used,path,res); // 回到之前的状态 path.removeLast(); used[i] = false; &#125; &#125;&#125; 括号生成题目链接 代码如下： 1234567891011121314151617181920212223242526public class Solution &#123; /** * * @param n int整型 * @return string字符串ArrayList */ public ArrayList&lt;String&gt; generateParenthesis (int n) &#123; ArrayList&lt;String&gt; res = new ArrayList(); backtrack(&quot;&quot;,0,0,n,res); return res; &#125; public void backtrack(String s,int open,int close,int n, List&lt;String&gt; res)&#123; // 如果长度够了，加入结果集 if(s.length() == n &lt;&lt; 1)&#123; res.add(s); return; &#125; if(open &lt; n)&#123; backtrack(s + &quot;(&quot;,open + 1,close,n,res); &#125; if(close &lt; open)&#123; backtrack(s + &quot;)&quot;,open,close + 1, n ,res); &#125; &#125;&#125; DFS剑指 Offer 12. 矩阵中的路径题目链接 代码如下： 1234567891011121314151617181920212223242526class Solution &#123; public boolean exist(char[][] board, String word) &#123; char[] words = word.toCharArray(); for(int i = 0; i &lt; board.length; i++)&#123; for(int j = 0; j &lt; board[i].length; j++)&#123; if(dfs(board,words,i,j,0))&#123; return true; &#125; &#125; &#125; return false; &#125; public boolean dfs(char[][] board,char[] words,int i, int j, int k)&#123; if(i &gt;= board.length || i &lt; 0 || j &gt;= board[0].length || j &lt; 0 || board[i][j] != words[k])&#123; return false; &#125; if( k == words.length - 1)&#123; return true; &#125; board[i][j] = &#x27;\\0&#x27;; boolean res = dfs(board,words,i+1,j,k+1) || dfs(board,words,i-1,j,k+1) || dfs(board,words,i,j+1,k+1) ||dfs(board,words,i,j-1,k+1); board[i][j] = words[k]; return res; &#125;&#125; 合并区间题目链接 代码入下： 123456789101112131415161718192021222324252627282930313233343536/** * Definition for an interval. * public class Interval &#123; * int start; * int end; * Interval() &#123; start = 0; end = 0; &#125; * Interval(int s, int e) &#123; start = s; end = e; &#125; * &#125; */import java.util.*;public class Solution &#123; public ArrayList&lt;Interval&gt; merge(ArrayList&lt;Interval&gt; intervals) &#123; ArrayList&lt;Interval&gt; res = new ArrayList(); // 根据节点左边从小到大排序 Collections.sort(intervals,(a,b)-&gt;&#123; return a.start - b.start; &#125;); int i = 0; int n = intervals.size(); while(i &lt; n)&#123; // 获得当前节点的左右端点 int left = intervals.get(i).start; int right = intervals.get(i).end; // 如果下一节点的左端点小于等于当前节点右端 while(i &lt; n - 1 &amp;&amp; intervals.get(i+1).start &lt;= right)&#123; // 更新右端点的值 right = Math.max(right,intervals.get(i+1).end); i++; &#125; // 将当前区间加入结果集 res.add(new Interval(left,right)); i++; &#125; return res; &#125;&#125;","categories":[{"name":"题解","slug":"题解","permalink":"https://xmmarlowe.github.io/categories/%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"https://xmmarlowe.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"数组","slug":"数组","permalink":"https://xmmarlowe.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"dp","slug":"dp","permalink":"https://xmmarlowe.github.io/tags/dp/"}],"author":"Marlowe"},{"title":"Leetcode-剑指offer 40.最小的K个数","slug":"题解/Leetcode-剑指offer-40-最小的K个数","date":"2021-03-27T11:51:16.000Z","updated":"2021-03-31T14:38:17.442Z","comments":true,"path":"2021/03/27/题解/Leetcode-剑指offer-40-最小的K个数/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/27/%E9%A2%98%E8%A7%A3/Leetcode-%E5%89%91%E6%8C%87offer-40-%E6%9C%80%E5%B0%8F%E7%9A%84K%E4%B8%AA%E6%95%B0/","excerpt":"","text":"输入整数数组 arr ，找出其中最小的 k 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。 示例 1： 输入：arr = [3,2,1], k = 2输出：[1,2] 或者 [2,1]示例 2： 输入：arr = [0,1,2,1], k = 1输出：[0] 限制： 0 &lt;= k &lt;= arr.length &lt;= 100000 &lt;= arr[i] &lt;= 10000 思路本题是求前 K 小，因此用一个容量为 K 的大根堆，每次 poll 出最大的数，那堆中保留的就是前 K 小。 若目前堆的大小小于K，将当前数字放入堆中。 否则判断当前数字与大根堆堆顶元素的大小关系，如果当前数字比大根堆堆顶还大，这个数就直接跳过；反之如果当前数字比大根堆堆顶小，先poll掉堆顶，再将该数字放入堆中。 代码12345678910111213141516171819202122232425class Solution &#123; public int[] getLeastNumbers(int[] arr, int k) &#123; if (k == 0 || arr.length == 0) &#123; return new int[0]; &#125; // 默认是小根堆，实现大根堆需要重写一下比较器。 Queue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;((v1, v2) -&gt; v2 - v1); for (int num: arr) &#123; if (pq.size() &lt; k) &#123; pq.offer(num); &#125; else if (num &lt; pq.peek()) &#123; pq.poll(); pq.offer(num); &#125; &#125; // 返回堆中的元素 int[] res = new int[pq.size()]; int idx = 0; for(int num: pq) &#123; res[idx++] = num; &#125; return res; &#125;&#125; 参考4种解法秒杀TopK（快排/堆/二叉搜索树/计数排序）❤️","categories":[{"name":"题解","slug":"题解","permalink":"https://xmmarlowe.github.io/categories/%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"TopK","slug":"TopK","permalink":"https://xmmarlowe.github.io/tags/TopK/"}],"author":"Marlowe"},{"title":"富途笔试-找到搜索二叉树中两个错误的节点","slug":"题解/富途笔试-找到搜索二叉树中两个错误的节点","date":"2021-03-27T08:48:17.000Z","updated":"2021-03-31T14:38:17.445Z","comments":true,"path":"2021/03/27/题解/富途笔试-找到搜索二叉树中两个错误的节点/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/27/%E9%A2%98%E8%A7%A3/%E5%AF%8C%E9%80%94%E7%AC%94%E8%AF%95-%E6%89%BE%E5%88%B0%E6%90%9C%E7%B4%A2%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E4%B8%A4%E4%B8%AA%E9%94%99%E8%AF%AF%E7%9A%84%E8%8A%82%E7%82%B9/","excerpt":"","text":"题目描述一棵二叉树原本是搜索二叉树，但是其中有两个节点调换了位置，使得这棵二叉树不再是搜索二叉树，请按升序输出这两个错误节点的值。(每个节点的值各不相同)示例1输入{1,2,3}返回值[1,2] 思路中序遍历可以得到搜索二叉树的升序遍历结果，题目描述其中两个节点交换了位置，因此只需在中序遍历中找到异常数据即可。 中序遍历二叉树 从前面往后找，发现当前数比后一个数大，则是异常数据，放在结果集下标为1的位置 从后面往前找，发现当前数比前一个数小，则是异常数据，放在结果集下标为0的位置 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.*;/* * public class TreeNode &#123; * int val = 0; * TreeNode left = null; * TreeNode right = null; * &#125; */public class Solution &#123; /** * * @param root TreeNode类 the root * @return int整型一维数组 */ List&lt;Integer&gt; res = new ArrayList(); public int[] findError (TreeNode root) &#123; // write code here int[] r = new int[2]; dfs(root); for(int i = 0; i &lt; res.size(); i++)&#123; if(res.get(i) &gt; res.get(i+1))&#123; r[1] = res.get(i); break; &#125; &#125; for(int j = res.size() - 1; j &gt;= 0; j--)&#123; if(res.get(j) &lt; res.get(j-1))&#123; r[0] = res.get(j); break; &#125; &#125; return r; &#125; public void dfs(TreeNode root)&#123; if(root != null)&#123; dfs(root.left); res.add(root.val); dfs(root.right); &#125; &#125;&#125;","categories":[{"name":"题解","slug":"题解","permalink":"https://xmmarlowe.github.io/categories/%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}],"author":"Marlowe"},{"title":"初识CAS与ABA问题","slug":"并发/初识CAS与ABA问题","date":"2021-03-25T12:34:19.000Z","updated":"2021-04-28T06:12:29.881Z","comments":true,"path":"2021/03/25/并发/初识CAS与ABA问题/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/25/%E5%B9%B6%E5%8F%91/%E5%88%9D%E8%AF%86CAS%E4%B8%8EABA%E9%97%AE%E9%A2%98/","excerpt":"","text":"什么是CAS？CAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。 CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。它体现的一种乐观锁的思想，比如多个线程要对一个共享的整型变量执行 +1 操作 获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。结合 CAS 和 volatile 可以实现无锁并发，适用于竞争不激烈、多核 CPU 的场景下。 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 CAS 底层依赖于一个 Unsafe 类来直接调用操作系统底层的 CAS 指令 伪代码： 123456789101112// 需要不断尝试while(true) &#123; int 旧值 = 共享变量;//比如拿到了当前值 0 int 结果 = 旧值 + 1;//在旧值 0 的基础上增加 1 ，正确结果是 1 //这时候如果别的线程把共享变量改成了 5，本线程的正确结果 1 就作 //废了，这时候 compareAndSwap 返回 false，重新尝试，直到： compareAndSwap 返回 //true，表示我本线程做修改的同时，别的线程没有干扰 if( compareAndSwap ( 旧值, 结果 )) &#123; // 成功，退出循环 &#125;&#125; 代码示例： 1234567891011121314public class CASDemo &#123; public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(2020); // public final boolean compareAndSet(int expect, int update) // 如果我的期望值达到了，就更新，否则不更新 CAS是CPU的并发原语！ System.out.println(atomicInteger.compareAndSet(2020, 2021)); System.out.println(atomicInteger.get()); System.out.println(atomicInteger.compareAndSet(2020, 2021)); System.out.println(atomicInteger.get()); &#125;&#125; 结果： 1234true2021false2021 CAS 缺点CAS虽然很高效的解决了原子操作问题，但是CAS仍然存在三大问题。 ABA问题在多线程场景下CAS会出现ABA问题，关于ABA问题这里简单科普下，例如有2个线程同时对同一个值(初始值为A)进行CAS操作，这三个线程如下 线程1，期望值为A，欲更新的值为B 线程2，期望值为A，欲更新的值为B 线程1抢先获得CPU时间片，而线程2因为其他原因阻塞了，线程1取值与期望的A值比较，发现相等然后将值更新为B，然后这个时候出现了线程3，期望值为B，欲更新的值为A，线程3取值与期望的值B比较，发现相等则将值更新为A，此时线程2从阻塞中恢复，并且获得了CPU时间片，这时候线程2取值与期望的值A比较，发现相等则将值更新为B，虽然线程2也完成了操作，但是线程2并不知道值已经经过了A-&gt;B-&gt;A的变化过程。 ABA问题带来的危害：小明在提款机，提取了50元，因为提款机问题，有两个线程，同时把余额从100变为50线程1（提款机）：获取当前值100，期望更新为50，线程2（提款机）：获取当前值100，期望更新为50，线程1成功执行，线程2某种原因block了，这时，某人给小明汇款50线程3（默认）：获取当前值50，期望更新为100，这时候线程3成功执行，余额变为100，线程2从Block中恢复，获取到的也是100，compare之后，继续更新余额为50！！！此时可以看到，实际余额应该为100（100-50+50），但是实际上变为了50（100-50+50-50）这就是ABA问题带来的成功提交。 解决方法： 在变量前面加上版本号，每次变量更新的时候变量的版本号都+1，即A-&gt;B-&gt;A就变成了1A-&gt;2B-&gt;3A。 循环会耗时如果CAS操作失败，就需要循环进行CAS操作(循环同时将期望值更新为最新的)，如果长时间都不成功的话，那么会造成CPU极大的开销。解决办法： 限制自旋次数，防止进入死循环。 只能保证一个共享变量的原子操作CAS的原子操作只能针对一个共享变量。 解决方法： 如果需要对多个共享变量进行操作，可以使用加锁方式(悲观锁)保证原子性，或者可以把多个共享变量合并成一个共享变量进行CAS操作。 CAS:ABA问题什么是ABA问题？ABA问题通俗一点的说，就是一个从内存里面读取到了值A，正在改的时候也检查到了还是A，但是真实的值是被改成了B再改回了A的。 怎么解决ABA问题?解决ABA问题就是给操作数加上一个“版本号”，就像Mysql的乐观锁一样。而Java中提供了AtomicStampedReference类来实现这个功能。 AtomicStampedReference类可以给一个引用标记上一个标记位，来保证原子性。AtomicStampedReference可以给一个引用标记上一个整型的版本戳，来保证原子性。 代码测试： 123456789101112131415161718192021public class CASTest &#123; public static String A = &quot;A&quot;; public static String B = &quot;B&quot;; public static String C = &quot;C&quot;; public static AtomicStampedReference&lt;String&gt; atomic = new AtomicStampedReference&lt;&gt;(A, 0); public static void main(String[] args) &#123; //线程1来了，先检查是否和当前值一样,我准备把A改成C了,并且拿到线程1比较时候的stamp boolean same = atomic.attemptStamp(A, 1); int stamp = atomic.getStamp(); //线程2来了，我准备把A换成B了 atomic.compareAndSet(A, B, atomic.getStamp(), atomic.getStamp() + 1); //线程3来了，我准备把B换回A了 atomic.compareAndSet(A, B, atomic.getStamp(), atomic.getStamp() + 1); //到线程1来修改了A成C了 if (same) &#123; boolean b = atomic.compareAndSet(A, C, stamp, stamp + 1); System.out.println(b?&quot;修改成功&quot;:&quot;修改失败ABA了&quot;); &#125; &#125;&#125; CAS的应用我们知道CAS操作并不会锁住共享变量，也就是一种非阻塞的同步机制，CAS就是乐观锁的实现。 乐观锁 乐观锁总是假设最好的情况，每次去操作数据都认为不会被别的线程修改数据，所以在每次操作数据的时候都不会给数据加锁， 即在线程对数据进行操作的时候，别的线程不会阻塞仍然可以对数据进行操作，只有在需要更新数据的时候才会去判断数据是否被别的线程修改过，如果数据被修改过则会拒绝操作并且返回错误信息给用户。2. 悲观锁悲观锁总是假设最坏的情况，每次去操作数据时候都认为会被的线程修改数据，所以在每次操作数据的时候都会给数据加锁， 让别的线程无法操作这个数据，别的线程会一直阻塞直到获取到这个数据的锁。这样的话就会影响效率，比如当有个线程发生一个很耗时的操作的时候，别的线程只是想获取这个数据的值而已都要等待很久。 Java利用CAS的乐观锁、原子性的特性高效解决了多线程的安全性问题，例如JDK1.8中的集合类ConcurrentHashMap、关键字volatile、ReentrantLock等。 参考认识CAS与ABA问题 CAS原理分析及ABA问题详解","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"CAS","slug":"CAS","permalink":"https://xmmarlowe.github.io/tags/CAS/"},{"name":"ABA","slug":"ABA","permalink":"https://xmmarlowe.github.io/tags/ABA/"}],"author":"Marlowe"},{"title":"异步回调","slug":"并发/异步回调","date":"2021-03-25T08:15:43.000Z","updated":"2021-04-19T12:10:57.400Z","comments":true,"path":"2021/03/25/并发/异步回调/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/25/%E5%B9%B6%E5%8F%91/%E5%BC%82%E6%AD%A5%E5%9B%9E%E8%B0%83/","excerpt":"","text":"Future 设计初衷：对将来的某个事件的结果进行建模 To be continue…","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://xmmarlowe.github.io/tags/%E5%BC%82%E6%AD%A5/"}],"author":"Marlowe"},{"title":"ForkJoin","slug":"并发/ForkJoin","date":"2021-03-25T05:37:54.000Z","updated":"2021-04-19T12:10:57.701Z","comments":true,"path":"2021/03/25/并发/ForkJoin/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/25/%E5%B9%B6%E5%8F%91/ForkJoin/","excerpt":"ForkJoin 在JDK1.7， 并行执行任务！ 在大数据量下提高效率。","text":"ForkJoin 在JDK1.7， 并行执行任务！ 在大数据量下提高效率。 ForkJoin特点：工作窃取 里面维护的是双端队列。 代码示例：ForkJoinDemo.java: 12345678910111213141516171819202122232425262728293031323334public class ForkJoinDemo extends RecursiveTask&lt;Long&gt; &#123; private Long start; private Long end; private Long temp = 10000L; public ForkJoinDemo(Long start, Long end) &#123; this.start = start; this.end = end; &#125; /** * The main computation performed by this task. * * @return the result of the computation */ @Override protected Long compute() &#123; if ((end - start) &lt; temp) &#123; Long sum = 0L; for (Long i = start; i &lt;= end; i++) &#123; sum += i; &#125; return sum; &#125; else &#123; long mid = (start + end) / 2; ForkJoinDemo task1 = new ForkJoinDemo(start, mid); task1.fork(); ForkJoinDemo task2 = new ForkJoinDemo(mid + 1, end); task2.fork(); return task1.join() + task2.join(); &#125; &#125;&#125; 12345678910public static void test1() throws ExecutionException, InterruptedException &#123; long start = System.currentTimeMillis(); ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask&lt;Long&gt; task = new ForkJoinDemo(0L, 10_0000_0000L); ForkJoinTask&lt;Long&gt; submit = forkJoinPool.submit(task); Long sum = submit.get(); long end = System.currentTimeMillis(); System.out.println(&quot;sum = &quot; + sum); System.out.println(&quot;耗时：&quot; + (end - start));&#125; 结果： 12sum = 500000000500000000耗时：4950 并行流 1234567public static void test2() &#123; long start = System.currentTimeMillis(); long sum = LongStream.rangeClosed(0L, 10_0000_0000L).parallel().reduce(0, Long::sum); long end = System.currentTimeMillis(); System.out.println(&quot;sum = &quot; + sum); System.out.println(&quot;耗时：&quot; + (end - start));&#125; 结果： 12sum = 500000000500000000耗时：271","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"ForkJoin","slug":"ForkJoin","permalink":"https://xmmarlowe.github.io/tags/ForkJoin/"}],"author":"Marlowe"},{"title":"Redis 相关知识点总结","slug":"NoSQL/Redis-相关知识点总结","date":"2021-03-22T17:01:53.000Z","updated":"2021-04-15T02:30:49.601Z","comments":true,"path":"2021/03/23/NoSQL/Redis-相关知识点总结/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/23/NoSQL/Redis-%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","excerpt":"总结一些Redis常见知识点…","text":"总结一些Redis常见知识点…","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"B树与B+树","slug":"算法与数据结构/B树与B+树","date":"2021-03-22T16:32:18.000Z","updated":"2021-04-23T13:47:39.763Z","comments":true,"path":"2021/03/23/算法与数据结构/B树与B+树/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/23/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/B%E6%A0%91%E4%B8%8EB+%E6%A0%91/","excerpt":"","text":"B树简介 一种二叉搜索树。 除根节点外的所有非叶节点至少含有（M/2（向上取整）-1）个关键字，每个节点最多有M-1个关键字，并且以升序排列。所以M阶B树的除根节点外的所有非叶节点的关键字取值区间为[M/2-1(向上取整),M-1]。 每个节点最多有M-1个关键字。 动图演示 B+树简介 有n棵子树的非叶子结点中含有n个关键字（b树是n-1个），这些关键字不保存数据，只用来索引，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接（叶子节点组成一个链表）。 所有的非叶子结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。 通常在b+树上有两个头指针，一个指向根结点，一个指向关键字最小的叶子结点。 同一个数字会在不同节点中重复出现，根节点的最大元素就是b+树的最大元素。 B树与B+树的区别 B树每个节点都存储数据，所有节点组成这棵树。B+树只有叶子节点存储数据（B+数中有两个头指针：一个指向根节点，另一个指向关键字最小的叶节点），叶子节点包含了这棵树的所有数据，所有的叶子结点使用链表相连，便于区间查找和遍历，所有非叶节点起到索引作用。 B树中叶节点包含的关键字和其他节点包含的关键字是不重复的，B+树的索引项只包含对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。 B树中每个节点（非根节点）关键字个数的范围为m/2(向上取整)-1,m-1，并且具有n个关键字的节点包含（n+1）棵子树。B+树中每个节点（非根节点）关键字个数的范围为m/2(向上取整),m，具有n个关键字的节点包含（n）棵子树。 B+树中查找，无论查找是否成功，每次都是一条从根节点到叶节点的路径。 B树的优点B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。 B+树的优点 所有的叶子结点使用链表相连，便于区间查找和遍历。B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。 b+树的中间节点不保存数据，能容纳更多节点元素。B树和B+树的共同优点考虑磁盘IO的影响，它相对于内存来说是很慢的。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少IO次数，对于树来说，IO次数就是树的高度，而“矮胖”就是b树的特征之一，m的大小取决于磁盘页的大小。 B+树比B树在哪里 B+树的磁盘读写代价更低B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。 B+树的数据信息遍历更加方便 B+树只要遍历叶子节点就可以实现整棵树的遍历，而B树不支持这样的操作（或者说效率太低），而且 在数据库中基于范围的查询是非常频繁的，所以数据库索引基本采用B+树。 B+树的查询效率更加稳定由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 为什么 MySQL 的索引要使用 B+ 树而不是其它树形结构？因为 B 树不管叶子节点还是非叶子节点，都会保存数据， 这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致 IO 操作变多，查询性能变低。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"BTree","slug":"BTree","permalink":"https://xmmarlowe.github.io/tags/BTree/"},{"name":"B+Tree","slug":"B-Tree","permalink":"https://xmmarlowe.github.io/tags/B-Tree/"}],"author":"Marlowe"},{"title":"进程和线程相关知识点","slug":"操作系统/进程和线程相关知识点","date":"2021-03-22T13:42:24.000Z","updated":"2021-04-22T07:48:30.836Z","comments":true,"path":"2021/03/22/操作系统/进程和线程相关知识点/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"何为进程？进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 何为线程？线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 何为协程？协程是计算机程序的一类组件，推广了协作式多任务的子程序，允许执行被挂起与被恢复。相对子例程而言，协程更为一般和灵活，但在实践中使用没有子例程那样广泛。协程更适合于用来实现彼此熟悉的程序组件，如协作式多任务、异常处理、事件循环、迭代器、无限列表和管道。 线程和进程的区别是什么？总结: 线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护;而进程正相反。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"}],"author":"Marlowe"},{"title":"线程之间同步的机制","slug":"操作系统/线程之间同步的机制","date":"2021-03-22T11:41:19.000Z","updated":"2021-04-08T06:45:36.950Z","comments":true,"path":"2021/03/22/操作系统/线程之间同步的机制/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E5%90%8C%E6%AD%A5%E7%9A%84%E6%9C%BA%E5%88%B6/","excerpt":"待完善…","text":"待完善… 临界区：不可以跨进程，忘记解锁会无限等待，要么存在要么没有，多线程访问独占性共享资源 互斥量：可以跨进程，忘记解锁会自动释放，要么存在要么没有 事件：又叫线程触发器，不可以跨进程，要么存在要么没有，一个线程来唤醒另一个线程（包括自动和人工两种方式） 信号量：可以跨进程，始终代表可用资源数量，当资源数为0时，线程阻塞，允许多个线程同时访问一个共享资源","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"常用排序算法Java实现","slug":"算法与数据结构/常用排序算法Java实现","date":"2021-03-20T07:14:27.000Z","updated":"2021-04-15T05:40:35.265Z","comments":true,"path":"2021/03/20/算法与数据结构/常用排序算法Java实现/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/20/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95Java%E5%AE%9E%E7%8E%B0/","excerpt":"排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。","text":"排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。 算法概览 排序算法1 冒泡排序算法思想从左到右不断交换相邻逆序的元素，在一轮的循环之后，可以让未排序的最大元素上浮到右侧。在一轮循环中，如果没有发生交换，那么说明数组已经是有序的，此时可以直接退出。动图演示最好情况当输入的数据已经是正序最差情况当输入的数据是反序代码实现 1234567891011121314151617181920/** * 冒泡排序 * * @param nums */public static void bubbleSort(int[] nums) &#123; int n = nums.length; boolean flag = false; for (int i = 0; i &lt; n - 1 &amp;&amp; !flag; i++) &#123; flag = true; for (int j = 0; j &lt; n - 1 - i; j++) &#123; // 如果全都排好，则flag = true,跳出循环 if (nums[j] &gt; nums[j + 1]) &#123; flag = false; swap(nums, j, j + 1); &#125; &#125; &#125; System.out.println(Arrays.toString(nums));&#125; 2 选择排序算法思想每一次从未排序的集合中选出最小的数，依次放在第1、2、3…位置处动图演示 最好情况当输入的数据已经是正序最差情况当输入的数据是反序 代码实现 1234567891011121314151617181920212223/** * 选择排序 * * @param nums */public static void selectSort(int[] nums) &#123; int n = nums.length; // 比较n - 1 轮 for (int i = 0; i &lt; n - 1; i++) &#123; int min = i; // 每一轮找到最小值的下标 for (int j = i + 1; j &lt; n; j++) &#123; if (nums[j] &lt; nums[min]) &#123; min = j; &#125; &#125; // 找到最小值与当前值交换 if (min != i) &#123; swap(nums, i, min); &#125; &#125; System.out.println(Arrays.toString(nums));&#125; 3 插入排序算法思想将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 动图演示 最好情况如果序列是完全有序的，插入排序只要比较n次，无需移动，时间复杂度为O(N)最差情况如果序列是逆序的，插入排序要比较O（N2）和移动O(N2)代码实现 1234567891011121314/** * 插入排序 * @param nums */public static void insertSort(int[] nums) &#123; int n = nums.length; for (int i = 1; i &lt; n; i++) &#123; // 从后往前找，如果当前元素比最后一个元素都大，则当前轮次排序结束 for (int j = i; j &gt; 0 &amp;&amp; nums[j] &lt; nums[j - 1]; j--) &#123; swap(nums, j, j - 1); &#125; &#125; System.out.println(Arrays.toString(nums));&#125; 4 希尔排序算法思想希尔排序是将待排序的数组元素 按下标的一定增量分组 ，分成多个子序列，然后对各个子序列进行直接插入排序算法排序；然后依次缩减增量再进行排序，直到增量为1时，进行最后一次直接插入排序，排序结束。动图演示最好情况序列是正序排列，在这种情况下，需要进行的比较操作需（n-1）次。后移赋值操作为0次。即O(n)最差情况O(nlog2n)代码实现 123456789101112131415161718192021/** * 希尔排序 * * @param nums */public static void shellSort(int[] nums) &#123; int n = nums.length; // gap： 增量，每次减半 for (int gap = n / 2; gap &gt; 0; gap /= 2) &#123; // i:代表即将插入的元素角标，作为每一组比较数据的最后一个元素角标 for (int i = gap; i &lt; n; i++) &#123; // j:代表与i同一组的数组元素角标 for (int j = i - gap; j &gt;= 0; j -= gap) &#123; if (nums[j] &gt; nums[j + gap]) &#123; swap(nums, j, j + gap); &#125; &#125; &#125; &#125; System.out.println(Arrays.toString(nums));&#125; 5 归并排序算法思想归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。算法步骤： 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列； 设定两个指针，最初位置分别为两个已经排序序列的起始位置； 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置； 重复步骤 3 直到某一指针达到序列尾； 将另一序列剩下的所有元素直接复制到合并序列尾。 动图演示最好情况O(nlogn)最差情况O(nlogn)代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 合并两个有序子数组 * @param nums * @param low * @param mid * @param high * @param tmp */public static void merge(int[] nums, int low, int mid, int high, int[] tmp) &#123; int i = 0; int j = low; int k = mid + 1; while (j &lt;= mid &amp;&amp; k &lt;= high) &#123; if (nums[j] &lt; nums[k]) &#123; tmp[i++] = nums[j++]; &#125; else &#123; tmp[i++] = nums[k++]; &#125; &#125; while (j &lt;= mid) &#123; tmp[i++] = nums[j++]; &#125; while (k &lt;= high) &#123; tmp[i++] = nums[k++]; &#125; for (int l = 0; l &lt; i; l++) &#123; nums[low + l] = tmp[l]; &#125;&#125;/** * 左右子数组分别递归分 * @param nums * @param low * @param high * @param tmp */public static void mergeSort(int[] nums, int low, int high, int[] tmp) &#123; if (low &lt; high) &#123; int mid = (low + high) &gt;&gt; 1; mergeSort(nums, low, mid, tmp); mergeSort(nums, mid + 1, high, tmp); merge(nums, low, mid, high, tmp); &#125;&#125; 6 快速排序算法思想快速排序通过一个切分元素将数组分为两个子数组，左子数组小于等于切分元素，右子数组大于等于切分元素，将这两个子数组排序也就将整个数组排序了。算法步骤： 从数列中挑出一个元素，称为 “基准”（pivot）; 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序； 动图演示最好情况最好情况，递归树的深度为log2n，其空间复杂度也就为O(logn)最差情况最坏情况，需要进行n‐1递归调用，其空间复杂度为O(n^2)代码实现 1234567891011121314151617181920212223242526272829303132333435363738/** * 快速排序 * * @param nums * @param low * @param high */public static void quickSort(int[] nums, int low, int high) &#123; int i, j, tmp; if (low &gt; high) &#123; return; &#125; i = low; j = high; //tmp就是基准位 tmp = nums[low]; while (i &lt; j) &#123; //先看右边，依次往左递减 while (tmp &lt;= nums[j] &amp;&amp; i &lt; j) &#123; j--; &#125; //再看左边，依次往右递增 while (tmp &gt;= nums[i] &amp;&amp; i &lt; j) &#123; i++; &#125; //如果满足条件则交换 if (i &lt; j) &#123; swap(nums, i, j); &#125; &#125; //最后将基准为与i和j相等位置的数字交换 nums[low] = nums[i]; nums[i] = tmp; //递归调用左半数组 quickSort(nums, low, j - 1); //递归调用右半数组 quickSort(nums, j + 1, high);&#125; 7 堆排序算法思想堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法： 大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列； 小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列； 堆排序的平均时间复杂度为 Ο(nlogn)。 动图演示最好情况O(nlogn)最差情况O(nlogn)代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class HeapSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;88, 11, 22, 3, 5, 1, 19&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static void sort(int[] arr) &#123; int len = arr.length; buildHeap(arr, len); for (int i = len - 1; i &gt; 0; i--) &#123; //首尾交换 swap(arr, 0, i); //重新维护堆性质 heapify(arr, 0, --len); &#125; &#125; private static void buildHeap(int[] arr, int len) &#123; for (int i = 0; i &lt; len / 2; i++) &#123; heapify(arr, i, len); &#125; &#125; private static void heapify(int[] arr, int index, int len) &#123; int left = 2 * index + 1; int right = 2 * index + 2; int max = index; if (left &lt; len &amp;&amp; arr[left] &gt; arr[max]) &#123; max = left; &#125; if (right &lt; len &amp;&amp; arr[right] &gt; arr[max]) &#123; max = right; &#125; if (max != index) &#123; swap(arr, max, index); heapify(arr, max, len); &#125; &#125; /** * 交换 * * @param arr 数组 * @param self 自身 * @param other 另一个 */ private static void swap(int[] arr, int self, int other) &#123; int tmp = arr[self]; arr[self] = arr[other]; arr[other] = tmp; &#125;&#125; 8 计数排序算法思想计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 算法的步骤如下： 找出待排序的数组中最大和最小的元素 统计数组中每个值为i的元素出现的次数，存入数组C的第i项 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加） 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1 动图演示 代码实现 1234567891011121314151617181920212223242526/** * 计数排序 * * @param nums */public static void countSort(int[] nums) &#123; int max = Integer.MIN_VALUE; // 找到最大值 for (int num : nums) &#123; if (num &gt; max) &#123; max = num; &#125; &#125; int[] bucket = new int[max + 1]; // 统计每个元素的个数 for (int num : nums) &#123; bucket[num]++; &#125; int index = 0; for (int i = 0; i &lt; bucket.length; i++) &#123; while (bucket[i] &gt; 0) &#123; nums[index++] = i; bucket[i]--; &#125; &#125;&#125; 9 桶排序算法思想桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点： 在额外空间充足的情况下，尽量增大桶的数量 使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中 动图演示元素分布在桶中：然后，元素在每个桶中排序： 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class BucketSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; sort(arr, 5); System.out.println(Arrays.toString(arr)); &#125; private static void sort(int[] arr, int bucketSize) &#123; if (arr.length == 0) &#123; return; &#125; int minValue = arr[0]; int maxValue = arr[0]; for (int value : arr) &#123; if (value &lt; minValue) &#123; minValue = value; &#125; else if (value &gt; maxValue) &#123; maxValue = value; &#125; &#125; int bucketCount = (maxValue - minValue) / bucketSize + 1; int[][] buckets = new int[bucketCount][0]; // 利用映射函数将数据分配到各个桶中 for (int item : arr) &#123; int index = (item - minValue) / bucketSize; buckets[index] = arrAppend(buckets[index], item); &#125; int arrIndex = 0; for (int[] bucket : buckets) &#123; if (bucket.length &lt;= 0) &#123; continue; &#125; // 对每个桶进行排序，这里使用了归并排序 MergeSort.sort(bucket); for (int value : bucket) &#123; arr[arrIndex++] = value; &#125; &#125; &#125; /** * 自动扩容，并保存数据 */ private static int[] arrAppend(int[] arr, int value) &#123; arr = Arrays.copyOf(arr, arr.length + 1); arr[arr.length - 1] = value; return arr; &#125;&#125; 10 基数排序算法思想基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 动图演示 代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * 基数排序 * 考虑负数的情况还可以参考： https://code.i-harness.com/zh-CN/q/e98fa9 */public class RadixSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static int[] sort(int[] arr) &#123; int maxDigit = getMaxDigit(arr); return radixSort(arr, maxDigit); &#125; /** * 获取最高位数 */ private static int getMaxDigit(int[] arr) &#123; int maxValue = getMaxValue(arr); return getNumLength(maxValue); &#125; private static int getMaxValue(int[] arr) &#123; int maxValue = arr[0]; for (int value : arr) &#123; if (maxValue &lt; value) &#123; maxValue = value; &#125; &#125; return maxValue; &#125; protected static int getNumLength(long num) &#123; if (num == 0) &#123; return 1; &#125; int lenght = 0; for (long temp = num; temp != 0; temp /= 10) &#123; lenght++; &#125; return lenght; &#125; private static int[] radixSort(int[] arr, int maxDigit) &#123; int mod = 10; int dev = 1; for (int i = 0; i &lt; maxDigit; i++, dev *= 10, mod *= 10) &#123; // 考虑负数的情况，这里扩展一倍队列数，其中 [0-9]对应负数，[10-19]对应正数 (bucket + 10) int[][] counter = new int[mod * 2][0]; for (int j = 0; j &lt; arr.length; j++) &#123; int bucket = ((arr[j] % mod) / dev) + mod; counter[bucket] = arrayAppend(counter[bucket], arr[j]); &#125; int pos = 0; for (int[] bucket : counter) &#123; for (int value : bucket) &#123; arr[pos++] = value; &#125; &#125; &#125; return arr; &#125; /** * 自动扩容，并保存数据 * * @param arr * @param value */ private static int[] arrayAppend(int[] arr, int value) &#123; arr = Arrays.copyOf(arr, arr.length + 1); arr[arr.length - 1] = value; return arr; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://xmmarlowe.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://xmmarlowe.github.io/tags/%E6%8E%92%E5%BA%8F/"}],"author":"Marlowe"},{"title":"JUC 核心之AQS介绍","slug":"并发/JUC-核心之AQS介绍","date":"2021-03-19T14:19:40.000Z","updated":"2021-04-30T08:27:25.779Z","comments":true,"path":"2021/03/19/并发/JUC-核心之AQS介绍/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/19/%E5%B9%B6%E5%8F%91/JUC-%E6%A0%B8%E5%BF%83%E4%B9%8BAQS%E4%BB%8B%E7%BB%8D/","excerpt":"AQS 的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。","text":"AQS 的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。 简介AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。 AQS原理分析AQS原理概览AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。 看个 AQS(AbstractQueuedSynchronizer)原理图： AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过 protected 类型的 getState，setState，compareAndSetState 进行操作 12345678910111213//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; AQS 对资源的共享方式AQS 定义两种资源共享方式 Exclusive（独占）：只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如 CountDownLatch、Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS 已经在顶层实现好了。 AQS 底层使用了模板方法模式AQS 使用了模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的模板方法： 12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS 类中的其他方法都是 final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以 ReentrantLock 为例，state 初始化为 0，表示未锁定状态。A 线程 lock()时，会调用 tryAcquire()独占该锁并将 state+1。此后，其他线程再 tryAcquire()时就会失败，直到 A 线程 unlock()到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证 state 是能回到零态的。 再以 CountDownLatch 以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后 countDown() 一次，state 会 CAS(Compare and Swap)减 1。等到所有子线程都执行完后(即 state=0)，会 unpark()主调用线程，然后主调用线程就会从 await() 函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但 AQS 也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 如何表明锁状态?无锁还是有锁?state变量即可。假如咱们让这个变量类型为boolean, true表明有锁、false表明无锁。 ReentrantLock, 由于RL的设计叫做:可重入锁，而boolean只能表示两种状态，这时需要别的类型，int即可。0表明无锁，&gt;0表明重入了几次，也即获取了多少次锁。 AQS 组件总结 Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。 CountDownLatch （倒计时器）： CountDownLatch 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。 CyclicBarrier (循环栅栏)： CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 一些问题谈谈你对AQS的理解，AQS如何实现可重入锁？ AQS是一个Java线程同步框架。是JDK中很多锁工具的核心实现框架。 在AQS中，维护了一个信号量state和一个线程组成的双向链表队列。其中，这个线程队列，就是用来给线程排队的，而state就像是一个红绿灯，用来控制线程排队或者放行的。在不同的场景下，有不同的意义。 在可重入锁这个场景下，state就用来表示加锁的次数。0表示无锁，每加一次锁，state就加1。释放锁state就减1。 总结AQS底层是通过一个状态量State记录当前同步器的状态，这个状态量的更改是通过CAS方式更新，同时维护了一个等待队列，如果新的任务进来的时候发现AQS是独占模式并且状态为0，则表示可以直接执行，如果状态为1则加入等待队列（双向链表），当调用unlock的时候唤醒等待队列中没有被取消的线程。 如果为非公平模式，当AQS已经被使用完成，从等待队列中唤醒一个任务的时候同时有一个任务也正加入进来，则两个任务直接竞争。如果是公平模式则直接将新加的任务放入队尾。 而AQS中还有Condition，也就是一个锁可以有多个条件来保证并发 参考AQS JUC：AQS详解","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"https://xmmarlowe.github.io/tags/AQS/"},{"name":"JUC","slug":"JUC","permalink":"https://xmmarlowe.github.io/tags/JUC/"}],"author":"Marlowe"},{"title":"Atomic 原子类","slug":"并发/Atomic-原子类","date":"2021-03-19T13:03:15.000Z","updated":"2021-03-19T14:31:01.462Z","comments":true,"path":"2021/03/19/并发/Atomic-原子类/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/19/%E5%B9%B6%E5%8F%91/Atomic-%E5%8E%9F%E5%AD%90%E7%B1%BB/","excerpt":"Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。","text":"Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 1、简介原子类说简单点就是具有原子/原子操作特征的类。 2、JUC 包中的原子类是哪 4 类?基本类型 使用原子的方式更新基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 数组类型 使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicReferenceFieldUpdater：原子更新引用类型字段的更新器 3、讲讲 AtomicInteger 的使用AtomicInteger 类常用方法 1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 AtomicInteger 类的使用示例使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。 1234567891011class AtomicIntegerTest &#123; private AtomicInteger count = new AtomicInteger(); //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。 public void increment() &#123; count.incrementAndGet(); &#125; public int getCount() &#123; return count.get(); &#125;&#125; 4、 AtomicInteger 类的原理AtomicInteger 类的部分源码： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS 的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个 volatile 变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 参考Atomic 原子类","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"原子类","slug":"原子类","permalink":"https://xmmarlowe.github.io/tags/%E5%8E%9F%E5%AD%90%E7%B1%BB/"}],"author":"Marlowe"},{"title":"线程池原理分析","slug":"并发/线程池原理分析","date":"2021-03-19T12:38:30.000Z","updated":"2021-03-19T12:43:24.306Z","comments":true,"path":"2021/03/19/并发/线程池原理分析/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/19/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","excerpt":"","text":"execute方法源码： 12345678910111213141516171819202122232425262728293031323334353637383940// 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; private final BlockingQueue&lt;Runnable&gt; workQueue; public void execute(Runnable command) &#123; // 如果任务为null，则抛出异常。 if (command == null) throw new NullPointerException(); // ctl 中保存的线程池当前的一些状态信息 int c = ctl.get(); // 下面会涉及到 3 步 操作 // 1.首先判断当前线程池中执行的任务数量是否小于 corePoolSize // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2.如果当前执行的任务数量大于等于 corePoolSize 的时候就会走到这里 // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果当前线程池为空就新创建一个线程并执行。 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。 else if (!addWorker(command, false)) reject(command); &#125; 具体流程见图解：","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}],"author":"Marlowe"},{"title":"线程池","slug":"并发/线程池","date":"2021-03-18T08:11:53.000Z","updated":"2021-04-16T07:17:15.047Z","comments":true,"path":"2021/03/18/并发/线程池/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/18/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。三大创建方法、七大参数、四种拒绝策略…","text":"池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。三大创建方法、七大参数、四种拒绝策略… 1、为什么要用线程池？ 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 2、线程池的三大创建方法通过 Executor 框架的工具类 Executors 来实现 我们可以创建三种类型的 ThreadPoolExecutor： FixedThreadPool： 该方法返回一个固定线程数量的线程池。 该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 SingleThreadExecutor： 方法返回一个只有一个线程的线程池。 若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。 线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 3、实现 Runnable 接口和 Callable 接口的区别Runnable自 Java 1.0 以来一直存在，但Callable仅在 Java 1.5 中引入,目的就是为了来处理Runnable不支持的用例。Runnable 接口不会返回结果或抛出检查异常，但是Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口， 这样代码看起来会更加简洁。 工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。（Executors.callable（Runnable task）或 Executors.callable（Runnable task，Object resule））。 Runnable.java 1234567@FunctionalInterfacepublic interface Runnable &#123; /** * 被线程执行，没有返回值也无法抛出异常 */ public abstract void run();&#125; Callable.java 123456789@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; /** * 计算结果，或在无法这样做时抛出异常。 * @return 计算得出的结果 * @throws 如果无法计算结果，则抛出异常 */ V call() throws Exception;&#125; 4、执行 execute()方法和 submit()方法的区别是什么呢？ execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功， 并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 5、ThreadPoolExecutor 类分析ThreadPoolExecutor 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么）。 123456789101112131415161718192021222324/** * 用给定的初始参数创建一个新的ThreadPoolExecutor。 */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 5.1 ThreadPoolExecutor构造函数重要参数分析ThreadPoolExecutor 3 个最重要的参数： corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数: keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 5.2 ThreadPoolExecutor 饱和策略(4种拒绝策略)ThreadPoolExecutor 饱和策略定义: 如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。 举个例子： Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略的话来配置线程池的时候默认使用的是 ThreadPoolExecutor.AbortPolicy。在默认情况下，ThreadPoolExecutor 将抛出 RejectedExecutionException 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 ThreadPoolExecutor.CallerRunsPolicy。当最大池被填满时，此策略为我们提供可伸缩队列。 编写测试程序，我们这里以阿里巴巴推荐的使用 ThreadPoolExecutor 构造函数自定义参数的方式来创建线程池。 ThreadPoolExecutorDemo.java 1234567891011121314151617181920212223242526272829303132333435import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class ThreadPoolExecutorDemo &#123; private static final int CORE_POOL_SIZE = 5; private static final int MAX_POOL_SIZE = 10; private static final int QUEUE_CAPACITY = 100; private static final Long KEEP_ALIVE_TIME = 1L; public static void main(String[] args) &#123; //使用阿里巴巴推荐的创建线程池的方式 //通过ThreadPoolExecutor构造函数自定义参数创建 ThreadPoolExecutor executor = new ThreadPoolExecutor( CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 10; i++) &#123; //创建WorkerThread对象（WorkerThread类实现了Runnable 接口） Runnable worker = new MyRunnable(&quot;&quot; + i); //执行Runnable executor.execute(worker); &#125; //终止线程池 executor.shutdown(); while (!executor.isTerminated()) &#123; &#125; System.out.println(&quot;Finished all threads&quot;); &#125;&#125; 可以看到我们上面的代码指定了： corePoolSize: 核心线程数为 5。 maximumPoolSize ：最大线程数 10 keepAliveTime : 等待时间为 1L。 unit: 等待时间的单位为 TimeUnit.SECONDS。 workQueue：任务队列为 ArrayBlockingQueue，并且容量为 100; handler:饱和策略为 CallerRunsPolicy。 6、线程池原理分析为了搞懂线程池的原理，我们需要首先分析一下 execute方法。看看它的源码： 12345678910111213141516171819202122232425262728293031323334353637383940// 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; private final BlockingQueue&lt;Runnable&gt; workQueue; public void execute(Runnable command) &#123; // 如果任务为null，则抛出异常。 if (command == null) throw new NullPointerException(); // ctl 中保存的线程池当前的一些状态信息 int c = ctl.get(); // 下面会涉及到 3 步 操作 // 1.首先判断当前线程池中执行的任务数量是否小于 corePoolSize // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2.如果当前执行的任务数量大于等于 corePoolSize 的时候就会走到这里 // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果当前线程池为空就新创建一个线程并执行。 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。 else if (!addWorker(command, false)) reject(command); &#125; 图解： 小结线程池最大线程数到底该如何定义： CPU 密集型：电脑是几核，就是几，可以保持CPU的效率最高。12// 获取CPU核心数Runtime.getRuntime().availableProcessors() IO 密集型：判断程序中十分耗IO的线程有多少个，大于这个数（或者2倍） 参考线程池","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}],"author":"Marlowe"},{"title":"volatile 关键字","slug":"并发/volatile-关键字","date":"2021-03-18T02:30:02.000Z","updated":"2021-04-28T07:23:24.856Z","comments":true,"path":"2021/03/18/并发/volatile-关键字/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/18/%E5%B9%B6%E5%8F%91/volatile-%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"volatile 是Java虚拟机提供的轻量级同步机制，保证可见性，不保证原子性，禁止指令重排。","text":"volatile 是Java虚拟机提供的轻量级同步机制，保证可见性，不保证原子性，禁止指令重排。 1、CPU缓存模型为什么要弄一个 CPU 高速缓存呢？类比我们开发网站后台系统使用的缓存（比如 Redis）是为了解决程序处理速度和访问常规关系型数据库速度不对等的问题。 CPU 缓存则是为了解决 CPU 处理速度和内存处理速度不对等的问题。 我们甚至可以把 内存可以看作外存的高速缓存，程序运行的时候我们把外存的数据复制到内存，由于内存的处理速度远远高于外存，这样提高了处理速度。 总结： CPU Cache 缓存的是内存数据用于解决 CPU 处理速度和内存不匹配的问题，内存缓存的是硬盘数据用于解决硬盘访问速度过慢的问题。 CPU Cache 的工作方式： 先复制一份数据到 CPU Cache 中，当 CPU 需要用到的时候就可以直接从 CPU Cache 中读取数据，当运算完成后，再将运算得到的数据写回 Main Memory 中。但是，这样存在 内存缓存不一致性的问题 ！ 比如我执行一个 i++操作的话，如果两个线程同时执行的话，假设两个线程从 CPU Cache 中读取的 i=1，两个线程做了 1++运算完之后再写回 Main Memory 之后 i=2，而正确结果应该是 i=3。 CPU 为了解决内存缓存不一致性问题可以通过制定缓存一致协议或者其他手段来解决。 2、讲一下 JMM(Java 内存模型)在 JDK1.2 之前，Java 的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 要解决这个问题，就需要把变量声明为volatile，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。 所以，volatile 关键字 除了防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性。 关于JMM的一些同步约定： 线程解锁前，必须把共享变量立刻刷回主存。 线程加锁前，必须读取主存中的最新值到工作内存中。 加锁和解锁是同一把锁。 关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成： lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。 unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则： 如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。 代码示例：开启两个线程，一个主线程，一个新线程。 1234567891011121314151617181920public class Test3 &#123; private static int num = 0; public static void main(String[] args) &#123; new Thread(() -&gt; &#123; // 线程1对主内存的变化是不知道的 while (num == 0) &#123; &#125; &#125;).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; num = 1; System.out.println(num); &#125;&#125; 结果： 1231// 程序一直执行 问题：程序不知道主内存的值已经被修改为1 3、volatile 保证可见性 代码示例： 1234567891011121314151617181920212223public class Test3 &#123; /** * 不加 volatile 程序会死循环！ * 加 volatile 可以保证变量可见性 */ private volatile static int num = 0; public static void main(String[] args) &#123; new Thread(() -&gt; &#123; while (num == 0) &#123; &#125; &#125;).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; num = 1; System.out.println(num); &#125;&#125; 结果： 1231Process finished with exit code 0 不保证原子性 原子性：不可分割线程A在执行任务的时候，是不能被打扰的，也不能被分割，要么同时成功，要么同时失败。 代码示例： 1234567891011121314151617181920212223242526public class TestVolatile &#123; // volatile 不保证原子性 private volatile static int num = 0; public static void add() &#123; // 不是原子性操作 num++; &#125; public static void main(String[] args) &#123; // 理论上num结果应该为2w for (int i = 1; i &lt;= 20; i++) &#123; new Thread(() -&gt; &#123; for (int j = 0; j &lt; 1000; j++) &#123; add(); &#125; &#125;).start(); &#125; while (Thread.activeCount() &gt; 2) &#123; Thread.yield(); &#125; System.out.println(Thread.currentThread().getName() + &quot; &quot; + num); &#125;&#125; 结果： 1main 19782 // 结果每次可能不一样，但不会变为2w 如果不加lock和synchronized,怎么样保证原子性? 使用原子类解决原子性问题 代码示例: 1234567891011121314151617181920212223242526public class TestVolatile &#123; // volatile 不保证原子性 private volatile static AtomicInteger num = new AtomicInteger(); public static void add() &#123; // AtomicInteger +1 方法 不是简单的 +1 操作，而是用的CAS num.getAndIncrement(); &#125; public static void main(String[] args) &#123; // 理论上num结果应该为2w for (int i = 1; i &lt;= 20; i++) &#123; new Thread(() -&gt; &#123; for (int j = 0; j &lt; 1000; j++) &#123; add(); &#125; &#125;).start(); &#125; while (Thread.activeCount() &gt; 2) &#123; Thread.yield(); &#125; System.out.println(Thread.currentThread().getName() + &quot; &quot; + num); &#125;&#125; 结果： 1main 20000 这些类的底层都直接和操作系统挂钩！在内存中修改值！Unsafe类是一个很特殊的存在。 禁止指令重排 什么是指令重排：你写的程序，计算机并不是按照你写的那样去执行的。源代码–&gt; 编译器优化的重排–&gt; 指令并行也可能重排–&gt; 内存系统也会重排–&gt; 执行. 前提：处理器在进行指令重排的时候，会考虑数据之间的依赖性！ 123456int x = 1; // 1int y = 2; // 2x = x + 5; // 3y = x * x; // 4我们所期望的：1234 但是可能执行的时候会变成 2134 1324 volatile如何保证可见性？volatile 主要是利用了java的先行发生原则 （简单介绍先行发生原则：在计算机科学中，先行发生原则是两个事件的结果之间的关系，如果一个事件发生在另一个事件之前，结果必须反映，即使这些事件实际上是乱序执行的（通常是优化程序流程））。volatile相关的规则： 对于一个volatile变量的写操作先行发生于后面对这个变量的读操作。 因此当线程1执行了vlt=5；写操作是必然先发生2线程读操作。即线程2从主内存读到的数据一定是线程1写过的数据那就是5。所以volatile主要利用了先行发生原则保证线程之间的可见性。 volatile如何避免指令重排？内存屏障，是一个CPU指令。 作用： 保证特定操作的执行顺序。 可以保证某些变量的内存可见性（利用这些特性，volatile实现了可见性）。 volatile 可以保证可见性，不能保证原子性，由于内存屏障，可以保证避免指令重排的现象产生！ 由于编译器和处理器都能执行指令重排优化，如果在指令之间插入一条内存屏障则会告诉编译器和cup不管在任何情况下，无论任何指令都不能和这条内存屏障进行指令重排，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。内存屏障的另外一个作用就是强制刷出各种CPU的缓存数据，因此在任何CPU上的线程都能读取到这些数据的最新值。 4、并发编程的三个重要特性 原子性 : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。synchronized 可以保证代码片段的原子性。 可见性 ： 当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。 有序性 ： 代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。 5、说说 synchronized 关键字和 volatile 关键字的区别synchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！ volatile 关键字是线程同步的轻量级实现，所以volatile 性能肯定比synchronized关键字要好。但是volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块。 volatile 关键字能保证数据的可见性，但不能保证数据的原子性。 synchronized 关键字两者都能保证。 volatile 关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。 5、参考volatile 关键字","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"https://xmmarlowe.github.io/tags/volatile/"}],"author":"Marlowe"},{"title":"synchronized相关知识点","slug":"并发/synchronized相关知识点","date":"2021-03-17T14:39:35.000Z","updated":"2021-04-28T06:10:10.625Z","comments":true,"path":"2021/03/17/并发/synchronized相关知识点/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/17/%E5%B9%B6%E5%8F%91/synchronized%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"1、synchronized 关键字 1.1 synchronized 关键字简介synchronized 关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 另外，在 Java 早期版本中，synchronized 属于 重量级锁，效率低下。 为什么呢？因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。 庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对 synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6 对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 所以，你会发现目前的话，不论是各种开源框架还是 JDK 源码都大量使用了 synchronized 关键字。 2、synchronized 关键字使用方式synchronized 关键字最主要的三种使用方式： 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁123synchronized void method() &#123; //业务代码&#125; 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前 class 的锁。因为静态成员不属于任何一个实例对象，是类成员（ _static 表明这是该类的一个静态资源，不管 new 了多少个对象，只有一份_）。所以，如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。123synchronized static void method() &#123;//业务代码&#125; 修饰代码块： 指定加锁对象，对给定对象/类加锁。synchronized(this|object) 表示进入同步代码库前要获得给定对象的锁。synchronized(类.class) 表示进入同步代码前要获得 当前 class 的锁 123synchronized(this) &#123; //业务代码&#125; 总结： synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁。 synchronized 关键字加到实例方法上是给对象实例上锁。 尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能！ 重点：面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！” 双重校验锁实现对象单例（线程安全） 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 构造方法不能使用synchronized 关键词修饰。因为构造方法本身就属于线程安全的，不存在同步的构造方法一说。 2.1 synchronized 关键字的底层原理2.1.1 synchronized 同步语句块的情况1234567public class SynchronizedDemo &#123; public void method() &#123; synchronized (this) &#123; System.out.println(&quot;synchronized 代码块&quot;); &#125; &#125;&#125; 从上面我们可以看出： synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。 在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。 在执行 monitorexit 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 2.1.2 synchronized 修饰方法的的情况12345public class SynchronizedDemo2 &#123; public synchronized void method() &#123; System.out.println(&quot;synchronized 方法&quot;); &#125;&#125; synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 2.1.3 总结synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。 不过两者的本质都是对对象监视器 monitor 的获取。 2.2 说说 JDK1.6 之后的 synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗？JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 2.3 谈谈 synchronized 和 ReentrantLock 的区别2.3.1 两者都是可重入锁“可重入锁” 指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。 2.3.2 synchronized 依赖于 JVM 而 ReentrantLock 依赖于 APIsynchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 2.3.3 ReentrantLock 比 synchronized 增加了一些高级功能相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点： 等待可中断 : ReentrantLock提供了一种能够中断等待锁的线程的机制，通过 lock.lockInterruptibly() 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 可实现公平锁 : ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。 可实现选择性通知（锁可以绑定多个条件）: synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制。ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition()方法。 Condition是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是 Condition 接口默认提供的。而synchronized关键字就相当于整个 Lock 对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 3、参考synchronized 关键字","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"synchronized","slug":"synchronized","permalink":"https://xmmarlowe.github.io/tags/synchronized/"}],"author":"Marlowe"},{"title":"JDK动态代理和CGLIB动态代理","slug":"春招面试/JDK动态代理和CGLIB动态代理","date":"2021-03-15T06:21:31.000Z","updated":"2021-03-17T07:39:58.775Z","comments":true,"path":"2021/03/15/春招面试/JDK动态代理和CGLIB动态代理/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/15/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/JDK%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%92%8CCGLIB%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"1、代理模式简介我们使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。 作用代理模式的主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。 2、静态代理静态代理中，我们对目标对象的每个方法的增强都是手动完成的（后面会具体演示代码_），非常不灵活（_比如接口一旦新增加方法，目标对象和代理对象都要进行修改_）且麻烦(_需要对每个目标类都单独写一个代理类)。 实际应用场景非常非常少，日常开发几乎看不到使用静态代理的场景。 上面我们是从实现和应用角度来说的静态代理，从 JVM 层面来说， 静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。 静态代理实现步骤: 定义一个接口及其实现类； 创建一个代理类同样实现这个接口 将目标对象注入进代理类，然后在代理类的对应方法调用目标类中的对应方法。这样的话，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。 见下面代码展示：1.定义发送短信的接口 123public interface SmsService &#123; String send(String message);&#125; 2.实现发送短信的接口 123456public class SmsServiceImpl implements SmsService &#123; public String send(String message) &#123; System.out.println(&quot;send message:&quot; + message); return message; &#125;&#125; 3.创建代理类并同样实现发送短信的接口 123456789101112131415161718public class SmsProxy implements SmsService &#123; private final SmsService smsService; public SmsProxy(SmsService smsService) &#123; this.smsService = smsService; &#125; @Override public String send(String message) &#123; //调用方法之前，我们可以添加自己的操作 System.out.println(&quot;before method send()&quot;); smsService.send(message); //调用方法之后，我们同样可以添加自己的操作 System.out.println(&quot;after method send()&quot;); return null; &#125;&#125; 4.实际使用 123456789101112131415161718public class SmsProxy implements SmsService &#123; private final SmsService smsService; public SmsProxy(SmsService smsService) &#123; this.smsService = smsService; &#125; @Override public String send(String message) &#123; //调用方法之前，我们可以添加自己的操作 System.out.println(&quot;before method send()&quot;); smsService.send(message); //调用方法之后，我们同样可以添加自己的操作 System.out.println(&quot;after method send()&quot;); return null; &#125;&#125; 运行上述代码之后，控制台打印出： 123before method send()send message:javaafter method send() 通过输出结果看出，我们已经增加了SmsServiceImpl 的send()方法。 3、动态代理3.1、JDK动态代理机制3.1.1 介绍：在 Java 动态代理机制中 InvocationHandler 接口和 Proxy 类是核心。Proxy 类中使用频率最高的方法是：newProxyInstance() ，这个方法主要用来生成一个代理对象。这个方法一共有 3 个参数： loader :类加载器，用于加载代理对象。 interfaces : 被代理类实现的一些接口。 h : 实现了 InvocationHandler 接口的对象。 要实现动态代理的话，还必须需要实现InvocationHandler 来自定义处理逻辑。 当我们的动态代理对象调用一个方法时候，这个方法的调用就会被转发到实现InvocationHandler 接口类的 invoke 方法来调用。 也就是说：你通过Proxy 类的 newProxyInstance() 创建的代理对象在调用方法的时候，实际会调用到实现InvocationHandler 接口的类的 invoke()方法。 你可以在 invoke() 方法中自定义处理逻辑，比如在方法执行前后做什么事情。 3.1.2 JDK 动态代理类使用步骤 定义一个接口及其实现类； 自定义 InvocationHandler 并重写invoke方法，在 invoke 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑； 通过 Proxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 方法创建代理对象； 3.1.3 代码示例1.定义发送短信的接口 123public interface SmsService &#123; String send(String message);&#125; 2.实现发送短信的接口 123456public class SmsServiceImpl implements SmsService &#123; public String send(String message) &#123; System.out.println(&quot;send message:&quot; + message); return message; &#125;&#125; 3.定义一个 JDK 动态代理类 12345678910111213141516171819202122232425import java.lang.reflect.InvocationHandler;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;public class DebugInvocationHandler implements InvocationHandler &#123; /** * 代理类中的真实对象 */ private final Object target; public DebugInvocationHandler(Object target) &#123; this.target = target; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException &#123; //调用方法之前，我们可以添加自己的操作 System.out.println(&quot;before method &quot; + method.getName()); Object result = method.invoke(target, args); //调用方法之后，我们同样可以添加自己的操作 System.out.println(&quot;after method &quot; + method.getName()); return result; &#125;&#125; invoke() 方法: 当我们的动态代理对象调用原生方法的时候，最终实际上调用到的是 invoke() 方法，然后 invoke() 方法代替我们去调用了被代理对象的原生方法。4.获取代理对象的工厂类 123456789public class JdkProxyFactory &#123; public static Object getProxy(Object target) &#123; return Proxy.newProxyInstance( target.getClass().getClassLoader(), // 目标类的类加载 target.getClass().getInterfaces(), // 代理需要实现的接口，可指定多个 new DebugInvocationHandler(target) // 代理对象对应的自定义 InvocationHandler ); &#125;&#125; getProxy() ：主要通过Proxy.newProxyInstance（）方法获取某个类的代理对象5.实际使用 12SmsService smsService = (SmsService) JdkProxyFactory.getProxy(new SmsServiceImpl());smsService.send(&quot;java&quot;); 运行上述代码之后，控制台打印出： 123before method sendsend message:javaafter method send 3.2、CGLIB 动态代理机制3.2.1 介绍JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。 为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。 CGLIB(Code Generation Library)是一个基于ASM的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。CGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了CGLIB， 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。 在 CGLIB 动态代理机制中 MethodInterceptor 接口和 Enhancer 类是核心。 你需要自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法。 123456public interface MethodInterceptorextends Callback&#123; // 拦截被代理类中的方法 public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args, MethodProxy proxy) throws Throwable;&#125; obj :被代理的对象（需要增强的对象） method :被拦截的方法（需要增强的方法） args :方法入参 methodProxy :用于调用原始方法 你可以通过 Enhancer类来动态获取被代理类，当代理类调用方法的时候，实际调用的是 MethodInterceptor 中的 intercept 方法。 3.2.2 CGLIB 动态代理类使用步骤 定义一个类； 自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似； 通过 Enhancer 类的 create()创建代理类 3.2.3 代码示例不同于 JDK 动态代理不需要额外的依赖。CGLIB(Code Generation Library) 实际是属于一个开源项目，如果你要使用它的话，需要手动添加相关依赖。 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 1.实现一个使用阿里云发送短信的类 12345678package github.javaguide.dynamicProxy.cglibDynamicProxy;public class AliSmsService &#123; public String send(String message) &#123; System.out.println(&quot;send message:&quot; + message); return message; &#125;&#125; 2.自定义 MethodInterceptor（方法拦截器） 12345678910111213141516171819202122232425262728import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * 自定义MethodInterceptor */public class DebugMethodInterceptor implements MethodInterceptor &#123; /** * @param o 被代理的对象（需要增强的对象） * @param method 被拦截的方法（需要增强的方法） * @param args 方法入参 * @param methodProxy 用于调用原始方法 */ @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; //调用方法之前，我们可以添加自己的操作 System.out.println(&quot;before method &quot; + method.getName()); Object object = methodProxy.invokeSuper(o, args); //调用方法之后，我们同样可以添加自己的操作 System.out.println(&quot;after method &quot; + method.getName()); return object; &#125;&#125; 3.获取代理类import net.sf.cglib.proxy.Enhancer; public class CglibProxyFactory { public static Object getProxy(Class&lt;?&gt; clazz) &#123; // 创建动态代理增强类 Enhancer enhancer = new Enhancer(); // 设置类加载器 enhancer.setClassLoader(clazz.getClassLoader()); // 设置被代理类 enhancer.setSuperclass(clazz); // 设置方法拦截器 enhancer.setCallback(new DebugMethodInterceptor()); // 创建代理类 return enhancer.create(); &#125; } 12345```**4.实际使用**```javaAliSmsService aliSmsService = (AliSmsService) CglibProxyFactory.getProxy(AliSmsService.class);aliSmsService.send(&quot;java&quot;); 运行上述代码之后，控制台打印出： 123before method sendsend message:javaafter method send 3.3 JDK 动态代理和 CGLIB 动态代理对比 JDK 动态代理只能只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。 静态代理和动态代理的对比 灵活性 ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！ JVM 层面 ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。 参考代理模式详解","categories":[{"name":"春招面试","slug":"春招面试","permalink":"https://xmmarlowe.github.io/categories/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"动态代理","slug":"动态代理","permalink":"https://xmmarlowe.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"JDK","slug":"JDK","permalink":"https://xmmarlowe.github.io/tags/JDK/"}],"author":"Marlowe"},{"title":"代理模式之静态代理和动态代理","slug":"春招面试/代理模式之静态代理和动态代理","date":"2021-03-15T06:20:34.000Z","updated":"2021-03-16T01:57:29.483Z","comments":true,"path":"2021/03/15/春招面试/代理模式之静态代理和动态代理/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/15/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86%E5%92%8C%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"","categories":[],"tags":[],"author":"Marlowe"},{"title":"Spring是什么？","slug":"Spring/Spring是什么？","date":"2021-03-11T07:42:30.000Z","updated":"2021-04-15T09:09:24.575Z","comments":true,"path":"2021/03/11/Spring/Spring是什么？/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/11/Spring/Spring%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"轻量级的开源的J2EE框架。它是一个容器框架，用来装JavaBean，也是一个中间层框架，可以起连接作用。","text":"轻量级的开源的J2EE框架。它是一个容器框架，用来装JavaBean，也是一个中间层框架，可以起连接作用。 Spring是什么？Spring是一个轻量级的控制反转(IOC)和面向切面(AOP)的容器框架。 1、Spring的核心是一个轻量级（Lightweight）的容器（Container）。2、Spring是实现IoC（Inversion of Control）容器和非入侵性（No intrusive）的框架。3、Spring提供AOP（Aspect-oriented programming）概念的实现方式。4、Spring提供对持久层（Persistence）、事物（Transcation）的支持。5、Spring供MVC Web框架的实现，并对一些常用的企业服务API（Application Interface）提供一致的模型封装。6、Spring提供了对现存的各种框架（Structs、JSF、Hibernate、Ibatis、Webwork等）相整合的方案。总之，Spring是一个全方位的应用程序框架。 对AOP的理解AOP:将程序中的交叉业务逻辑(比如安全，日志，事务等)，封装成一个切面,然后注入到目标对象(具体业务逻辑)中去。AOP可以对某个对象或某些对象的功能进行增强，比如对象中的方法进行增强，可以在执行某个方法之前额外的做一些事情，在某个方法执行之后额外的做一些事情。 对IoC的理解IOC:控制反转也叫依赖注入，IOC利用java反射机制，所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是耦合性太强，IOC则是统一交给spring来管理创建，将对象交给容器管理，你只需要在spring配置文件中配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类。 控制反转:没有引入IOC容器之前，对象A依赖于对象B,那么对象A在初始化或者运行到某一点的时候， 自己必须主动去创建对象B或者使用已经创建的对象B。无论是创建还是使用对象B,控制权都在自己手上。 引入IOC容器之后,对象A与对象B之间失去了直接联系,当对象A运行到需要对象B的时候，IOC容器 会主动创建一个对象B注入到对象A需要的地方。 通过前后的对比，不难看出来:对象A获得依赖对象B的过程,由主动行为变为了被动行为,控制权颠倒过来，这就是”控制反转”这个名称的由来。 全部对象的控制权全部上缴给”第三方”IOC容器,所以，IOC容器成了整个系统的关键核心，它起到了一种类似“粘合剂”的作用，把系统中的所有对象粘合在一起发挥作用，如果没有这个”粘合剂”，对象与对象之间会彼此失去联系,这就是有人把IOC容器比喻成”粘合剂”的由来。 依赖注入:“获得依赖对象的过程被反转了”。控制被反转之后，获得依赖对象的过程由自身管理变为了由IOC容器主动注入。依赖注入是实现IOC的方法,就是由IOC容器在运行期间，动态地将某种依赖关系注入到对象之中。","categories":[{"name":"春招面试","slug":"春招面试","permalink":"https://xmmarlowe.github.io/categories/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/tags/Spring/"}],"author":"Marlowe"},{"title":"线程池中阻塞队列的作用?为什么是先添加列队而不是先创建最大线程?线程池中线程复用原理","slug":"并发/线程池中阻塞队列的作用-为什么是先添加列队而不是先创建最大线程-线程池中线程复用原理","date":"2021-03-11T06:35:10.000Z","updated":"2021-04-16T07:00:55.029Z","comments":true,"path":"2021/03/11/并发/线程池中阻塞队列的作用-为什么是先添加列队而不是先创建最大线程-线程池中线程复用原理/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/11/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E7%9A%84%E4%BD%9C%E7%94%A8-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E5%85%88%E6%B7%BB%E5%8A%A0%E5%88%97%E9%98%9F%E8%80%8C%E4%B8%8D%E6%98%AF%E5%85%88%E5%88%9B%E5%BB%BA%E6%9C%80%E5%A4%A7%E7%BA%BF%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E7%BA%BF%E7%A8%8B%E5%A4%8D%E7%94%A8%E5%8E%9F%E7%90%86/","excerpt":"","text":"线程池中阻塞队列的作用?一般的队列只能保证作为一个有限长度的缓冲区,如果超出了缓冲长度,就无法保留当前的任务了,阻塞队列通过阻塞可以保留住当前想要继续入队的任务。阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程,使得线程进入wait状态,释放cpu资源。阻塞队列自带阻塞和唤醒的功能,不需要额外处理,无任务执行时,线程池利用阻塞队列的take方法挂起,从而维持核心线程的存活、不至于一直占用cpu资源 为什么是先添加列队而不是先创建最大线程?在创建新线程的时候,是要获取全局锁的,这个时候其它的就得阻塞,影响了整体效率。 就好比一个饭店里面有10个(core)正式工的名额,最多招10个正式工,要是任务超过正式工人数(task&gt;core)的情况下,工厂领导(线程池)不是首先扩招工人,还是这10人,但是任务可以稍微积压一下,即先放到队列去(代价低) 。10个正式工慢慢干,迟早会千完的,要是任务还在继续增加,超过正式工的加班忍耐极限了(队列满了) ,就的招外包帮忙了(注意是临时工)要是正式工加上外包还是不能完成任务,那新来的任务就会被领导拒绝了(线程池的拒绝策略) 线程池中线程复用原理线程池将线程和任务进行解耦,线程是线程,任务是任务,摆脱了之前通过Thread创建线程时的一个线程必须对应一个任务的限制。 在线程池中,同一个线程可以从阻塞队列中不断获取新任务来执行,其核心原理在于线程池对Thread进行了封装,并不是每次执行任务都会调用Thread.start（)来创建新线程, 而是让每个线程去执行一个”循环任务”,在这个”循环任务”中不停检查是否有任务需要被执行,如果有则直接执行,也就是调用任务中的run方法,将run方法当成一个普通的方法执行,通过这种方式只使用固定的线程就将所有任务的run方法串联起来。 参考线程池中阻塞队列的作用?为什么是先添加列队而不是先创建最大线程?线程池中线程复用原理","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"为什么用线程池？线程池参数解释","slug":"并发/为什么用线程池？线程池参数解释","date":"2021-03-11T02:26:10.000Z","updated":"2021-03-19T12:59:25.220Z","comments":true,"path":"2021/03/11/并发/为什么用线程池？线程池参数解释/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/11/%E5%B9%B6%E5%8F%91/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%EF%BC%9F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A/","excerpt":"","text":"为什么使用线程池? 1、降低资源消耗;提高线程利用率,降低创建和销毁线程的消耗。 2、提高响应速度;任务来了,直接有线程可用可执行,而不是先创建线程,再执行。 3、提高线程的可管理性;线程是稀缺资源,使用线程池可以统一分配调优监控。 corePoolsize代表核心线程数,也就是正常情况下创建工作的线程数,这些线程创建后并不会消除,而是一种常驻线程 maxinumPoolsize代表的是最大线程数,它与核心线程数相对应,表示最大允许被创建的线程数,比如当前任务较多,将核心线程数都用完了,还无法满足需求时,此时就会创建新的线程,但是线程池内线程总数不会超过最大线程数 keepAliverime, unit表示超出核心线程数之外的线程的空闲存活时间,也就是核心线程不会消除,但是超出核心线程数的部分线程如果空闲一定的时间则会被消除,我们可以通过setKeepAliveTime来设置空闲时间 workQueue用来存放待执行的任务,假设我们现在核心线程都已被使用,还有任务进来则全部放入队列,直到整个队列被放满但任务还再持续进入则会开始创建新的线程 ThreadFactory实际上是一个线程工厂,用来生产线程执行任务。我们可以选择使用默认的创建工厂,产生的线程都在同一个组内,拥有相同的优先级,且都不是守护线程。当然我们也可以选择自定义线程工厂,一般我们会根据业务来制定不同的线程工厂 Handler任务拒绝策略,有两种情况,第一种是当我们调用shutdown等方法关闭线程池后,这时候即使线程池内部还有没执行完的任务正在执行,但是由于线程池已经关闭,我们再继续想线程池提交任务就会遭到拒绝。另一种情况就是当达到最大线程数,线程池已经没有能力继续处理新提交的任务时,这时也就拒绝 执行线程池的流程线程池任务开始执行时，会先判断线程池是否已满，如果没有满则创建核心线程执行，如果核心线程已满那么就判断任务队列是否已满，未满则将任务放入到队列中，如果已满则判断最大线程数是否打到，未达到则创建临时线程执行，临时吸线程如果空闲时我们可以设置超时时间也就是KeepAliveTime，当达到超时时间临时线程则被回收。如果全部线程空间都满了那么我们可设置拒绝策略来处理。 参考文档为什么要用线程池，线程池的参数解释","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"并发的三大特性","slug":"并发/并发的三大特性","date":"2021-03-11T00:31:23.000Z","updated":"2021-04-14T07:33:57.274Z","comments":true,"path":"2021/03/11/并发/并发的三大特性/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/11/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E7%9A%84%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/","excerpt":"","text":"原子性定义：原子性是指在一个操作中cpu不可以在中途暂停然后再调度,即不被中断操作，要不全部执行完成，要不都不执行。就好比转账，从账户A向账户B转1000元，那么必然包括2个操作:从账户A减去1000元,往账户B加上1000元。2个操作必须全部完成。 关键字：synchronized 1234private long count = 0;public void calc()&#123; count++;&#125; 在上述代码中，将执行以下步骤： 将count从主存读取到工作内存中的副本 +1运算 将结果写入工作内存 将工作内存中的值刷回主存(什么时候刷入由操作系统决定，不确定的) 可见性定义：当一个线程修改了共享变量的值，其他线程会马上知道这个修改。当其他线程要读取这个变量的时候，最终会去内存中读取，而不是从缓存中读取。 关键字：volatile、synchronized、final 有序性定义：虚拟机在进行代码编译时，对于那些改变顺序之后不会对最终结果造成影响的代码，虚拟机不一定会按照我们写的代码的顺序来执行，有可能将他们重排序。实际上，对于有些代码进行重排序之后，虽然对变量的值没有造成影响，但有可能会出现线程安全问题。 1234567891011121314int a = 0;boolean flag = false;public void write()&#123; a = 2; //1 //1 flag = true; //2 //4&#125; public void multiply()&#123; if(flag)&#123; //3 //2 int res = a * a; //4 //3 &#125; &#125; 1234567如果按照1234执行，结果为：a = 2;res = 4;如果按照1423执行，结果为：a = 2;res = 0; 关键字：volatile、synchronized volatile本身就包含了禁止指令重排序的语义，而synchronized关键字是由“一个变量在同一时刻只允许一条线程对其进行lock操作”这条规则明确的。 小结 synchronized关键字同时满足以上三种特性，但是volatile关键字不满足原子性。 在某些情况下，volatile的同步机制的性能确实要优于锁(使用synchronized关键字或java.util.concurrent包里面的锁)，因为volatile的总开销要比锁低。 我们判断使用volatile还是加锁的唯一依据就是volatile的语义能否满足使用的场景(原子性) 参考文档高并发的三大特性—原子性、有序性、可见性","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/tags/%E5%B9%B6%E5%8F%91/"}],"author":"Marlowe"},{"title":"ThreadLocal原理和使用场景","slug":"并发/ThreadLocal原理和使用场景","date":"2021-03-10T07:31:01.000Z","updated":"2021-04-28T13:17:27.035Z","comments":true,"path":"2021/03/10/并发/ThreadLocal原理和使用场景/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/10/%E5%B9%B6%E5%8F%91/ThreadLocal%E5%8E%9F%E7%90%86%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"每一个Thread对象均含有一个ThreadLocalMap类型的成员变量threadLocals,它存储本线程中所有ThreadLocal对象及其对应的值。","text":"每一个Thread对象均含有一个ThreadLocalMap类型的成员变量threadLocals,它存储本线程中所有ThreadLocal对象及其对应的值。 简介ThreadLocal保存当前线程的变量，当前线程内，可以任意获取，但每个线程往ThreadLocal中读写数据是线程隔离，互不影响。 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 1234567891011ThreadLocalMap源码：static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ThreadLocalMap由一个个Entry对象构成Entry继承自WeakReference&lt;ThreadLoca1&lt;?&gt;&gt;,一个Entry由ThreadLocal对象和Object构成。由此可见，Entry 的key是ThreadLocal对象,并且是一个弱引用。 当没指向key的强引用后, 该key就会被垃圾收集器回收。 注意 ThreadLocal存在内存泄露强引用(StrongReference)： 使用最普遍的引用(new),一个对象具有强引用，不会被GC回收。当JVM的内存空间不足时，宁愿抛出OutOfMemoryError使得程序异常终止也不愿意回收具有强引用的存活着的对象。如果想取消强引用和某个对象之间的关联，可以显式的将引用赋值为null，这样可以是JVM在合适的时候回收该对象。 弱引⽤(WeakReference)： 在GC的时候，不管内存空间足不足都会回收这个对象。可以在缓存中使用弱引用。 当我们了解完，ThreadLocalMap 中使⽤的 key是以弱引用指向ThreadLocal，这时候垃圾回收器线程运行，发现弱引用就回收，key被回收。ThreadLocalMap里对应的Entry的key会变成null。这时候尴尬出现了，ThreadLocalMap里对应的Entry的value则无法被访问到，value作为一个强引用垃圾回收不到也不能被访问，即造成了内存溢出。 ThreadLocal正确的使用方法(如何解决内存泄漏) 在使用完ThreadLocal后，主动调用remove方法进行清理。 将ThreadLocal变量定义成private static, 这样就一 直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值， 进而清除掉。 123456789ThreadLocal set()方法public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 当执行set方法时，ThreadLocal首先会获取当前线程对象，然后获取当前线程的ThreadLocalMap对象。再以当前ThreadLocal对象为key,将值存储进ThreadLocalMap对象中。 1234567891011121314ThreadLocal get()方法public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; get方法执行过程类似。ThreadLocal首先会获取当前线程对象,然后获取当前线程的ThreadLocalMap对象。再以当前ThreadLocal对象为key,获取对应的value。 由于每一条线程均含有各自私有的ThreadLocalMap容器，这些容器相互独立互不影响，因此不会存在线程安全性问题，从而也无需使用同步机制来保证多条线程访问容器的互斥性。 使用场景：1、在进行对象跨层传递的时候，使用ThreadLocal可以避免多次传递，打破层次间的约束。2、线程间数据隔离。3、进行事务操作，用于存储线程事务信息。4、数据库连接，Session会话管理。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"浅谈对守护线程的理解","slug":"并发/浅谈对守护线程的理解","date":"2021-03-10T07:13:51.000Z","updated":"2021-04-20T05:27:37.839Z","comments":true,"path":"2021/03/10/并发/浅谈对守护线程的理解/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/10/%E5%B9%B6%E5%8F%91/%E6%B5%85%E8%B0%88%E5%AF%B9%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"为所有非守护线程提供服务的线程，也称后台线程，任何一个守护线程都是整个JVM中所有非守护线程的保姆。","text":"为所有非守护线程提供服务的线程，也称后台线程，任何一个守护线程都是整个JVM中所有非守护线程的保姆。 守护线程的作用：举例，GC垃圾回收线程:就是一个经典的守护线程, 当我们的程序中不再有任何运行的Thread,程序就不会再产生垃圾，垃圾回收器也就无事可做,所以当垃圾回收线程是JVM.上仅剩的线程时,垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统中的可回收资源。 （守护线程必须在线程开启前设置！）thread.setDaemon(true)必须在thread.start()之前设置,否则会抛出一个llegalThreadStateException异常。 你不能把正在运行的常规线程设置为守护线程。 在守护(deamon)线程中产生的新线程也是守护线程","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"浅谈对线程安全的理解","slug":"并发/浅谈对线程安全的理解","date":"2021-03-10T06:46:58.000Z","updated":"2021-04-16T06:54:46.196Z","comments":true,"path":"2021/03/10/并发/浅谈对线程安全的理解/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/10/%E5%B9%B6%E5%8F%91/%E6%B5%85%E8%B0%88%E5%AF%B9%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"当多个线程访问一个对象时，如果不进行额外的同步控制或其他的协调操作，调用这个对象的行为都可以获得正确的结果，我们就说这个对象是线程安全的。","text":"当多个线程访问一个对象时，如果不进行额外的同步控制或其他的协调操作，调用这个对象的行为都可以获得正确的结果，我们就说这个对象是线程安全的。 简单来说，多线程情况下和单线程执行结果一样，就是线程安全的。 堆是进程和线程共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆,但是用完了要还给操作系统，要不然就是内存泄漏。 在Java中，堆是Java虚拟机所管理的内存中最大的一块,是所有线程共享的一块内存区域，在虚拟机启动时创建。堆所存在的内存区域的唯一目的就是存放对象实例， 几乎所有的对象实例以及数组都在这里分配内存。 栈是每个线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立,因此，栈是线程安全的。 操作系统在切换线程的时候会自动切换栈。栈空间不需要在高级语言里面显式的分配和释放。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"sleep(),wait(),join(),yield()的区别","slug":"并发/sleep-wait-join-yield-的区别","date":"2021-03-09T09:12:15.000Z","updated":"2021-04-20T14:24:45.528Z","comments":true,"path":"2021/03/09/并发/sleep-wait-join-yield-的区别/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/09/%E5%B9%B6%E5%8F%91/sleep-wait-join-yield-%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"sleepwaitjoinyield 锁池所有需要竞争同步锁的线程都会放在锁池当中，比如当前对象的锁已经被其中一个线程得到，则其他线程需要在这个锁池等待，当前面的线程释放同步锁后锁池中的线程去竞争同步锁，当某个线程得到后会进入就绪队列进行等待cpu资源分配。 等待池当我们调用wait()方法后，线程会放到等待池当中，等待池的线程是不会去竞争同步锁。只有调用了notify()或notifyAll()后等待的线程才会开始去竞争锁，notify()是随机从等待池中选出一个线程放到锁池，而notifyAll()是将等待池的所有线程放到锁池当中。 sleep是Thread类的静态本地方法，wait是Object类的本地方法。 sleep方法不会释放lock，但wait会释放，而且会加入到等待队列中。1sleep就是把cpu的执行资格和执行权释放出去，不在运行此线程，当定时时间结束后再取回cpu资源，参与cpu的调度，获取到cpu资源后就可以继续运行了。而如果sleep时线程有所，那么sleep不会释放这个锁，而是把锁带着进入了冻结状态，也就是说其他需要这个锁的线程根本不可能获取到这个锁。也即无法执行程序。如果在睡眠期间其他线程调用了这个线程的interrupt方法，那么这个线程也会抛出interruptexception异常返回，这个点和wait是一样的。 sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字。 sleep不需要被唤醒(休眠之后退出阻塞),但是wait需要(不指定时间需要被别人中断)。 sleep一般用于当前线程休眠，或者轮循暂停操作，wait则多用于多线程之间的通信。 sleep会放出cpu执行时间且强制上下文切换，而wait则不一定，wait后可能还是有机会重新竞争到锁继续执行的。 yield() 执行后线程直接进入就绪状态，马上释放了cpu的执行权，但是依然保留了cpu的执行资格，所以有可能cpu下次进行线程调度还会让这个线程获取到执行权继续执行。 join() 执行后线程进入阻塞状态，例如在线程B中调用线程A的join()，则线程B会进入到阻塞队列，直到线程A结束或中断线程。 1234567891011121314151617public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;222222&quot;); &#125; &#125;); t1.start(); t1.join(); // 这行代码需等t1线程执行结束才会继续执行 System.out.println(&quot;11111&quot;); &#125; 123结果：22222211111","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"线程的生命周期包括哪几个阶段","slug":"并发/线程的生命周期包括哪几个阶段","date":"2021-03-09T08:49:03.000Z","updated":"2021-04-20T05:34:51.318Z","comments":true,"path":"2021/03/09/并发/线程的生命周期包括哪几个阶段/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/09/%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%8C%85%E6%8B%AC%E5%93%AA%E5%87%A0%E4%B8%AA%E9%98%B6%E6%AE%B5/","excerpt":"线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。","text":"线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。 新建（New）：就是刚使用new方法，new出来的线程。 就绪（Runnable）：就是调用的线程的start()方法。该状态的线程位于可运行线程池中，等待获取CPU的使用权。 运行（Running）：当就绪的线程被调度并获得CPU资源时，便进入运行状态。 阻塞（Blocked）：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待CPU分配资源进入运行状态。 销毁（Dead）：线程执行完了或者因异常退出了run方法，该线程结束生命周期。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"什么是字节码？采用字节码的好处是什么？","slug":"春招面试/什么是字节码？采用字节码的好处是什么？","date":"2021-03-09T02:43:58.000Z","updated":"2021-03-10T14:29:28.660Z","comments":true,"path":"2021/03/09/春招面试/什么是字节码？采用字节码的好处是什么？/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/09/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/%E4%BB%80%E4%B9%88%E6%98%AF%E5%AD%97%E8%8A%82%E7%A0%81%EF%BC%9F%E9%87%87%E7%94%A8%E5%AD%97%E8%8A%82%E7%A0%81%E7%9A%84%E5%A5%BD%E5%A4%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"字节码：在Java中，供虚拟机理解的代码叫做字节码(也就是Java代码编译后的.class文件),他不面向任何特定的处理器，只面向虚拟机。","text":"字节码：在Java中，供虚拟机理解的代码叫做字节码(也就是Java代码编译后的.class文件),他不面向任何特定的处理器，只面向虚拟机。 Java中的编译器和解释器Java 中引入了虚拟机的概念，即在机器和编译程序之间加入了一层抽象的虚拟的机器。这台虚拟的机器在任何平台上都提供给编译程序一个的共同的接口。编译程序只需要面向虚拟机，生成虚拟机能够理解的代码，然后由解释器来将虚拟机代码转换为特定系统的机器码执行。在 Java 中，这种供虚拟机理解的代码叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。每一种平台的解释器是不同的，但是实现的虚拟机是相同的。Java 源程序经过编译器编译后变成字节码，字节码由虚拟机解释执行，虚拟机将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行。这也就是解释了 Java 的编译与解释并存的特点。 采用字节码的好处Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。","categories":[{"name":"春招面试","slug":"春招面试","permalink":"https://xmmarlowe.github.io/categories/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/"}],"tags":[],"author":"Marlowe"},{"title":"JWTUtils","slug":"自定义工具类/JWTUtils","date":"2021-03-02T06:36:50.000Z","updated":"2021-03-02T06:45:38.286Z","comments":true,"path":"2021/03/02/自定义工具类/JWTUtils/","link":"","permalink":"https://xmmarlowe.github.io/2021/03/02/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7%E7%B1%BB/JWTUtils/","excerpt":"Jwt 学习","text":"Jwt 学习 引入jwt依赖12345&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.4.0&lt;/version&gt;&lt;/dependency&gt; 编写JWTUtils工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class JWTUtils &#123; private static final String SIGN = &quot;!QDJHFKSHFK:&quot;; /** * 生成token header.payload.sign * * @param map * @return */ public static String getToken(Map&lt;String, String&gt; map) &#123; Calendar instance = Calendar.getInstance(); // 默认7天过期 instance.add(Calendar.DATE, 7); // 创建jwt builder JWTCreator.Builder builder = JWT.create(); // payload map.forEach((k, v) -&gt; &#123; builder.withClaim(k, v); &#125;); // 指定令牌过期时间和签名 String token = builder.withExpiresAt(instance.getTime()) .sign(Algorithm.HMAC256(SIGN)); return token; &#125; /** * 验证token 合法性 * * @param token */ public static void verify(String token) &#123; JWT.require(Algorithm.HMAC256(SIGN)).build().verify(token); &#125; /** * 获取token信息 * * @param token * @return */ public static DecodedJWT getTokenInfo(String token) &#123; DecodedJWT verify = JWT.require(Algorithm.HMAC256(SIGN)).build().verify(token); return verify; &#125;&#125; 编写JWTinterceptor类12345678910111213141516171819202122232425262728293031public class JWTInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Map&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); // 获取请求头令牌 String token = request.getHeader(&quot;token&quot;); try &#123; // 验证令牌 JWTUtils.verify(token); // 放行请求 return true; &#125; catch (SignatureVerificationException e) &#123; e.printStackTrace(); map.put(&quot;msg&quot;, &quot;无效签名&quot;); &#125; catch (TokenExpiredException e) &#123; e.printStackTrace(); map.put(&quot;msg&quot;, &quot;token过期&quot;); &#125; catch (AlgorithmMismatchException e) &#123; e.printStackTrace(); map.put(&quot;msg&quot;, &quot;token算法不一致&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); map.put(&quot;msg&quot;, &quot;token 无效&quot;); &#125; map.put(&quot;state&quot;, false); String json = new ObjectMapper().writeValueAsString(map); response.setContentType(&quot;application/json;charset=UTF-8&quot;); response.getWriter().println(json); return false; &#125;&#125; 编写拦截器配置类123456789@Configurationpublic class InterceptorConfig implements WebMvcConfigurer&#123; @Override public vpid addInterceptors(InterceptorRegistry registry)&#123; registry.addInterceptor(new JWTInterceptor()) .addPathPatterns(&quot;/xxx&quot;) .excludePathPatterns(&quot;/xxx&quot;); &#125;&#125;","categories":[{"name":"自定义工具类","slug":"自定义工具类","permalink":"https://xmmarlowe.github.io/categories/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7%E7%B1%BB/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://xmmarlowe.github.io/tags/JWT/"}],"author":"Marlowe"},{"title":"浅谈DNS协议","slug":"计算机网络/浅谈DNS协议","date":"2021-02-22T16:40:29.000Z","updated":"2021-05-06T08:27:40.905Z","comments":true,"path":"2021/02/23/计算机网络/浅谈DNS协议/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%85%E8%B0%88DNS%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"简介DNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住IP。通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 DNS查找过程DNS解析是一个递归查询的过程。 浏览器查找域名的IP地址(DNS查找过程：浏览器缓存、路由器缓存、DNS缓存) 浏览器向web服务器发送一个HTTP请求(cookies会随着请求发送给服务器) 服务器处理请求(请求 处理请求 &amp; 它的参数、cookie、生成一个HTML相应) 服务器发回一个HTML响应 浏览器开始显示HTML 查找www.google.com的IP地址过程 首先在本地域名服务器中查询IP地址，如果没有找到的情况下，本地域名服务器会向根域名服务器发送一个请求，如果根域名服务器也不存在该域名时，本地域名会向com顶级域名服务器发送一个请求，依次类推下去。直到最后本地域名服务器得到google的IP地址并把它缓存到本地，供下次查询使用。从上述过程中，可以看出网址的解析是一个从右向左的过程: com -&gt; google.com -&gt; www.google.com。但是你是否发现少了点什么，根域名服务器的解析过程呢？事实上，真正的网址是 www.google.com.，并不是我多打了一个.，这个.对应的就是根域名服务器，默认情况下所有的网址的最后一位都是.，既然是默认情况下，为了方便用户，通常都会省略，浏览器在请求DNS的时候会自动加上，所有网址真正的解析过程为: . -&gt; .com -&gt; google.com. -&gt; www.google.com.。 使用的协议 TCP：与服务器建立TCP连接 IP：建立TCP协议时，需要发送数据，发送数据在网络层使用IP协议 OSPF：开放最短路径优先协议,是由Internet工程任务组开发的路由选择协议 ARP：路由器在与服务器通信时，需要将ip地址转换为MAC地址，需要使用ARP协议 HTTP：在TCP建立完成后，使用HTTP协议访问网页 DNS的记录类型 其中CNAME解析就是将域名解析到另一个域名。 DNS负载均衡不知道大家有没有思考过一个问题: DNS返回的IP地址是否每次都一样？如果每次都一样是否说明你请求的资源都位于同一台机器上面，那么这台机器需要多高的性能和储存才能满足亿万请求呢？其实真实的互联网世界背后存在成千上百台服务器，大型的网站甚至更多。但是在用户的眼中，它需要的只是处理他的请求，哪台机器处理请求并不重要。 DNS可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等，这种过程就是DNS负载均衡，又叫做DNS重定向。大家耳熟能详的CDN(Content Delivery Network)就是 利用DNS的重定向技术，DNS服务器会返回一个跟用户最接近的点的IP地址给用户，CDN节点的服务器负责响应用户的请求，提供所需的内容。 DNS劫持与污染DNS劫持DNS决定的是我们的域名将解析到哪一个IP地址的记录，是基于UDP协议的一种应用层协议。这种攻击的前提是攻击者掌控了你的本地DNS服务器 攻击者劫持了DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致用户对该域名地址进行访问的时候，由原来的IP地址转入到修改后的IP地址。结果就是让正确的网址不能解析或者是被解析到另一个网址的IP，实现获取用户资料或者破坏原有网址正常服务的目的。 简单来说就是就是ip解析请求发送到了其他DNS服务器了，给你返回了一个错误的ip。 DNS污染又称域名服务器缓存投毒（DNS cache poisoning），它和DNS劫持的不同之处，在于污染针对的是DNS缓存，是在查询信息到达目标DNS服务器前，经过的节点上做手脚，而劫持是DNS服务器中记录的是错误的内容。 参考浅谈DNS协议 前端经典面试题: 从输入URL到页面加载发生了什么？","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://xmmarlowe.github.io/tags/DNS/"}],"author":"Marlowe"},{"title":"TCP流量控制、拥塞控制","slug":"计算机网络/TCP流量控制、拥塞控制","date":"2021-02-22T16:24:56.000Z","updated":"2021-04-23T14:26:00.979Z","comments":true,"path":"2021/02/23/计算机网络/TCP流量控制、拥塞控制/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/","excerpt":"","text":"一、流量控制什么是流量控制？流量控制的目的？如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止分组丢失，它是构成TCP可靠性的一方面。 如何实现流量控制？由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。 流量控制引发的死锁？怎么避免死锁的发生？当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。 二、拥塞控制和流量控制的区别拥塞控制： 拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：（ 1 ）慢开始、拥塞避免（ 2 ）快重传、快恢复。 流量控制： 流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止分组丢失的。 三、拥塞控制的算法（一）慢开始算法：发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。 慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。 这里用报文段的个数作为拥塞窗口的大小举例说明慢开始算法，实际的拥塞窗口大小是以字节为单位的。如下图： 从上图可以看到，一个传输轮次所经历的时间其实就是往返时间RTT，而且每经过一个传输轮次（transmission round），拥塞窗口cwnd就加倍。 为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：当cwnd &lt; ssthresh时，使用慢开始算法。当cwnd&gt;ssthresh时，改用拥塞避免算法。当cwnd=ssthresh时，慢开始与拥塞避免算法任意 注意，这里的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，然后逐渐增大，这当然比按照大的cwnd一下子把许多报文段突然注入到网络中要“慢得多”。 （二）拥塞避免算法：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。 无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 整个拥塞控制的流程如下图： （1）拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16（2）执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长（3）假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法。当cwnd=12=ssthresh时，改为执行拥塞避免算法 关于 乘法减小（Multiplicative Decrease）和加法增大（Additive Increase）： “乘法减小”指的是无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半，并执行慢开始算法，所以当网络频繁出现拥塞时，ssthresh下降的很快，以大大减少注入到网络中的分组数。“加法增大”是指执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止过早出现拥塞。常合起来成为AIMD算法。 注意：“拥塞避免”并非完全能够避免了阻塞，而是使网络比较不容易出现拥塞。 （三）快重传算法：快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。 如下图： （四）快恢复算法：快重传配合使用的还有快恢复算法，有以下两个要点： 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法，考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。如下图：TCP Reno版本是目前使用最广泛的版本。 注意：在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用。 参考TCP流量控制、拥塞控制","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://xmmarlowe.github.io/tags/TCP/"}],"author":"Marlowe"},{"title":"HTTP 和 HTTPS","slug":"计算机网络/HTTP-和-HTTPS-","date":"2021-02-22T14:11:06.000Z","updated":"2021-05-03T12:47:53.967Z","comments":true,"path":"2021/02/22/计算机网络/HTTP-和-HTTPS-/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP-%E5%92%8C-HTTPS-/","excerpt":"","text":"什么是HTTP？超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议,所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法。 HTTP的特点 无状态： 协议对客户端没有状态存储，对事物处理没有“记忆”能力，比如访问一个网站需要反复进行登录操作。 无连接： HTTP/1.1之前，由于无状态特点，每次请求需要通过TCP三次握手四次挥手，和服务器重新建立连接。比如某个客户机在短时间多次请求同一个资源，服务器并不能区别是否已经响应过用户的请求，所以每次需要重新响应请求，需要耗费不必要的时间和流量。 基于请求和响应： 基本的特性，由客户端发起请求，服务端响应。 简单快速、灵活 通信使用明文、请求和响应不会对通信方进行确认、无法保护数据的完整性。 HTTP报文格式 请求方法: GET和POST是最常见的HTTP方法,初次以外还包括 DELETE、HEAD、OPTIONS、PUT、TRACE，不过现在大部分的浏览器只支持GET和POST。 请求对应的URL地址： 他和报文头的Host属性,组合起来是一个完整的请求URL。 协议名称和版本号。 报文头： 有若干个属性,形式为key:val,服务端据此获取客户端信息。 是报文体： 它将一个页面表单中的组件值通过param1=val1&amp;parma=2的键值对形式编码成一个格式化串,它承载多个请求参数的数据,不但报文头可以传递请求参数,URL也可以通过/chapter15/user.html? param1=value1&amp;param2=value2”的方式传递数值。 HTTP响应报文 报文协议及版本； 状态码及状态描述； 响应报文头: 也是由多个属性组成； 响应报文体: 即我们要的数据。 HTTP通信传输 客户端输入URL回车，DNS解析域名得到服务器的IP地址，服务器在80端口监听客户端请求，端口通过TCP/IP协议（可以通过Socket实现）建立连接。HTTP属于TCP/IP模型中的运用层协议，所以通信的过程其实是对应数据的入栈和出栈。 报文从运用层传送到运输层，运输层通过TCP三次握手和服务器建立连接，四次挥手释放连接。 什么是HTTPS？HTTPS是身披SSL外壳的HTTP。HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。 PS:TLS是传输层加密协议，前身是SSL协议，由网景公司1995年发布，有时候两者不区分。 HTTPS的特点 内容加密： 采用混合加密技术，中间者无法直接查看明文内容。 验证身份： 通过证书认证客户端访问的是自己的服务器。 保护数据完整性： 防止传输的内容被中间人冒充或者篡改。 HTTPS的缺点 HTTPS的握手协议比较费时，所以会影响服务的响应速度以及吞吐量。 HTTPS也并不是完全安全的。他的证书体系其实并不是完全安全的。并且HTTPS在面对DDOS这样的攻击时，几乎起不到任何作用。 证书需要费钱，并且功能越强大的证书费用越高。 HTTP和HTTPS的区别 端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。 安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等； 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。 如何保证HTTP传输安全性？目前大多数网站和app的接口都是采用http协议，但是http协议很容易就通过抓包工具监听到内容，甚至可以篡改内容，为了保证数据不被别人看到和修改，可以通过以下几个方面避免。 重要的数据，要加密： 比如用户名密码，我们需要加密，这样即使被抓包监听，他们也不知道原始数据是什么（如果简单的md5，是可以暴力破解），所以加密方法越复杂越安全，根据需要，常见的是 md5(不可逆)，aes（可逆），自由组合吧,你还可以加一些特殊字符啊，没有做不到只有想不到， 举例：username = aes(username), pwd = MD5(pwd + username);。。。。。 非重要数据，要签名： 签名的目的是为了防止篡改，比如http://www.xxx.com/getnews?id=1，获取id为1的新闻，如果不签名那么通过id=2,就可以获取2的内容等等。怎样签名呢？通常使用sign，比如原链接请求的时候加一个sign参数，sign=md5(id=1)，服务器接受到请求，验证sign是否等于md5(id=1)，如果等于说明正常请求。这会有个弊端，假如规则被发现，那么就会被伪造，所以适当复杂一些，还是能够提高安全性的。 登录态怎么做： http是无状态的，也就是服务器没法自己判断两个请求是否有联系，那么登录之后，以后的接口怎么判定是否登录呢，简单的做法，在数据库中存一个token字段（名字随意），当用户调用登陆接口成功的时候，就将该字段设一个值，（比如aes(过期时间)），同时返回给前端，以后每次前端请求带上该值，服务器首先校验是否过期，其次校验是否正确，不通过就让其登陆。（redis 做这个很方便哦，key有过期时间）。 HTTPS为什么安全？因为HTTPS保证了传输安全，防止传输过程被监听、防止数据被窃取，可以确认网站的真实性。 HTTPS的传输过程是怎样的?客户端发起HTTPS请求，服务端返回证书，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数，通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。 Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。 客户端拿到证书，证书校验通过后，用系统内置的CA证书，进行对证书解密，拿到公钥。 客户端的浏览器与Web服务器开始协商SSL/TLS连接的安全等级，也就是信息加密的等级。 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 Web服务器利用自己的私钥解密出会话密钥。 Web服务器利用会话密钥对数据进行对称加密，再与客户端进程通讯。 HTTP长连接、短连接在HTTP/1.0中默认使用短连接。 也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接， 用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。 实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 CA证书的作用CA证书就是服务端自己有一份公钥私钥，把公钥给CA证书，获得一份数字证书，当客户端来请求时，就拿这个数字证书给客户端，客户端再通过CA认证算法拿到公钥，再进行后续操作。 为什么需要证书?防止”中间人“攻击，同时可以为网站提供身份证明。 验证证书安全性过程 当客户端收到这个证书之后，使用本地配置的权威机构的公钥对证书进行解密得到服务端的公钥和证书的数字签名，数字签名经过CA公钥解密得到证书信息摘要。 然后证书签名的方法计算一下当前证书的信息摘要，与收到的信息摘要作对比，如果一样，表示证书一定是服务器下发的，没有被中间人篡改过。因为中间人虽然有权威机构的公钥，能够解析证书内容并篡改，但是篡改完成之后中间人需要将证书重新加密，但是中间人没有权威机构的私钥，无法加密，强行加密只会导致客户端无法解密，如果中间人强行乱修改证书，就会导致证书内容和证书签名不匹配。 使用HTTPS会被抓包吗？会被抓包，HTTPS只防止用户在不知情的情况下通信被监听，如果用户主动授信，是可以构建“中间人”网络，代理软件可以对传输内容进行解密。 SSL/TLS协议的基本过程客户端发出请求（ClientHello） 支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数，稍后用于生成”对话密钥”。 支持的加密方法，比如RSA公钥加密。 支持的压缩方法。服务器回应（SeverHello） 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数，稍后用于生成”对话密钥”。 确认使用的加密方法，比如RSA公钥加密，此时带有公钥信息。 服务器证书。客户端回应 一个随机数pre-master key。该随机数用服务器公钥加密，防止被窃听。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。 上面客户端回应中第一项的随机数，是整个握手阶段出现的第三个随机数，又称”pre-master key”。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把”会话密钥”。 SSL建立连接过程 client向server发送请求 https://baidu.com， 然后连接到server的443端口，发送的信息主要是随机值1和客户端支持的加密算法。 server接收到信息之后给予client响应握手信息，包括随机值2和匹配好的协商加密算法，这个加密算法一定是client发送给server加密算法的子集。 随即server给client发送第二个响应报文是数字证书。服务端必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面，这套证书其实就是一对公钥和私钥。传送证书，这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间、服务端的公钥，第三方证书认证机构(CA)的签名，服务端的域名信息等内容。 客户端解析证书，这部分工作是由客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值（预主秘钥）。 客户端认证证书通过之后，接下来是通过随机值1、随机值2和预主秘钥组装会话秘钥。然后通过证书的公钥加密会话秘钥。 传送加密信息，这部分传送的是用证书加密后的会话秘钥，目的就是让服务端使用秘钥解密得到随机值1、随机值2和预主秘钥。 服务端解密得到随机值1、随机值2和预主秘钥，然后组装会话秘钥，跟客户端会话秘钥相同。 客户端通过会话秘钥加密一条消息发送给服务端，主要验证服务端是否正常接受客户端加密的消息。 同样服务端也会通过会话秘钥加密一条消息回传给客户端，如果客户端能够正常接受的话表明SSL层连接建立完成了。 一些问题那么为什么一定要用三个随机数，来生成”会话密钥”呢？为了保证绝对随机，不相信服务器或者客户端的随机数，而是才用三个随机数再进行一定算法计算出真正的会话密钥(对称加密)。 为什么不都使用对称加密而是才有非对称与对称加密组合？因为非对称加密比较耗费性能，比对称加密慢了几倍甚至几百倍，所以才有了对称加密进行最终的数据加密。 参考HTTP与HTTPS详解 HTTP和HTTPS协议，看一篇就够了","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://xmmarlowe.github.io/tags/HTTP/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://xmmarlowe.github.io/tags/HTTPS/"}],"author":"Marlowe"},{"title":"TCP三次握手、四次挥手","slug":"计算机网络/TCP三次握手、四次挥手","date":"2021-02-22T13:47:45.000Z","updated":"2021-04-29T13:31:21.144Z","comments":true,"path":"2021/02/22/计算机网络/TCP三次握手、四次挥手/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/","excerpt":"","text":"三次握手客户端和服务端通信前要进行连接，“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。 从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。 三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 所以三次握手就能确认双发收发功能都正常，缺一不可。 为什么不两次握手？一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。 如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。 为什么不四次握手？四次握手的过程就是把第二次握手拆分成了两次，一次服务器响应ACK，再一次发回SYN来确定客户端的接收是否正常。因为握手没有数据传输，所以可以放在一次就可以完成的没有必要用两次。 四次挥手 为什么需要四次挥手？任何⼀⽅都可以在数据传送结束后发出连接释放的通知，待对⽅确认后进⼊半关闭状态。当另⼀⽅也没有数据再发送的时候，则发出连接释放通知，对⽅确认后就完全关闭了TCP连接。 举个例⼦：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着⾃⼰的节奏结束通话，于是 B 可能⼜巴拉巴拉说了⼀通，最后B 说“我说完了”，A 回答“知道了”，这样通话才算结束。 为什么客户端最后还要等待2MSL？MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。 TIME_WAIT 状态产生的原因1）为实现TCP全双工连接的可靠释放 由TCP状态变迁图可知，假设发起主动关闭的一方（client）最后发送的ACK在网络中丢失，由于TCP协议的重传机制，执行被动关闭的一方（server）将会重发其FIN，在该FIN到达client之前，client必须维护这条连接状态，也就说这条TCP连接所对应的资源（client方的local_ip,local_port）不能被立即释放或重新分配，直到另一方重发的FIN达到之后，client重发ACK后，经过2MSL时间周期没有再收到另一方的FIN之后，该TCP连接才能恢复初始的CLOSED状态。如果主动关闭一方不维护这样一个TIME_WAIT状态，那么当被动关闭一方重发的FIN到达时，主动关闭一方的TCP传输层会用RST包响应对方，这会被对方认为是有错误发生，然而这事实上只是正常的关闭连接过程，并非异常。 2）为使旧的数据包在网络因过期而消失 为说明这个问题，我们先假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：(local_ip, local_port, remote_ip,remote_port)，因某些原因，我们先关闭，接着很快以相同的四元组建立一条新连接。本文前面介绍过，TCP连接由四元组唯一标识，因此，在我们假设的情况中，TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间先释放再建立的过程对其来说是“感知”不到的。这样就可能发生这样的情况：前一条TCP连接由local peer发送的数据到达remote peer后，会被该remot peer的TCP传输层当做当前TCP连接的正常数据接收并向上传递至应用层（而事实上，在我们假设的场景下，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。作为一种可靠的传输协议，TCP必须在协议层面考虑并避免这种情况的发生，这正是TIME_WAIT状态存在的第2个原因。 3）总结具体而言，local peer主动调用close后，此时的TCP连接进入TIME_WAIT状态，处于该状态下的TCP连接不能立即以同样的四元组建立新连接，即发起active close的那方占用的local port在TIME_WAIT期间不能再被重新分配。由于TIME_WAIT状态持续时间为2MSL，这样保证了旧TCP连接双工链路中的旧数据包均因过期（超过MSL）而消失，此后，就可以用相同的四元组建立一条新连接而不会发生前后两次连接数据错乱的情况。 Closed状态。。。。为什么建立连接是三次握手，关闭连接确是四次挥手呢？建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 如果已经建立了连接，但是客户端突然出现故障了怎么办？TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 问题TCP初始序列号为什么是随机的？在TCP的三次握手中，采用随机产生的初始化序列号进行请求，这样做主要是出于网络安全的因素着想。如果不是随机产生初始序列号，黑客将会以很容易的方式获取到你与其他主机之间通信的初始化序列号，并且伪造序列号进行攻击，这已经成为一种很常见的网络攻击手段。 参考TCP的三次握手与四次挥手两张动图-彻底明白TCP的三次握手与四次挥手","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://xmmarlowe.github.io/tags/TCP/"}],"author":"Marlowe"},{"title":"网络5层模型和7层模型","slug":"计算机网络/网络5层模型和7层模型","date":"2021-02-22T12:51:17.000Z","updated":"2021-04-23T14:25:25.645Z","comments":true,"path":"2021/02/22/计算机网络/网络5层模型和7层模型/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C5%E5%B1%82%E6%A8%A1%E5%9E%8B%E5%92%8C7%E5%B1%82%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"体系结构图 七层OSI 物理层(Physical Laye)主要功能： 利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。作用： 实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 数据链路层(Data Link Layer)主要功能： 通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。作用： 接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层；并且，还负责处理接收端发回的确认帧的信息，以便提供可靠的数据传输。 网络层(Network Layer)主要功能： 通过路由选择算法，为报文或分组通过通信子网选择最适当的路径。该层控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。作用： 解决不同子网间的通信。例如在广域网之间通信时，必然会遇到路由（即两节点间可能有多条路径）选择问题。 运输层(Transport Layer)主要功能： 负责向两台主机进程之间的通信提供通⽤的数据传输服务。作用： 传输连接管理：提供建立、维护和拆除传输连接的功能。传输层在网络层的基础上为高层提供“面向连接”和“面向无接连”的两种服务。 处理传输差错：提供可靠的“面向连接”和不太可靠的“面向无连接”的数据传输服务、差错控制和流量控制。在提供“面向连接”服务时，通过这一层传输的数据将由目标设备确认，如果在指定的时间内未收到确认信息，数据将被重发。会话层(Session Layer) *主要功能：** 向两个实体的表示层提供建立和使用连接的方法。将不同实体之间的表示层的连接称为会话。因此会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。 *作用：** 会话管理：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。例如提供单方向会话或双向同时会话，并管理会话中的发送顺序，以及会话所占用时间的长短。 会话流量控制：提供会话流量控制和交叉会话功能。 寻址：使用远程地址建立会话连接。l 出错控制：从逻辑上讲会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠正错误。会话控制和远程过程调用均属于这一层的功能。但应注意，此层检查的错误不是通信介质的错误，而是磁盘空间、打印机缺纸等类型的高级错误。表示层(Presentation Layer) *主要功能：** 对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层。其主要功能是“处理用户信息的表示问题，如编码、数据格式转换和加密解密”等。 *作用：** 数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。 数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。 压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。 数据的加密和解密：可以提高网络的安全性。应用层(Application Layer)应用层提供的协议有Telnet，SMTP，FTP等等。 *主要功能：** 通过应⽤进程间的交互来完成特定⽹络应⽤ *作用：** 用户接口：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。 实现各种服务：该层具有的各种应用程序可以完成和实现用户请求的各种服务。 四层TCP网络接口层包括用于协作IP数据在已有网络介质上传输的协议。实际上TCP/IP标准并不定义与ISO数据链路层和物理层相对应的功能。相反，它定义像地址解析协议(Address Resolution Protocol,ARP)这样的协议，提供TCP/IP协议的数据结构和实际物理硬件之间的接口。 网际层对应于OSI七层参考模型的网络层。本层包含IP协议、RIP协议(Routing Information Protocol，路由信息协议)，负责数据的包装、寻址和路由。同时还包含网间控制报文协议(Internet Control Message Protocol,ICMP)用来提供网络诊断信息。 传输层对应于OSI七层参考模型的传输层，它提供两种端到端的通信服务。其中TCP协议(Transmission Control Protocol)提供可靠的数据流运输服务，UDP协议(Use Datagram Protocol)提供不可靠的用户数据报服务。 应用层对应于OSI七层参考模型的应用层和表达层。因特网的应用层协议包括Finger、Whois、FTP(文件传输协议)、Gopher、HTTP(超文本传输协议)、Telent(远程终端协议)、SMTP(简单邮件传送协议)、IRC(因特网中继会话)、NNTP（网络新闻传输协议）等，这也是本书将要讨论的重点。 参考OSI的七层模型","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"OSI","slug":"OSI","permalink":"https://xmmarlowe.github.io/tags/OSI/"}],"author":"Marlowe"},{"title":"Ping过程解析","slug":"计算机网络/Ping过程解析","date":"2021-02-16T12:03:07.000Z","updated":"2021-04-23T14:25:48.246Z","comments":true,"path":"2021/02/16/计算机网络/Ping过程解析/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/16/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/Ping%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90/","excerpt":"","text":"Ping过程解析 A电脑（192.168.2.135）发起ping请求，ping 192.168.2.179 A电脑广播发起ARP请求，查询 192.168.2.179的MAC地址。 B电脑应答ARP请求，向A电脑发起单向应答，告诉A电脑自己的MAC地址为90:A4:DE:C2:DF:FE 知道了MAC地址后，开始进行真正的ping请求，由于B电脑可以根据A电脑发送的请求知道源MAC地址，所有就可以根据源MAC地址进行响应了。 ARP协议的主要功能是什么arp协议的主要功能是将IP地址解析为物理地址。使用ARP协议可根据网络层IP数据包包头中的IP地址信息解析出目标硬件地址（MAC地址）信息，以保证通信的顺利进行。 总结我们分析了一次完整的ping请求过程，ping命令是依托于ICMP协议的，ICMP协议的存在就是为了更高效的转发IP数据报和提高交付成功的机会。ping命令除了依托于ICMP，在局域网下还要借助于ARP协议，ARP协议能根据IP地址查出计算机MAC地址。ARP是有缓存的，为了保证ARP的准确性，计算机会更新ARP缓存。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"Ping","slug":"Ping","permalink":"https://xmmarlowe.github.io/tags/Ping/"}],"author":"Marlowe"},{"title":"计算机网络分层的目的","slug":"计算机网络/计算机网络分层的目的","date":"2021-02-15T14:02:13.000Z","updated":"2021-04-23T14:25:20.015Z","comments":true,"path":"2021/02/15/计算机网络/计算机网络分层的目的/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82%E7%9A%84%E7%9B%AE%E7%9A%84/","excerpt":"简单讲讲计算机网络分层的原因…","text":"简单讲讲计算机网络分层的原因… 分层的优点 各层之间是独立的。 某一层并不需要知道它的下一层是如何实现的，而仅仅需要知道该层通过层间的接口（即界面）所提供的服务。由于每一层只实现一种相对独立的功能，因而可将一个难以处理的复杂问题分解为若干个较容易处理的更小一些的问题。这样，整个问题的复杂程度就下降了。 灵活性好。 当任何一层发生变化时（例如由于技术的变化），只要层间接口关系保持不变，则在这层以上或以下各层均不受影响。此外，对某一层提供的服务还可进行修改。 当某层提供的服务不再需要时，甚至可以将这层取消。 结构上可分割开。 各层都可以采用最合适的技术来实现。 易于实现和维护。 这种结构使得实现和调试一个庞大而又复杂的系统变得易于处理，因为整个的系统已被分解为若干个相对独立的子系统。 能促进标准化工作。 因为每一层的功能及其所提供的服务都已有了精确的说明。 分层时应注意使每一层的功能非常明确 若层数太少，就会使每一层的协议太复杂。 但层数太多又会在描述和综合各层功能的系统工程任务时遇到较多的困难。 通常各层所要完成的功能主要有以下一些（可以只包括一种，也可以包括多种）： 差错控制使相应层次对等方的通信更加可靠。 流量控制发送端的发送速率必须使接收端来得及接收，不要太快。 分段和重装发送端将要发送的数据块划分为更小的单位，在接收端将其还原。 复用和分用发送端几个高层会话复用一条低层的连接，在接收端再进行分用。 连接建立和释放交换数据前先建立一条逻辑连接，数据传送结束后释放连接。 分层的缺点没有考虑网络实际应用的复杂性，有的层的功能不明确。不能适应市场的需要。分层过多。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络分层","slug":"网络分层","permalink":"https://xmmarlowe.github.io/tags/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82/"}],"author":"Marlowe"},{"title":"TCP 协议如何保证可靠传输","slug":"计算机网络/TCP-协议如何保证可靠传输","date":"2021-02-10T10:34:42.000Z","updated":"2021-04-23T14:25:51.641Z","comments":true,"path":"2021/02/10/计算机网络/TCP-协议如何保证可靠传输/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93/","excerpt":"","text":"可靠传输 应用数据被分割成 TCP 认为最适合发送的数据块。 TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 TCP 的接收端会丢弃重复的数据。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 ARQ协议自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。 1.停止等待ARQ协议停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。 优缺点： 优点： 简单 缺点： 信道利用率低，等待时间长 1) 无差错情况: 发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。 2) 出现差错情况（超时重传）: 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 自动重传请求 ARQ 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续 ARQ 协议 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。 3) 确认丢失和确认迟到 确认丢失 ： 确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。 确认迟到 ： 确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。 2.连续ARQ协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 优缺点： 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://xmmarlowe.github.io/tags/TCP/"}],"author":"Marlowe"},{"title":"get和post的区别","slug":"计算机网络/get和post的区别","date":"2021-02-10T02:42:32.000Z","updated":"2021-04-23T14:25:31.729Z","comments":true,"path":"2021/02/10/计算机网络/get和post的区别/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/get%E5%92%8Cpost%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"功能不同 get是从服务器上获取数据。 post是向服务器传送数据。 过程不同 get是把参数数据队列加到提交表单的ACTION属性所指的URL中，值和表单内各个字段一一对应，在URL中可以看到。 post是通过HTTP post机制，将表单内各个字段与其内容放置在HTML HEADER内一起传送到ACTION属性所指的URL地址。用户看不到这个过程。 获取值不同 对于get方式，服务器端用Request.QueryString获取变量的值。 对于post方式，服务器端用Request.Form获取提交的数据。 传送数据量不同 get传送的数据量较小，不能大于2KB。 post传送的数据量较大，一般被默认为不受限制。但理论上，IIS4中最大量为80KB，IIS5中为100KB。 安全性不同 get安全性非常低。 post安全性较高。 如果没有加密，他们安全级别都是一样的，随便一个监听器都可以把所有的数据监听到。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"get","slug":"get","permalink":"https://xmmarlowe.github.io/tags/get/"},{"name":"post","slug":"post","permalink":"https://xmmarlowe.github.io/tags/post/"}],"author":"Marlowe"},{"title":"HTTP常见状态码","slug":"计算机网络/HTTP常见状态码","date":"2021-02-09T14:54:22.000Z","updated":"2021-04-23T14:25:41.104Z","comments":true,"path":"2021/02/09/计算机网络/HTTP常见状态码/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%B8%B8%E8%A7%81%E7%8A%B6%E6%80%81%E7%A0%81/","excerpt":"常见的http状态码：100,200,202,204,301,302,404,500,502,503,504…","text":"常见的http状态码：100,200,202,204,301,302,404,500,502,503,504… 123451xx:指示信息-表示请求已接收，继续处理。2xx:成功-表示请求已被成功接收、理解、接受。3xx:重定向-要完成请求必须进行更进一步 的操作。4xx:客户端错误-请求有语法错误或请求无法实现。5xx:服务器端错误-服务器未能实现合法的请求。 100： 这个状态码是告诉客户端应该继续发送请求，这个临时响应是用来通知客户端的，部分的请求服务器已经接受，但是客户端应继续发送求请求的剩余部分，如果请求已经完成，就忽略这个响应，而且服务器会在请求完成后向客户发送一个最终的结果 200： 这个是最常见的http状态码，表示服务器已经成功接受请求，并将返回客户端所请求的最终结果 202： 表示服务器已经接受了请求，但是还没有处理，而且这个请求最终会不会处理还不确定 204： 服务器成功处理了请求，但没有返回任何实体内容 ，可能会返回新的头部元信息 301: 永久性转移(Permanently Moved) 客户端请求的网页已经永久移动到新的位置，当链接发生变化时，返回301代码告诉客户端链接的变化，客户端保存新的链接，并向新的链接发出请求，以返回请求结果。 302: 暂时性转移(Temporarily Moved ) 转向可能会有URL规范化及网址劫持的问题。可能被搜索引擎判为可疑转向，甚至认为是作弊。 比如： 由于搜索引擎排名算法只是程序而不是人，在遇到302重定向的时候，并不能像人一样的去准确判定哪一个网址更适当，这就造成了网址URL劫持的可能性。也就是说，一个不道德的人在他自己的网址A做一个302重定向到你的网址B，出于某种原因， Google搜索结果所显示的仍然是网址A，但是所用的网页内容却是你的网址B上的内容，这种情况就叫做网址URL劫持。你辛辛苦苦所写的内容就这样被别人偷走了。 404： 请求失败，客户端请求的资源没有找到或者是不存在 500： 服务器遇到未知的错误，导致无法完成客户端当前的请求。 502：(Bad Gateway) 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503： 服务器由于临时的服务器过载或者是维护，无法解决当前的请求，以上http状态码是服务器经常返回的状态代码，用户只能通过浏览器的状态了解服务器是否正常运行，一般除了错误的状态码，都不会看到服务器的状态码的. 504：(Gateway Time-out) 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://xmmarlowe.github.io/tags/HTTP/"}],"author":"Marlowe"},{"title":"HTTP是不保存状态的协议,如何保存用户状态?","slug":"计算机网络/HTTP是不保存状态的协议-如何保存用户状态","date":"2021-02-09T14:42:30.000Z","updated":"2021-04-23T14:25:44.357Z","comments":true,"path":"2021/02/09/计算机网络/HTTP是不保存状态的协议-如何保存用户状态/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E6%98%AF%E4%B8%8D%E4%BF%9D%E5%AD%98%E7%8A%B6%E6%80%81%E7%9A%84%E5%8D%8F%E8%AE%AE-%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E7%94%A8%E6%88%B7%E7%8A%B6%E6%80%81/","excerpt":"","text":"HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。 在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。 Cookie 被禁用怎么办? 最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://xmmarlowe.github.io/tags/HTTP/"}],"author":"Marlowe"},{"title":"HTTP 1.0和HTTP 1.1的主要区别是什么?","slug":"计算机网络/HTTP-1-0和HTTP-1-1的主要区别是什么","date":"2021-02-09T14:39:29.000Z","updated":"2021-04-23T14:25:34.592Z","comments":true,"path":"2021/02/09/计算机网络/HTTP-1-0和HTTP-1-1的主要区别是什么/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP-1-0%E5%92%8CHTTP-1-1%E7%9A%84%E4%B8%BB%E8%A6%81%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/","excerpt":"","text":"HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在： 长连接 : 在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。 错误状态响应码: 在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 缓存处理: 在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用: HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://xmmarlowe.github.io/tags/HTTP/"}],"author":"Marlowe"},{"title":"Cookie和Session","slug":"计算机网络/Cookie和Session","date":"2021-02-09T14:35:26.000Z","updated":"2021-04-23T14:25:28.591Z","comments":true,"path":"2021/02/09/计算机网络/Cookie和Session/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/Cookie%E5%92%8CSession/","excerpt":"Cookie的作用是什么? 和Session有什么区别？","text":"Cookie的作用是什么? 和Session有什么区别？ Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。 Cookie 一般用来保存用户信息 比如：①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。 Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"Cookie","slug":"Cookie","permalink":"https://xmmarlowe.github.io/tags/Cookie/"},{"name":"Session","slug":"Session","permalink":"https://xmmarlowe.github.io/tags/Session/"}],"author":"Marlowe"},{"title":"TCP和UDP的区别，以及使用场景","slug":"计算机网络/TCP和UDP的区别，以及使用场景","date":"2021-02-07T14:50:57.000Z","updated":"2021-04-27T14:47:58.873Z","comments":true,"path":"2021/02/07/计算机网络/TCP和UDP的区别，以及使用场景/","link":"","permalink":"https://xmmarlowe.github.io/2021/02/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%92%8CUDP%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"","text":"UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等 TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。 视频通话为什么采用UDPUDP 没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://xmmarlowe.github.io/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"https://xmmarlowe.github.io/tags/UDP/"}],"author":"Marlowe"},{"title":"B+树存储数据计算","slug":"数据库/B-树存储数据计算","date":"2021-01-23T13:50:52.000Z","updated":"2021-04-27T13:33:16.249Z","comments":true,"path":"2021/01/23/数据库/B-树存储数据计算/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/23/%E6%95%B0%E6%8D%AE%E5%BA%93/B-%E6%A0%91%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97/","excerpt":"B+树存储数据量计算…","text":"B+树存储数据量计算… 问题引入InnoDB一棵B+树可以存放多少行数据？这个问题的简单回答是：约2千万。为什么是这么多呢？因为这是可以算出来的，要搞清楚这个问题，我们先从InnoDB索引数据结构、数据组织方式说起。我们都知道计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。下面几张图可以帮你理解最小存储单元：文件系统中一个文件大小只有1个字节，但不得不占磁盘上4KB的空间。 innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是16384（16k）的整数倍。 磁盘扇区、文件系统、InnoDB存储引擎都有各自的最小存储单元。 在MySQL中我们的InnoDB页的大小默认是16k，当然也可以通过参数设置： 1show variables like &#x27;innodb_page_size&#x27; 数据表中的数据都是存储在页中的，所以一个页中能存储多少行数据呢？假设一行数据的大小是1k，那么一个页可以存放16行这样的数据。 如果数据库只按这样的方式存储，那么如何查找数据就成为一个问题，因为我们不知道要查找的数据存在哪个页中，也不可能把所有的页遍历一遍，那样太慢了。所以人们想了一个办法，用B+树的方式组织这些数据。如图所示： 我们先将数据记录按主键进行排序，分别存放在不同的页中（为了便于理解我们这里一个页中只存放3条记录，实际情况可以存放很多），除了存放数据的页以外，还有存放键值+指针的页，如图中page number=3的页，该页存放键值和指向数据页的指针，这样的页由N个键值+指针组成。当然它也是排好序的。这样的数据组织形式，我们称为索引组织表。现在来看下，要查找一条数据，怎么查？ 如select * from user where id=5; 这里id是主键,我们通过这棵B+树来查找，首先找到根页，你怎么知道user表的根页在哪呢？其实每张表的根页位置在表空间文件中是固定的，即page number=3的页（这点我们下文还会进一步证明），找到根页后通过二分查找法，定位到id=5的数据应该在指针P5指向的页中，那么进一步去page number=5的页中查找，同样通过二分查询法即可找到id=5的记录： 现在我们清楚了InnoDB中主键索引B+树是如何组织数据、查询数据的，我们总结一下： InnoDB存储引擎的最小存储单元是页，页可以用于存放数据也可以用于存放键值+指针，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。 索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据； 那么回到我们开始的问题，通常一棵B+树可以存放多少行数据？ 这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。 上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右）。 那么现在我们需要计算出非叶子节点能存放多少指针，其实这也很好算，我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针(根节点)，即16 * 1024 / 14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。 根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170117016=21902400条这样的记录。 所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。 怎么得到InnoDB主键索引B+树的高度？上面我们通过推断得出B+树的高度通常是1-3，下面我们从另外一个侧面证明这个结论。在InnoDB的表空间文件中，约定page number为3的代表主键索引的根页，而在根页偏移量为64的地方存放了该B+树的page level。如果page level为1，树高为2，page level为2，则树高为3。即B+树的高度=page level+1；下面我们将从实际环境中尝试找到这个page level。 在实际操作之前，你可以通过InnoDB元数据表确认主键索引根页的page number为3，你也可以从《InnoDB存储引擎》这本书中得到确认。 1234567SELECTb.name, a.name, index_id, type, a.space, a.PAGE_NOFROMinformation_schema.INNODB_SYS_INDEXES a,information_schema.INNODB_SYS_TABLES bWHEREa.table_id = b.table_id AND a.space &lt;&gt; 0; 执行结果： 可以看出数据库dbt3下的customer表、lineitem表主键索引根页的page number均为3，而其他的二级索引page number为4。 下面我们对数据库表空间文件做想相关的解析： 因为主键索引B+树的根页在整个表空间文件中的第3个页开始，所以可以算出它在文件中的偏移量：(16 * 1024) * 3=49152（16384为页大小）。 另外根据《InnoDB存储引擎》中描述在根页的64偏移量位置前2个字节，保存了page level的值，因此我们想要的page level的值在整个文件中的偏移量为：16384*3+64=49152+64=49216，前2个字节中。 接下来我们用hexdump工具，查看表空间文件指定偏移量上的数据： linetem表的page level为2，B+树高度为page level+1=3； region表的page level为0，B+树高度为page level+1=1； customer表的page level为2，B+树高度为page level+1=3； 这三张表的数据量如下： 总结lineitem表的数据行数为600多万，B+树高度为3，customer表数据行数只有15万，B+树高度也为3。可以看出尽管数据量差异较大，这两个表树的高度都是3，换句话说这两个表通过索引查询效率并没有太大差异，因为都只需要做3次IO。那么如果有一张表行数是一千万，那么他的B+树高度依旧是3，查询效率仍然不会相差太大。 region表只有5行数据，当然他的B+树高度为1。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"B+Tree","slug":"B-Tree","permalink":"https://xmmarlowe.github.io/tags/B-Tree/"}],"author":"Marlowe"},{"title":"初识BufferPoll","slug":"数据库/初识BufferPoll","date":"2021-01-19T08:46:54.000Z","updated":"2021-04-23T14:24:26.920Z","comments":true,"path":"2021/01/19/数据库/初识BufferPoll/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/19/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%9D%E8%AF%86BufferPoll/","excerpt":"","text":"Buffer Pool是什么? 是一块内存区域，当数据库操作数据的时候，把硬盘上的数据加载到buffer pool，不直接和硬盘打交道，操作的是buffer pool里面的数据 数据库的增删改查都是在buffer pool上进行，和undo log/redo log/redo log buffer/binlog一起使用，后续会把数据刷到硬盘上 默认大小 128M 数据页 磁盘文件被分成很多数据页，一个数据页里面有很多行数据 一个数据页默认大小 16K 更新一行数据，实际上是把行数据所在的 数据页 整个加载到buffer pool中 缓存页 buffer pool中存放的数据页我们叫缓存页，和磁盘上的数据页是一一对应的，都是16KB 缓存页的数据，是从磁盘上加载到buffer pool当中的 缓存页描述信息（描述信息块） 存的是数据页所属的表空间号，数据页编号，数据页地址等信息 放在缓存页的前面 每个描述信息块大小是缓存页的5%左右，大约是 1610240.05=800个字节 Buffer Pool初始化 数据库只要一启动，就会按照你设置的Buffer Pool大小，稍微再加大一点，去找操作系统申请一块内存区域，作为Buffer Pool的内存区域 然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的16KB的大小以及对应的800个字节左右的描述数据的大小，在Buffer Pool中划分出来一个一个的缓存页和一个一个的他们对应的描述数据 free链表作用帮助我们找到空闲的缓存页 是一个双向链表，链表节点是空闲的缓存页对应的描述信息块（空的缓存页） 链表上除了描述信息块，还有一个基础节点，存储了free链有多少个描述信息块，也就是有多少个空闲的缓存页 当我们加载数据的时候，会从free链中找到空闲的缓存页，把数据页的表空间号和数据页号写入描述信息块；加载数据到缓存页后，会把缓存页对应的描述信息块从free链表中移除 怎么知道数据页是否被缓存？ 数据库中有一个 数据页缓存哈希表，用表空间号+数据页号，作为一个key，然后缓存页的地址作为value 表空间号+数据页号 = 缓存页地址 什么是脏缓存页？ 被更新过的缓存页，数据和磁盘上的数据不一致，所以是脏缓存页 脏缓存页的数据是要刷到磁盘上的 flush链表作用帮我们找到脏缓存页，也就是需要刷盘的缓存页 是一个双向链表，链表结点是被修改过的缓存页的描述信息块（更新过的缓存页） 和free链表一样，也有一个基础结点，链接首尾结点，并存储了有多少个描述信息块 最后要把flush链表上结点对应的缓存页刷盘，后台线程会在MySQL不怎么繁忙的时候，找个时间把flush链表中的缓存页都刷入磁盘中，这样被你修改过的数据，迟早都会刷入磁盘的；缓存页从flush链表中移除，加入到free链表当中 LRU链表作用用来淘汰不常被访问的缓存页 是一个双向链表，链表结点是 非空的缓存页对应的描述信息块（有数据的缓存页，包含更新过和未更新过的缓存页，范围比flush链表大，flush链表是它的子集） LRU链表分为热数据区和冷数据区，冷数据区占了总链表的37% (5:3) 冷数据区是不常访问的缓存页 热数据区是经常访问的缓存页 加载数据的时候，缓存页会放在冷数据区的头部 数据页加载到缓存页后，在1s之后，访问该缓存页，该缓存页会被移动到热数据区头部 数据页刚加载到缓存页后，在1s之内，访问该缓存页，该缓存页是不会被移动到热数据区头部的 什么时候会lru中的缓存页刷盘并清空？ 当缓存页用完的时候，把冷数据区尾部的缓存页刷盘清空，缓存页对应的信息描述块从lru链表中移除，加入到free链表当中 有一个后台线程，他会运行一个定时任务，这个定时任务每隔一段时间就会把LRU链表的冷数据区域的尾部的一些缓存页，刷入磁盘里去，清空这几个缓存页，把他们加入回free链表去；如果该缓存页也在flush链表中（该缓存页更新过），也需要把该缓存页从flush链表中移除 热数据区的前1/4的缓存页如果被访问，是不会移动到热数据区头部的；后3/4的缓存页被访问了，才会移动到热数据区头部 预读机制 所谓预读机制，说的就是当你从磁盘上加载一个数据页的时候，他可能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去 什么时候会触发预读机制？ 有一个参数是innodb_read_ahead_threshold，他的默认值是56，意思就是如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓存里去 如果Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去 全表扫描的时候，select * from tableName 会把该表所有的数据页都缓存到buffer pool当中 Buffer Pool的缓存页以及几个链表的使用回顾 数据库启动时，会申请内存创建buffer pool，buffer pool分成一个个缓存页及其缓存页描述信息块，描述信息块加入到free链表中 数据加载到一个缓存页，free链表里会移除这个缓存页，然后lru链表的冷数据区域的头部会放入这个缓存页 如果查询了一个缓存页，那么此时就会把这个缓存页在lru链表中移动到热数据区域去，或者在热数据区域中也有可能会移动到头部去 如果更新了缓存页，会把该缓存页加入到flush链表中 如果缓存页不够用了，会把lru冷数据区尾部的缓存页刷盘，清空；该缓存页从lru链表和flush链表中移除，加入到free链表中 mysql后台线程也会定时把lru冷数据区尾部的缓存页刷盘，清空；定时把flush链表中的缓存页刷盘，清空，加入到free链表中 总结 一边不停的加载数据到缓存页里去，不停的查询和修改缓存数据，然后free链表中的缓存页不停的在减少，flush链表中的缓存页不停的在增加，lru链表中的缓存页不停的在增加和移动 另外一边，你的后台线程不停的在把lru链表的冷数据区域的缓存页以及flush链表的缓存页，刷入磁盘中来清空缓存页，然后flush链表和lru链表中的缓存页在减少，free链表中的缓存页在增加 参考buffer pool详解","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"BufferPoll","slug":"BufferPoll","permalink":"https://xmmarlowe.github.io/tags/BufferPoll/"}],"author":"Marlowe"},{"title":"MySQL中SQL是如何执行的？","slug":"数据库/MySQL中SQL是如何执行的？","date":"2021-01-16T13:49:12.000Z","updated":"2021-04-23T14:25:13.433Z","comments":true,"path":"2021/01/16/数据库/MySQL中SQL是如何执行的？/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/16/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E4%B8%ADSQL%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/","excerpt":"简单分析sql的执行过程…","text":"简单分析sql的执行过程… 一、MySQL 基础架构分析MySQL 基本架构概览下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。 先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在 1.2 节中会详细介绍到这些组件的作用。 连接器： 身份认证和权限相关(登录 MySQL 的时候)。 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。 分析器: 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。 优化器： 按照 MySQL 认为最优的方案去执行。 执行器: 执行语句，然后从存储引擎返回数据。 简单来说 MySQL 主要分为 Server 层和存储引擎层： Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。 存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。 Server 层基本组件介绍1) 连接器连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。 主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。 2) 查询缓存(MySQL 8.0 版本后移除)查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。 连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。 MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。 所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。 MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。 3) 分析器MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步： 第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。 第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。 完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。 4) 优化器优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。 可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。 5) 执行器当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。 二、语句分析查询语句说了以上这么多，那么究竟一条 sql 语句是如何执行的呢？其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下： 1select * from tb_student A where A.age=&#x27;18&#x27; and A.name=&#x27; 张三 &#x27;; 结合上面的说明，我们分析下这个语句的执行流程： 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。 通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student,需要查询所有的列，查询条件是这个表的 id=’1’。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。 接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案： 12a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。 那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。 更新语句以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下： 1update tb_student A set A.age=&#x27;19&#x27; where A.name=&#x27; 张三 &#x27;; 我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块式binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志），我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下： 先查询到张三这一条数据，如果有缓存，也是会用到缓存。 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。 更新完成。 这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗? 这是因为最开始 MySQL 并没与 InnoDB 引擎( InnoDB 引擎是其他公司以插件形式插入 MySQL 的) ，MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。 并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？ 先写 redo log 直接提交，然后写 binlog， 假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。 先写 binlog，然后写 redo log， 假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。 如果采用 redo log 两阶段提交的方式就不一样了，写完 binlog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下： 判断 redo log 是否完整，如果判断是完整的，就立即提交。 如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。 这样就解决了数据一致性的问题。 三、总结 MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。 查询语句的执行流程如下：权限校验（如果命中缓存）—&gt;查询缓存—&gt;分析器—&gt;优化器—&gt;权限校验—&gt;执行器—&gt;引擎 更新语句执行流程如下：分析器—-&gt;权限校验—-&gt;执行器—&gt;引擎—redo log(prepare 状态—&gt;binlog—&gt;redo log(commit状态)","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"}],"author":"Marlowe"},{"title":"MySQL什么时候适合建索引，什么时候不适合建索引？","slug":"数据库/MySQL什么时候适合建索引，什么时候不适合建索引？","date":"2021-01-16T13:41:00.000Z","updated":"2021-04-23T14:24:58.220Z","comments":true,"path":"2021/01/16/数据库/MySQL什么时候适合建索引，什么时候不适合建索引？/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/16/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E9%80%82%E5%90%88%E5%BB%BA%E7%B4%A2%E5%BC%95%EF%BC%8C%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%B8%8D%E9%80%82%E5%90%88%E5%BB%BA%E7%B4%A2%E5%BC%95%EF%BC%9F/","excerpt":"","text":"1、什么是索引（本质：数据结构）索引是帮助MySQL高效获取数据的数据结构。 2、优势 提高数据检索的效率，降低数据库IO成本 通过索引对数据进行排序，降低数据排序的成本，降低了CPU的消耗 3、劣势 降低更新表的速度，如对表进行update 、delete、insert等操作时，MySQL不急要保存数据，还要保存一下索引文件每次添加了索引列的字段，都会调整因为更新带来的键值变化后的索引信息。 4、适合创建索引条件 主键自动建立唯一索引 频繁作为查询条件的字段应该建立索引 查询中与其他表关联的字段，外键关系建立索引 单键/组合索引的选择问题，组合索引性价比更高 查询中排序的字段，排序字段若通过索引去访问将大大提高排序效率 查询中统计或者分组字段 5、不适合创建索引条件 表记录少的 经常增删改的表或者字段 where条件里用不到的字段不创建索引 过滤性不好的不适合建索引","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://xmmarlowe.github.io/tags/%E7%B4%A2%E5%BC%95/"}],"author":"Marlowe"},{"title":"MySQL怎么让左模糊查询走索引？","slug":"数据库/MySQL怎么让左模糊查询走索引？","date":"2021-01-16T13:37:00.000Z","updated":"2021-04-23T14:25:06.094Z","comments":true,"path":"2021/01/16/数据库/MySQL怎么让左模糊查询走索引？/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/16/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E6%80%8E%E4%B9%88%E8%AE%A9%E5%B7%A6%E6%A8%A1%E7%B3%8A%E6%9F%A5%E8%AF%A2%E8%B5%B0%E7%B4%A2%E5%BC%95%EF%BC%9F/","excerpt":"","text":"需要做模糊匹配，又要用到索引，索引的最左匹配原则更是不能被打破，这时候可以增加一个字段，这个字段的内容等于USER_NAME字段内容的反转，同时加上这个字段的相关索引，如下： 此时如果是要模糊搜索出用户名后几位有杰这个词的所有用户信息，可以对REVERSE_USER_NAME字段做右模糊查询，效果其实就是和对USER_NAME字段做左模糊查询是一样的，因为二者的内容是相反的，结果如下： 1SELECT * from USER_INFO where REVERSE_USER_NAME like &#x27;杰%&#x27; 总结索引的最左匹配原则不能打破，那么要让左匹配也走索引的话，换个思路，让右匹配的效果和左匹配一样就好了，同时右匹配又能走索引，间接达到了左模糊查询也能走索引的目的。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"}],"author":"Marlowe"},{"title":"left join、right join和join的区别","slug":"数据库/left-join、right-join和join的区别","date":"2021-01-15T09:02:11.000Z","updated":"2021-04-23T14:24:51.139Z","comments":true,"path":"2021/01/15/数据库/left-join、right-join和join的区别/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/15/%E6%95%B0%E6%8D%AE%E5%BA%93/left-join%E3%80%81right-join%E5%92%8Cjoin%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"简要介绍三种连接查询的区别…","text":"简要介绍三种连接查询的区别… 首先，我们先来建两张表，第一张表命名为kemu，第二张表命名为score： left join顾名思义，就是“左连接”，表1左连接表2，以左为主，表示以表1为主，关联上表2的数据，查出来的结果显示左边的所有数据，然后右边显示的是和左边有交集部分的数据。如下： 12345select *from kemuleft join score on kemu.id = score.id 结果集： right join“右连接”，表1右连接表2，以右为主，表示以表2为主，关联查询表1的数据，查出表2所有数据以及表1和表2有交集的数据，如下： 12345select *from kemuright join score on kemu.id = score.id 结果集： join(inner join)join，其实就是“inner join”，为了简写才写成join，两个是表示一个的，内连接，表示以两个表的交集为主，查出来是两个表有交集的部分，其余没有关联就不额外显示出来，这个用的情况也是挺多的，如下： 12345select *from kemujoin score on kemu.id = score.id 结果集： 参考【mySQL】left join、right join和join的区别","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"join","slug":"join","permalink":"https://xmmarlowe.github.io/tags/join/"}],"author":"Marlowe"},{"title":"初识MySQL索引实现原理","slug":"数据库/初识MySQL索引实现原理","date":"2021-01-13T01:13:32.000Z","updated":"2021-04-23T14:24:30.643Z","comments":true,"path":"2021/01/13/数据库/初识MySQL索引实现原理/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/13/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%9D%E8%AF%86MySQL%E7%B4%A2%E5%BC%95%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","excerpt":"MySQL索引的实现原理，以及什么时候会走索引…","text":"MySQL索引的实现原理，以及什么时候会走索引… 目前大部分数据库系统及文件系统都采用B-Tree(B树)或其变种B+Tree(B+树)作为索引结构。B+Tree是数据库系统实现索引的首选数据结构。在MySQL中,索引属于存储引擎级别的概念,不同存储引擎对索引的实现方式是不同的,本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。 在 MySQL 中,索引属于存储引擎级别的概念,不同存储引擎对索引的实现方式是不同的,本文主要讨论 MyISAM 和 InnoDB 两个存储引擎的索引实现方式。 MyISAM 索引实现MyISAM 引擎使用 B+Tree 作为索引结构,叶节点的 data 域存放的是数据记录的地址。 下图是 MyISAM 索引的原理图: 这里设表一共有三列,假设我们以 Col1 为主键,则图 8 是一个 MyISAM 表的主索引(Primary key)示意。可以看出 MyISAM 的索引文件仅仅保存数据记录的地址。 辅助索引 在 MyISAM 中,主索引和辅助索引(Secondary key)在结构上没有任何区别,只是主索引要求 key 是唯一的,而辅助索引的 key 可以重复。如果我们在 Col2 上建立一个辅助索引,则此索引的结构如下图所示： 同样也是一颗 B+Tree,data 域保存数据记录的地址。因此,MyISAM 中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引,如果指定的 Key 存在,则取出其data 域的值,然后以 data 域的值为地址,读取相应数据记录。 MyISAM 的索引方式也叫做“非聚集索引”, 之所以这么称呼是为了与 InnoDB的聚集索引区分。 InnoDB 索引实现虽然 InnoDB 也使用 B+Tree 作为索引结构,但具体实现方式却与 MyISAM 截然不同。 1.第一个重大区别是 InnoDB 的数据文件本身就是索引文件。从上文知道,MyISAM 索引文件和数据文件是分离的,索引文件仅保存数据记录的地址。 而在InnoDB 中,表数据文件本身就是按 B+Tree 组织的一个索引结构,这棵树的叶点data 域保存了完整的数据记录。这个索引的 key 是数据表的主键,因此 InnoDB 表数据文件本身就是主索引。 上图是 InnoDB 主索引(同时也是数据文件)的示意图,可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为 InnoDB 的数据文件本身要按主键聚集。 1.InnoDB 要求表必须有主键(MyISAM 可以没有),如果没有显式指定,则 MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键,如果不存在这种列,则MySQL 自动为 InnoDB 表生成一个隐含字段作为主键,类型为长整形。 同时,请尽量在 InnoDB 上采用自增字段做表的主键。因为 InnoDB 数据文件本身是一棵B+Tree,非单调的主键会造成在插入新记录时数据文件为了维持 B+Tree 的特性而频繁的分裂调整,十分低效,而使用自增字段作为主键则是一个很好的选择。如果表使用自增主键,那么每次插入新的记录,记录就会顺序添加到当前索引节点的后续位置,当一页写满,就会自动开辟一个新的页。如下图所示: 这样就会形成一个紧凑的索引结构,近似顺序填满。由于每次插入时也不需要移动已有数据,因此效率很高,也不会增加很多开销在维护索引上。 2.第二个与 MyISAM 索引的不同是 InnoDB 的辅助索引 data 域存储相应记录主键的值而不是地址。 换句话说,InnoDB 的所有辅助索引都引用主键作为 data 域。例如,下图为定义在 Col3 上的一个辅助索引: 聚集索引这种实现方式使得按主键的搜索十分高效,但是辅助索引搜索需要检索两遍索引:首先检索辅助索引获得主键,然后用主键到主索引中检索获得记录。 引申:为什么不建议使用过长的字段作为主键? 因为所有辅助索引都引用主索引,过长的主索引会令辅助索引变得过大。 联合索引及最左原则联合索引存储数据结构图： 最左原则： 例如联合索引有三个索引字段（A,B,C） 查询条件： （A，，）—会使用索引 （A，B，）—会使用索引 （A，B，C）—会使用索引 （，B，C）—不会使用索引 （，，C）—不会使用索引 什么时候会走索引？一句话，当查询的数据是有序的时候，比如对一个对象数组进行排序后，他会默认从第一个字段到最后一个字段按照顺序排序，如果在上述例子中查询（，B，C），那么B这个属性不一定是有序的，B有序的前提是A有序的情况下，因此不会走索引。 参考MySQL索引实现原理分析","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"},{"name":"InnoDB","slug":"InnoDB","permalink":"https://xmmarlowe.github.io/tags/InnoDB/"},{"name":"MyISAM","slug":"MyISAM","permalink":"https://xmmarlowe.github.io/tags/MyISAM/"}],"author":"Marlowe"},{"title":"InnoDB引擎的特点以及调优","slug":"数据库/InnoDB引擎的特点以及调优","date":"2021-01-12T13:51:03.000Z","updated":"2021-04-23T14:24:48.255Z","comments":true,"path":"2021/01/12/数据库/InnoDB引擎的特点以及调优/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/12/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%BC%95%E6%93%8E%E7%9A%84%E7%89%B9%E7%82%B9%E4%BB%A5%E5%8F%8A%E8%B0%83%E4%BC%98/","excerpt":"谈谈InnoDB的特点，以及InnoDB解决的问题…","text":"谈谈InnoDB的特点，以及InnoDB解决的问题… 简介InnoDB引擎是MySQL数据库的另一个重要的存储引擎,正成为目前MySQL AB所发行的新版的标准,被包含在所有二进制安装包里,和其他存储引擎相比,InnoDB引擎的优点是支持兼容ACID的事务(类似于PostgreSQL),以及参数完整性(有外键)等.现在Innobase实行双认证授权.MySQL5.5.5以后默认的存储引擎都是InnoDB引擎 特点 支持事务(事务是指逻辑上的一组操作,组成这组操作的各个单元,要么全成功,要么全失败) 行级锁定(更新时一般是锁定当前行):通过索引实现,全表扫描仍然会是锁定整个表,注意间隙锁的影响. 读写阻塞与事务隔离级别相关. 具有非常高效的缓存特性,能缓存索引,也能缓存数据. 整个表和主键以Cluster方式存储,组成一颗平衡树. 所有Secondary Index 都会保存主键信息. 支持分区,表空间.类似于Oracle数据库. 支持外键约束,不支持全文索引,5.5之前支持,后面不再支持. 和MyISAM相比,InnoDB对于硬件资源要求比较高. 适用的生产场景 需要支持事务的业务(例如转账,付款) 行级锁定对于高并发有很好的适应能力但是需要保证查询是通过索引完成. 数据读写及更新都比较频繁的场景,如:BBS,SNS,微博,微信等. 数据一致性要求很高的业务.如:转账,充值等. 硬件设备内存较大,可以很好利用InnoDB较好的缓存能力来提高内存利用率,尽可能减少磁盘IO的开销. InnoDB引擎调优精要 主键尽可能小,避免给Secondary index带来过大的空间负担. 避免全表扫描,因为会使用表锁. 尽可能缓存所有的索引和数据,提高响应速度,减少磁盘IO消耗. 在大批量小插入的时候,尽量自己控制事务而不要使用autocommit自动提交,有开关参数可以控制提交. 合理设置Innodb_flush_log_at_trx_commit 参数值,不要过度追求安全性.如果Innodb_flush_log_at_trx_commit的值为0,log buffer每秒就会被刷写日志文件进入磁盘,提交事务的时候不做任何操作. 避免主键更新,因为这会带来大量的数据移动. 参考InnoDB引擎的特点及优化方法","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"InnoDB","slug":"InnoDB","permalink":"https://xmmarlowe.github.io/tags/InnoDB/"}],"author":"Marlowe"},{"title":"聚集索引与非聚集索引","slug":"数据库/聚集索引与非聚集索引","date":"2021-01-12T13:32:56.000Z","updated":"2021-04-27T06:14:35.323Z","comments":true,"path":"2021/01/12/数据库/聚集索引与非聚集索引/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/12/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95%E4%B8%8E%E9%9D%9E%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95/","excerpt":"聚集索引和非聚集索引是mysql数据库中两种主要的索引方式，不同的存储引擎支持索引类型是不一样，那这两种索引有什么不同呢？","text":"聚集索引和非聚集索引是mysql数据库中两种主要的索引方式，不同的存储引擎支持索引类型是不一样，那这两种索引有什么不同呢？ 聚集索引只有同时满足以下两个条件，才会创建聚集索引: 数据存储有序 key值应该是唯一的 每当您在表中应用聚集索引时，它将仅在该表中执行排序。您只能在像主键这样的表中创建一个聚集索引。聚簇索引与字典相同，字典按字母顺序排列数据。 在聚集索引中，索引包含指向数据存储的块而不是数据存储地址的指针。 为什么只能建一个聚集索引？因为聚焦索引决定了表的物理排列顺序，一个表只能有一个物理排列顺序，所以一个表只能建一个聚集索引。 非聚集索引数据存储在一个位置，索引存储在另一位置。 由于数据和非聚集索引是分开存储的，因此在一个表中可以有多个非聚集索引。 在非聚集索引中，索引包含指向数据的指针。 区别聚集索引 | 非聚集索引|:—:|:—:|聚集索引更快| 非聚集索引较慢聚集索引需要较少的内存来进行操作。| 非聚集索引需要更多的内存用于操作。在聚簇索引中，索引是主要数据。| 在非聚集索引中，索引是数据的副本。一个表只能有一个聚集索引。| 一个表可以有多个非聚集索引。聚集索引具有将数据存储在磁盘上的固有能力。| 非聚集索引不具有将数据存储在磁盘上的固有能力。聚集索引存储块指针不是数据指针| 非聚集索引存储值和指向保存数据的实际行的指针。在聚簇索引中，叶节点是实际数据本身。| 在非聚集索引中，叶节点不是实际数据本身，而是仅包含包含的列。在聚簇索引中，聚簇键定义表中数据的顺序。| 在非聚集索引中，索引键定义索引内数据的顺序。聚集索引是一种索引类型，其中表记录在物理上被重新排序以匹配该索引。| 非聚集索引是一种特殊类型的索引，其中索引的逻辑顺序与磁盘上行的物理存储顺序不匹配。 参考mysql聚集索引和非聚集索引之间的区别","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"索引","slug":"索引","permalink":"https://xmmarlowe.github.io/tags/%E7%B4%A2%E5%BC%95/"}],"author":"Marlowe"},{"title":"锁机制与 InnoDB 锁算法","slug":"数据库/锁机制与-InnoDB-锁算法","date":"2021-01-11T02:19:50.000Z","updated":"2021-04-27T01:04:39.836Z","comments":true,"path":"2021/01/11/数据库/锁机制与-InnoDB-锁算法/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%94%81%E6%9C%BA%E5%88%B6%E4%B8%8E-InnoDB-%E9%94%81%E7%AE%97%E6%B3%95/","excerpt":"","text":"MyISAM 和 InnoDB 存储引擎使用的锁 MyISAM 采用表级锁(table-level locking)。 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁 表级锁和行级锁对比 表级锁： MySQL 中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁： MySQL 中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB 存储引擎的锁的算法有三种Record lock：单个行记录上的锁Gap lock：间隙锁，锁定一个范围，不包括记录本身Next-key lock：record+gap 锁定一个范围，包含记录本身","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://xmmarlowe.github.io/tags/%E9%94%81/"},{"name":"InnoDB","slug":"InnoDB","permalink":"https://xmmarlowe.github.io/tags/InnoDB/"}],"author":"Marlowe"},{"title":"Mysql 中 MyISAM 和 InnoDB 的区别有哪些？","slug":"数据库/Mysql-中-MyISAM-和-InnoDB-的区别有哪些？","date":"2021-01-11T01:42:45.000Z","updated":"2021-04-23T14:24:54.435Z","comments":true,"path":"2021/01/11/数据库/Mysql-中-MyISAM-和-InnoDB-的区别有哪些？/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql-%E4%B8%AD-MyISAM-%E5%92%8C-InnoDB-%E7%9A%84%E5%8C%BA%E5%88%AB%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/","excerpt":"","text":"区别： InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败； InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一； 如何选择： 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM； 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使用InnoDB。 系统奔溃后，MyISAM恢复起来更困难，能否接受，不能接受就选 InnoDB； MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的。如果你不知道用什么存储引擎，那就用InnoDB，至少不会差。 参考Mysql 中 MyISAM 和 InnoDB 的区别有哪些？","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"InnoDB","slug":"InnoDB","permalink":"https://xmmarlowe.github.io/tags/InnoDB/"},{"name":"MyISAM","slug":"MyISAM","permalink":"https://xmmarlowe.github.io/tags/MyISAM/"}],"author":"Marlowe"},{"title":"MySQL事务以及隔离级别","slug":"数据库/MySQL事务以及隔离级别","date":"2021-01-10T03:23:22.000Z","updated":"2021-04-26T13:12:45.400Z","comments":true,"path":"2021/01/10/数据库/MySQL事务以及隔离级别/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/10/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E4%BA%8B%E5%8A%A1%E4%BB%A5%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","excerpt":"MySQL事务相关面试题…","text":"MySQL事务相关面试题… 何为事务？事务是逻辑上的一组操作，要么都执行，要么都不执行。举一个简单的例子：事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账 1000 元，这个转账会涉及到两个关键操作就是： 将小明的余额减少 1000 元 将小红的余额增加 1000 元。 事务会把这两个操作就可以看成逻辑上的一个整体，这个整体包含的操作要么都成功，要么都要失败。 这样就不会出现小明余额减少而小红的余额却并没有增加的情况。 何为数据库事务？数据库事务在我们日常开发中接触的最多了。如果你的项目属于单体架构的话，你接触到的往往就是数据库事务了。 平时，我们在谈论事务的时候，如果没有特指分布式事务，往往指的就是数据库事务。 那数据库事务有什么作用呢？ 简单来说：数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：要么全部执行成功,要么全部不执行。 123456# 开启一个事务START TRANSACTION;# 多条 SQL 语句SQL1,SQL2...## 提交事务COMMIT; 另外，关系型数据库（例如：MySQL、SQL Server、Oracle 等）事务都有 ACID 特性： 何为ACID特性？原子性（Atomicity）事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durabilily）一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 数据事务的实现原理呢？(InnoDB) 我们这里以 MySQL 的 InnoDB 引擎为例来简单说一下。 MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。 MySQL InnoDB 引擎通过 锁机制、MVCC 等手段来保证事务的隔离性（ 默认支持的隔离级别是 REPEATABLE-READ ）。 保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。 并发事务带来哪些问题?在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。 脏读（Dirty read）当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 脏写脏写是指事务回滚了其他事务对数据项的已提交修改,比如下面这种情况，在事务1对数据A的回滚,导致事务2对A的已提交修改也被回滚了。 丢失修改（Lost to modify）指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。 不可重复读（Unrepeatableread）指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复读和幻读区别： 不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。 事务隔离级别有哪些?SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 读未提交(READ-UNCOMMITTED) √ √ √ 读已提交(READ-COMMITTED) × √ √ 可重复读(REPEATABLE-READ) × × √ 串行化(SERIALIZABLE) × × × MySQL 的默认隔离级别是什么?MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看，MySQL 8.0 该命令改为SELECT @@transaction_isolation; 123456mysql&gt; SELECT @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+ MySQL InnoDB 的 REPEATABLE-READ（可重读）并不保证避免幻读，需要应用使用加锁读来保证。而这个加锁读使用到的机制就是 Next-Key Locks。 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是你要知道的是 InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读） 并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。 事务隔离级别的实现-并发控制技术并发控制技术是实现事务隔离性的关键，实现方式有多种，并发控制策略可以分为两类： 乐观并发控制：对于并发执行可能冲突的操作，假定其不会真的冲突，允许并发执行，直到真正发生冲突时才去解决冲突，比如让事务回滚。 悲观并发控制：对于并发执行可能冲突的操作，假定其必定发生冲突，通过让事务等待(锁)或者中止(时间戳排序)的方式使并行的操作串行执行。 基于封锁的并发控制封锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 锁的种类 1.读写锁 排它锁（Exclusive），简写为 X 锁，又称写锁。加了X锁，其他事务什么锁都不能加。 共享锁（Shared），简写为 S 锁，又称读锁。加了S锁其他事务可以加S锁，不能加X锁。 2.意向锁（Intention Locks） 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定： 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 各种锁的兼容关系如下：| - | X| IX | S | IS||:–:| :–:|:–:|:–:| :–: ||X | ×| ×| ×| ×||IX| × | √| ×| √||S | ×| √| √| √||IS| ×| √| √| √| 解释如下： 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。 三级锁与两段锁协议 三级封锁协议 三级封锁协议就是对锁使用的规定，来解决事务并发一致性问题。 a.一级封锁-解决丢失更新 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失更新问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 b.二级封锁-解决脏读 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 c.三级封锁-解决不可重复读 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 两段锁协议 加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 1lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。 1lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) MySQL隐式与显示锁定 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： 12SELECT ... LOCK In SHARE MODE; #S锁SELECT ... FOR UPDATE; #X锁 基于时间戳的并发控制核心思想：对于并发可能冲突的操作，基于时间戳排序规则选定某事务继续执行,其他事务回滚。 系统会在每个事务开始时赋予其一个时间戳,这个时间戳可以是系统时钟也可以是一个不断累加的计数器值,当事务回滚时会为其赋予一个新的时间戳，先开始的事务时间戳小于后开始事务的时间戳。 每一个数据项Q有两个时间戳相关的字段:W-timestamp(Q):成功执行write(Q)的所有事务的最大时间戳R-timestamp(Q):成功执行read(Q)的所有事务的最大时间戳 具体排序方式就是： 假设事务T发出read(Q),T的时间戳为TSa. 若TS(T)&lt;W-timestamp(Q),则T需要读入的Q已被覆盖。此read操作将被拒绝,T回滚。b. 若TS(T)&gt;=W-timestamp(Q),则执行read操作,同时把R-timestamp(Q)设置为TS(T)与R-timestamp(Q)中的最大值 假设事务T发出write(Q)a.若TS(T)&lt;R-timestamp(Q),write操作被拒绝,T回滚。b.若TS(T)&lt;W-timestamp(Q),则write操作被拒绝,T回滚。c.其他情况:系统执行write操作,将W-timestamp(Q)设置为TS(T)。 基于时间戳排序和基于锁实现的本质一样:对于可能冲突的并发操作,以串行的方式取代并发执行,因而它也是一种悲观并发控制。它们的区别主要有两点: 基于锁是让冲突的事务进行等待，而基于时间戳排序是让冲突的事务回滚。 基于锁冲突事务的执行次序是根据它们申请锁的顺序,先申请的先执行;而基于时间戳排序是根据特定的时间戳排序规则。 基于有效性检查的并发控制核心思想：事务对数据的更新首先在自己的工作空间进行，等到要写回数据库时才进行有效性检查，对不符合要求的事务进行回滚。 基于有效性检查的事务执行过程会被分为三个阶段: 读阶段： 数据项被读入并保存在事务的局部变量中。所有write操作都是对局部变量进行，并不对数据库进行真正的更新。 有效性检查阶段： 对事务进行有效性检查，判断是否可以执行write操作而不违反可串行性。如果失败，则回滚该事务。 写阶段： 事务已通过有效性检查，则将临时变量中的结果更新到数据库中。有效性检查通常也是通过对事务的时间戳进行比较完成的，不过和基于时间戳排序的规则不一样。 该方法允许可能冲突的操作并发执行,因为每个事务操作的都是自己工作空间的局部变量,直到有效性检查阶段发现了冲突才回滚。因而这是一种乐观的并发策略。 基于多版本并发控制（MVCC）与快照隔离什么是MVCC 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 可以认为MVCC是行级锁的一个变种，但是在很多情况下又避免了加锁，所以效率比较高。 MySQL的InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列实现： 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 其中系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。事务版本号：事务开始时的系统版本号。 MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 实现过程 以下实现过程针对可重复读隔离级别。 当开始一个事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号，理解这一点很关键。数据行快照的创建版本号是创建数据行快照时的系统版本号，系统版本号随着创建事务而递增，因此新创建一个事务时，这个事务的系统版本号比之前的系统版本号都大，也就是比所有数据行快照的创建版本号都大。 1.SELECT ①只查找版本早于当前事务版本的数据行（行的系统版本号小于等于事务的系统版本号），这样可以保证要么数据行是之前存在的，要么就是自己这个事务自己修改的。 ②查找行的删除版本号要么大于当前事务版本号，要么未定义。这样可以保证这个数据行没有被删除的。 2.INSERT 将当前系统版本号作为数据行快照的创建版本号。 3.DELETE 将当前系统版本号作为数据行快照的删除版本号。 4.UPDATE 将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读 1.快照读 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 1select * from table ...; 2.当前读 读取的是最新的数据，不去读快照，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update;delete; 参考事务 数据库之事务与实现原理","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"},{"name":"隔离级别","slug":"隔离级别","permalink":"https://xmmarlowe.github.io/tags/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"}],"author":"Marlowe"},{"title":"MySQL中乐观锁实现(mvcc)","slug":"数据库/MySQL中乐观锁实现-mvcc","date":"2021-01-10T02:49:23.000Z","updated":"2021-04-23T14:25:09.939Z","comments":true,"path":"2021/01/10/数据库/MySQL中乐观锁实现-mvcc/","link":"","permalink":"https://xmmarlowe.github.io/2021/01/10/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E4%B8%AD%E4%B9%90%E8%A7%82%E9%94%81%E5%AE%9E%E7%8E%B0-mvcc/","excerpt":"MVCC即Multi-Version Concurrency Control，中文翻译过来叫多版本并发控制。","text":"MVCC即Multi-Version Concurrency Control，中文翻译过来叫多版本并发控制。 MVCC是解决了什么问题众所周知，在MYSQL中，MyISAM使用的是表锁，InnoDB使用的是行锁。而InnoDB的事务分为四个隔离级别，其中默认的隔离级别REPEATABLE READ需要两个不同的事务相互之间不能影响，而且还能支持并发，这点悲观锁是达不到的，所以REPEATABLE READ采用的就是乐观锁，而乐观锁的实现采用的就是MVCC。正是因为有了MVCC，才造就了InnoDB强大的事务处理能力。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"},{"name":"mvcc","slug":"mvcc","permalink":"https://xmmarlowe.github.io/tags/mvcc/"}],"author":"Marlowe"},{"title":"countDownLatch、CyclicBarrier、Semaphore","slug":"并发/countDownLatch、CyclicBarrier、Semaphore","date":"2020-12-26T17:13:41.000Z","updated":"2021-04-19T12:47:15.194Z","comments":true,"path":"2020/12/27/并发/countDownLatch、CyclicBarrier、Semaphore/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/27/%E5%B9%B6%E5%8F%91/countDownLatch%E3%80%81CyclicBarrier%E3%80%81Semaphore/","excerpt":"","text":"countDownLatch简介 countDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。 是通过一个计数器来实现的，计数器的初始值是线程的数量。每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。 减法计数器 原理countDownLatch.countDown(); // 数量-1countDownLatch.await(); // 等待计数器归零，然后向下执行每次有线程调用countDown(),数量减一，假设计数器变为0,countDownLatch.await();就会被唤醒，继续执行！ 代码示例： 1234567891011121314151617public class CountDownLatchDemo &#123; public static void main(String[] args) throws InterruptedException &#123; // 总数是6，必须要执行任务的时候，再使用！ CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt;= 6; i++) &#123; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; Go out&quot;); countDownLatch.countDown(); &#125;, String.valueOf(i)).start(); &#125; // 等待计数器归零，然后再向下执行 countDownLatch.await(); System.out.println(&quot;close door&quot;); &#125;&#125; 结果： 12345678&#x2F;&#x2F; x顺序不确定，但只有6个线程结束后才向下执行x Go outx Go outx Go outx Go outx Go outx Go outClose door CyclicBarrier简介 从字面上的意思可以知道，这个类的中文意思是“循环栅栏”。大概的意思就是一个可循环利用的屏障。 加法计数器 举个例子，就像生活中我们会约朋友们到某个餐厅一起吃饭，有些朋友可能会早到，有些朋友可能会晚到，但是这个餐厅规定必须等到所有人到齐之后才会让我们进去。这里的朋友们就是各个线程，餐厅就是 CyclicBarrier。 作用CyclicBarrier的作用是让所有线程都等待完成后才会继续下一步行动。 代码示例： 1234567891011121314151617181920212223public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; // 召唤龙珠的线程 CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -&gt; &#123; System.out.println(&quot;召唤神龙成功！&quot;); &#125;); for (int i = 1; i &lt;= 7; i++) &#123; // 定义一个final 中间变量接收i final int temp = i; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;收集了&quot; + temp + &quot;个龙珠&quot;); try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125;&#125; 结果 12345678Thread-1收集了2个龙珠Thread-2收集了3个龙珠Thread-0收集了1个龙珠Thread-3收集了4个龙珠Thread-4收集了5个龙珠Thread-5收集了6个龙珠Thread-6收集了7个龙珠召唤神龙成功！ Semaphore简介一般用来控制同时访问特定共享资源的线程数，它通过协调各个线程来保证使用公共资源的合理性。 作用 Semaphore的作用是控制并发访问的线程数目。 多个共享资源互斥使用，开发限流！ 原理semaphore.acquire() // 获得，假设已经满了，等待，等待被释放为止semaphore.release() // 释放，会将当前的信号量释放 + 1，然后唤醒等待线程！ 代码示例： 1234567891011121314151617181920212223public class SemaphoreDemo &#123; public static void main(String[] args) &#123; // 线程数量，停车位，限流 Semaphore semaphore = new Semaphore(3); for (int i = 1; i &lt;= 6; i++) &#123; new Thread(() -&gt; &#123; try &#123; // 得到 semaphore.acquire(); System.out.println(Thread.currentThread().getName() + &quot;抢到车位&quot;); TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread().getName() + &quot;离开车位&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; // 释放 semaphore.release(); &#125; &#125;, String.valueOf(i)).start(); &#125; &#125;&#125; 结果： 1234567891011121 抢到车位2 抢到车位3 抢到车位1 离开车位2 离开车位3 离开车位4 抢到车位6 抢到车位5 抢到车位4 离开车位6 离开车位5 离开车位 CountDownLatch和CyclicBarrier区别 countDownLatch是一个计数器，线程完成一个记录一个，计数器递减，只能只用一次 CyclicBarrier的计数器更像一个阀门，需要所有线程都到达，然后继续执行，计数器递增，提供reset功能，可以多次使用。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"countDownLatch","slug":"countDownLatch","permalink":"https://xmmarlowe.github.io/tags/countDownLatch/"},{"name":"CyclicBarrier","slug":"CyclicBarrier","permalink":"https://xmmarlowe.github.io/tags/CyclicBarrier/"},{"name":"Semaphore","slug":"Semaphore","permalink":"https://xmmarlowe.github.io/tags/Semaphore/"}],"author":"Marlowe"},{"title":"Callable","slug":"并发/Callable","date":"2020-12-26T12:29:25.000Z","updated":"2021-04-19T12:10:57.554Z","comments":true,"path":"2020/12/26/并发/Callable/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/26/%E5%B9%B6%E5%8F%91/Callable/","excerpt":"","text":"Callable简介： 可以有返回值 可以抛出异常 方法不同，Runnable 是 run()， Callable 是call() 1234567891011121314151617181920212223242526public class CallableTest &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyThread thread = new MyThread(); // 适配类 FutureTask futureTask = new FutureTask(thread); new Thread(futureTask, &quot;A&quot;).start(); new Thread(futureTask, &quot;B&quot;).start(); // get方法可能会产生阻塞 Integer s = (Integer) futureTask.get(); System.out.println(s); &#125;&#125;class MyThread implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;call()&quot;); // 耗时的操作 return 1024; &#125;&#125; 结果： 12// 只有一个call(),因为有缓存call() 注意： 有缓存 结果可能需要等待，会阻塞！","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Callable","slug":"Callable","permalink":"https://xmmarlowe.github.io/tags/Callable/"}],"author":"Marlowe"},{"title":"Redis 发布与订阅","slug":"NoSQL/Redis-发布与订阅","date":"2020-12-25T03:59:32.000Z","updated":"2021-04-16T12:33:42.185Z","comments":true,"path":"2020/12/25/NoSQL/Redis-发布与订阅/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/25/NoSQL/Redis-%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85/","excerpt":"","text":"Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接受消息。微博、微信、关注系统！Redis客户端可以订阅任意数量的频道。订阅/发布消息图：第一个：消息发送者，第二个：频道，第三个：消息订阅者使用场景 实时消息系统 实时聊天(频道当做聊天室，将信息回显给所有人即可) 订阅，关注系统 缺点：稍微复杂的场景就会使用消息中间件MQ。在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis 缓存穿透与雪崩(面试高频)","slug":"NoSQL/Redis-缓存穿透与雪崩-面试高频","date":"2020-12-24T09:07:26.000Z","updated":"2021-05-04T12:31:13.704Z","comments":true,"path":"2020/12/24/NoSQL/Redis-缓存穿透与雪崩-面试高频/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/24/NoSQL/Redis-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E4%B8%8E%E9%9B%AA%E5%B4%A9-%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91/","excerpt":"","text":"缓存穿透什么是缓存穿透？缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。 缓存穿透情况的处理流程是怎样的？如下图所示，用户的请求最终都要跑到数据库中查询一遍。 有哪些解决办法？最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。 1）缓存无效 key如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。 另外，这里多说一嘴，一般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值 。 如果用 Java 代码展示的话，差不多是下面这样的： 123456789101112131415161718public Object getObjectInclNullById(Integer id) &#123; // 从缓存中获取数据 Object cacheValue = cache.get(id); // 缓存为空 if (cacheValue == null) &#123; // 从数据库中获取 Object storageValue = storage.get(key); // 缓存空对象 cache.set(key, storageValue); // 如果存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) &#123; // 必须设置过期时间，否则有被攻击的风险 cache.expire(key, 60 * 5); &#125; return storageValue; &#125; return cacheValue;&#125; 2）布隆过滤器布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。 具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。 加入布隆过滤器之后的缓存处理流程图如下: 但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。 缓存击穿什么是缓存击穿？在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 带来的问题？会造成某一时刻数据库请求量过大，压力剧增。 如何解决？1. 设置热点数据永不过期从缓存层面来看,没有设置过期时间,所以不会出现热点key过期后产生的问题。但是要注意在value中包含一个逻辑上的过期时间，然后另启一个线程，定期重建这些缓存。 2. 加互斥锁分布式锁:使用分布式锁,保证对于每个key同时只有一 个线程去查询后端服务,其他线程没有获得分布式锁的权限,因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁,因此对分布式锁的考验很大。 缓存雪崩什么是缓存雪崩？我发现缓存雪崩这名字起的有点意思，哈哈。 实际上，缓存雪崩描述的就是这样一个简单的场景：缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。 举个例子： 系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。 还有一种缓存雪崩的场景是：有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。 这样的情况，有下面几种解决办法： 举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。 有哪些解决办法？针对 Redis 服务不可用的情况： 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。 针对热点缓存失效的情况： 设置不同的失效时间比如随机设置缓存的失效时间。 缓存永不失效。 如何保证缓存和数据库数据的一致性？如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案： 缓存失效时间变短（不推荐，治标不治本）： 我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。 增加 cache 更新重试机制（常用）： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。 参考缓存穿透与缓存雪崩","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Redis 持久化","slug":"NoSQL/Redis-持久化","date":"2020-12-24T03:28:46.000Z","updated":"2021-05-06T07:07:27.839Z","comments":true,"path":"2020/12/24/NoSQL/Redis-持久化/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/24/NoSQL/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"Redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失，所以Redis提供了持久化功能！","text":"Redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失，所以Redis提供了持久化功能！ RDB(Redis DataBase)简介在指定的时间间隔内将内存中的数据集写入磁盘，也就是行话讲的Snapshot快照，它恢复时时将快照文件直接读到内存里。 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的。 这就确保了极高的性能。如果需要进行大规模数据的恢复，且对数据恢复的完整性不是非常敏感，那么RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化的数据可能丢失。我们默认的就是RDB，一般情况下不需要修改这个配置！ 在生产环境我们会将这个文件进行备份！ rdb保存的文件是dump.rdb 都是在配置文件中 快照中进行配置的！ 触发机制 save的规则满足情况下，会自动触发rdb规则 执行flushall命令，也会触发我们的rdb规则！ 退出redis，也会产生rdb文件备份就自动生成一个dump.rdb 如何恢复rdb文件？ 只需将rdb文件放在redis启动目录就可以，redis启动的时候就会自动检查dump.rdb，并恢复其中的数据。 查看需要存放的位置123127.0.0.1:6379&gt; config get dir1) &quot;dir&quot;2) &quot;D:\\\\Program Files\\\\redis-2.8.9&quot; 优点适合大规模的数据恢复！ 对数据的完整性要求不高 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 缺点需要一定的时间间隔进行操作，如果redis意外宕机了，这个最后一次修改的数据就没有了！ fork进程的时候，会占用一定的内存空间！ 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 RDB持久化流程 Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令 父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令 子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换 子进程发送信号给父进程表示完成，父进程更新统计信息 AOF(Append Only File)简介将我们的所有命令都记录下来，history，恢复的时候就把这个文件全部再执行一遍！以日志的形式来记录每个读写操作，将Redis执行过的所有指令记录下来(读操作不记录),只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据,换言之，redis重启的话就根据日志文件的内容将写指令从前往后执行一次以完成数据的恢复工作 Aof保存的是appendonly.aof文件 默认是不开启的，需要手动进行配置，只需要将appendonly改为yes就可以开启aof！ 重启redis就可以生效如果这个aof文件有错，redis将无法启动，需要修复这个aof文件redis提供了一个工具 redis-check-aof --fix如果文件正常，重启就可以直接恢复了！ 重写规则说明aof默认就是文件的无限追加，文件会越来越大! 如果aof文件大于64m，太大了，会fork一个新的进程来将文件重写！ 优点每一次修改都同步，文件的完整性会更加好！ 每秒同步一次，可能会丢失一秒的数据。 从不同步，效率最高。 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 缺点相对于数据文件来说，aof远远大于rdb，修复的速度也比rdb慢。 Aof运行效率比rdb慢，所以redis默认的配置就是rdb持久化。 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 AOF持久化流程 客户端发出 bgrewriteaof命令。 redis主进程fork子进程。 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存到 AOF重写缓冲区。这样就能保证如果子进程重写失败的话并不会出问题。 子进程根据内存快照，按照命令合并规则写入到新AOF文件中。 当子进程把内存快照写入临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。 常用配置RDB持久化配置Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息： 12345save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。 AOF持久化配置在Redis的配置文件中存在三种同步方式，它们分别是： 12345appendfsync always #每次有数据修改发生时都会写入AOF文件。appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。appendfsync no #从不同步。高效但是数据不会被持久化。 如何选择二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。 命令 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 块 慢 数据安全性 丢数据 根据策略决定 轻重 重 轻 一些问题Redis 持久化 之 AOF 和 RDB 同时开启，Redis听谁的？听AOF的，RDB与AOF同时开启 默认无脑加载AOF的配置文件相同数据集，AOF文件要远大于RDB文件，恢复速度慢于RDBAOF运行效率慢于RDB,但是同步策略效率好，不同步效率和RDB相同 参考redis持久化的几种方式 如何彻底理解Redis持久化？触发机制注意的点 | AOF持久化过程。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://xmmarlowe.github.io/tags/redis/"}],"author":"Marlowe"},{"title":"SpringBoot整合Redis","slug":"NoSQL/SpringBoot整合Redis","date":"2020-12-23T13:59:54.000Z","updated":"2020-12-24T02:14:15.077Z","comments":true,"path":"2020/12/23/NoSQL/SpringBoot整合Redis/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/23/NoSQL/SpringBoot%E6%95%B4%E5%90%88Redis/","excerpt":"","text":"说明：SpringBoot2.x之后，原来使用jedis被替换为了lettucejedis：采用的直连，多个线程操作的话，是不安全的，如果想要避免不安全，使用jedis pool连接池！ 更像BIO模式lettuce：采用netty，示例可以在多个线程中共享，不存在线程不安全的情况！可以减少线程数据了，更像NIO模式原码分析： 12345678910111213141516171819@Bean@ConditionalOnMissingBean(name = &quot;redisTemplate&quot;)// 我们可以自定义一个redisTemplate来替换这个默认的！@ConditionalOnSingleCandidate(RedisConnectionFactory.class)public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; // 默认的RedisTemplate没有过多的设置，redis对象都是需要序列化！ // 两个泛型都是Object，Object的类型，我们使用需要强制转换&lt;String,Object&gt; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template;&#125;@Bean@ConditionalOnMissingBean // 由于tring是redis中最常使用的类型，所以单独提取出来了一个bean！@ConditionalOnSingleCandidate(RedisConnectionFactory.class)public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template;&#125; 整合测试 导入依赖12345&lt;!--操作redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置连接12spring.redis.host=127.0.0.1spring.redis.port=6379 测试12345678910@Testvoid contextLoads() &#123; // 获取redis的连接对象 // RedisConnection connection = redisTemplate.getConnectionFactory().getConnection(); // connection.flushDb(); // connection.flushAll(); redisTemplate.opsForValue().set(&quot;mykey&quot;, &quot;kuangshen&quot;); System.out.println(redisTemplate.opsForValue().get(&quot;mykey&quot;));&#125;","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://xmmarlowe.github.io/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"Jedis","slug":"NoSQL/Jedis","date":"2020-12-23T13:19:43.000Z","updated":"2020-12-24T02:14:15.073Z","comments":true,"path":"2020/12/23/NoSQL/Jedis/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/23/NoSQL/Jedis/","excerpt":"…","text":"… 简介Jedis 是 Redis官方推荐的Java连接开发工具，使用Java操作Redis中间件。 测试 导入对应的依赖12345678910111213&lt;!--导入jedis的依赖--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.62&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 编码测试 连接数据库 操作命令 断开连接12345678910public class TestPing &#123; public static void main(String[] args) &#123; // 1、new Jedis对象 Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379); System.out.println(jedis.ping()); &#125;&#125; 输出： 操作事务： 12345678910111213141516171819202122232425262728293031public class TestTx &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379); jedis.flushDB(); JSONObject jsonObject = new JSONObject(); jsonObject.put(&quot;hello&quot;, &quot;world&quot;); jsonObject.put(&quot;name&quot;, &quot;marlowe&quot;); // 开启事务 Transaction multi = jedis.multi(); String result = jsonObject.toJSONString(); try &#123; multi.set(&quot;user1&quot;, result); multi.set(&quot;user2&quot;, result); // 代码抛出异常，事务执行失败 int i = 1 / 0; // 执行事务 multi.exec(); &#125; catch (Exception e) &#123; // 放弃事务 multi.discard(); e.printStackTrace(); &#125; finally &#123; System.out.println(jedis.get(&quot;user1&quot;)); System.out.println(jedis.get(&quot;user2&quot;)); jedis.close(); &#125; &#125;&#125; 输出：","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"},{"name":"Jedis","slug":"Jedis","permalink":"https://xmmarlowe.github.io/tags/Jedis/"}],"author":"Marlowe"},{"title":"Redis 事务","slug":"NoSQL/Redis-事务","date":"2020-12-20T03:46:30.000Z","updated":"2021-04-21T06:02:08.083Z","comments":true,"path":"2020/12/20/NoSQL/Redis-事务/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/20/NoSQL/Redis-%E4%BA%8B%E5%8A%A1/","excerpt":"Redis 事务简介…","text":"Redis 事务简介… Redis 事务本质：一组命令的集合！一个事务中的所有命令都会被序列化，在事务执行过程中，会按照顺序执行！一次性，顺序性，排他性 执行一系列的命令！ 1-----队列 set set set 执行----- Redis事务没有隔离级别的概念所有的命令在事务中，并没有直接被执行！只有发起执行命令的时候才会执行！ExecRedis单条命令是保证原子性的，但是事务不保证原子性Redis的事务： 开启事务() 命令入队() 执行事务() 正常执行事务 123456789101112131415127.0.0.1:6379&gt; multi # 开启事务OK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; exec # 执行事务1) OK2) OK3) &quot;v2&quot;4) OK 放弃事务 123456789101112127.0.0.1:6379&gt; multi # 开启事务OK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k4 v4QUEUED127.0.0.1:6379&gt; discard # 取消事务OK127.0.0.1:6379&gt; get k4 # 事务队列中的命令都不会被执行(nil) 编译型异常，事务中的所有命令都不会被执行！ 123456789101112131415161718127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; getset k3 # 错误的命令(error) ERR wrong number of arguments for &#x27;getset&#x27; command127.0.0.1:6379&gt; set k4 v4QUEUED127.0.0.1:6379&gt; set k5 v5QUEUED127.0.0.1:6379&gt; exec # 执行命令的时候报错(error) EXECABORT Transaction discarded because of previous errors.127.0.0.1:6379&gt; get k5 # 所有的命令都不会执行(nil) 运行时异常如果事务队列中存在与发行，那么执行命令的时候，其他命令是可以正常执行，错误命令抛出异常！ 1234567891011121314151617181920127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 &quot;v1&quot;QUEUED127.0.0.1:6379&gt; incr k1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; get k3QUEUED127.0.0.1:6379&gt; exec1) OK2) (error) ERR value is not an integer or out of range # 第一条命令报错，但是依旧正常执行成功了！3) OK4) OK5) &quot;v3&quot;127.0.0.1:6379&gt; get k2&quot;v2&quot; 监控 Watch 悲观锁 很悲观，认为什么时候都会出问题，无论做什么都会加锁！ 乐观锁 很乐观，认为什么时候都不会出问题，所以不会上锁！更新数据的时候去判断一下，在此期间是否有人修改过这个数据 获取version 更新的时候比较version Redis 监视测试正常执行成功！ 123456789101112131415127.0.0.1:6379&gt; set money 100OK127.0.0.1:6379&gt; set out 0OK127.0.0.1:6379&gt; watch money # 监视money对象OK127.0.0.1:6379&gt; multi # 事务正常结束，数据期间没有发生变动，这个时候就正常执行成功OK127.0.0.1:6379&gt; decrby money 20QUEUED127.0.0.1:6379&gt; incrby out 20QUEUED127.0.0.1:6379&gt; exec1) (integer) 802) (integer) 20 测试多线程修改值，使用watch可以当做redis的乐观锁操作 三特性单独的隔离操作事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中,不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念队列中的命令没有提交之前都不会实际被执行,因为事务提交前任何指令都不会被实际执行。 不保证原子性事务中如果有一条命令执行失败 ,后的命令仍然会被执行,没有回滚。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"},{"name":"事务","slug":"事务","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8B%E5%8A%A1/"}],"author":"Marlowe"},{"title":"Redis 三种特殊数据类型","slug":"NoSQL/Redis-三种特殊数据类型","date":"2020-12-20T02:58:35.000Z","updated":"2021-05-06T08:38:43.512Z","comments":true,"path":"2020/12/20/NoSQL/Redis-三种特殊数据类型/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/20/NoSQL/Redis-%E4%B8%89%E7%A7%8D%E7%89%B9%E6%AE%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"Radis 三种特殊数据类型…","text":"Radis 三种特殊数据类型… geospatial12345678geoadd # 添加位置geopos #获得当前定位 一定是一个坐标值geodist # 两人之间的距离georadius # 以给定的经纬度为中心，找出某一半径内的元素可以加参数 withdist 显示距离， withcoord 显示经纬度， count x 限制个数georadiusbymember 找出指定元素周围的其他元素geohash 返回11个字符串的geohash字符串geo底层的实现原理就是zset！我们可以通过zset命令来操作geo Hyperloglog1234567891011Redis Hyperloglog 基数统计的算法！优点:占用的内存固定，2^64不同的元素基数，只需要12KB内存！如果要从内存角度来比较的话Hyperloglog首选！网页UV（一个人访问一个网站多次，但是还是算作一个人！）传统的方式，set保存用户的id，然后就可以统计set中的元素数量作为标准判断！这个方式如果保存大量的用户id，就会比较麻烦！ 我们的目的是为了计数，而不是保存用户id；0.81误错率！ 统计UV任务，可以忽略不计的！pfcount 统计元素的基数数量pfmearge mykey3 mykey mykey2 #合并两组mykey mykey2 =&gt; mykey3 并集如果允许容错，使用Hyperloglog；如果不允许容错，就使用set或者自己的数据类型即可 Bitmap原理8bit = 1b = 0.001kb bitmap就是通过最小的单位bit来进行0或者1的设置，表示某个元素对应的值或者状态。一个bit的值，或者是0，或者是1；也就是说一个bit能存储的最多信息是2。 优势 基于最小的单位bit进行存储，所以非常省空间。 设置时候时间复杂度O(1)、读取时候时间复杂度O(n)，操作是非常快的。 二进制数据的存储，进行相关计算的时候非常快。 方便扩容 限制redis中bit映射被限制在512MB之内，所以最大是2^32位。建议每个key的位数都控制下，因为读取时候时间复杂度O(n)，越大的串读的时间花销越多。 案例12345678910111213141516171819统计用户信息，活跃 不活跃！ 登录 未登录! 打卡 未打卡！ 两个状态的，都可以使用BitmapsBitmaps 位图，数据结构！ 都是操作二进制来进行记录，就只有0和1两个状态！365天=365bit 1字节=8比特 46比特左右！使用bitmap来记录 周一到周日的打卡！127.0.0.1:6379&gt; setbit sign 0 1(integer) 0127.0.0.1:6379&gt; setbit sign 1 0(integer) 0127.0.0.1:6379&gt; setbit sign 2 0(integer) 0127.0.0.1:6379&gt; setbit sign 3 1(integer) 0127.0.0.1:6379&gt; setbit sign 4 1(integer) 0127.0.0.1:6379&gt; setbit sign 5 0(integer) 0127.0.0.1:6379&gt; setbit sign 6 0(integer) 0 查看某一天是否打卡！ 1234127.0.0.1:6379&gt; getbit sign 3(integer) 1127.0.0.1:6379&gt; getbit sign 6(integer) 0 统计操作，统计打卡的天数！ 12127.0.0.1:6379&gt; bitcount sign # 统计这周的打卡记录，可以看到是否全勤(integer) 3","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"},{"name":"数据类型","slug":"数据类型","permalink":"https://xmmarlowe.github.io/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}],"author":"Marlowe"},{"title":"Redis 五大数据类型","slug":"NoSQL/Redis-五大数据类型","date":"2020-12-19T09:10:33.000Z","updated":"2021-04-16T12:16:33.440Z","comments":true,"path":"2020/12/19/NoSQL/Redis-五大数据类型/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/19/NoSQL/Redis-%E4%BA%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"Redis 五大数据类型详述…","text":"Redis 五大数据类型详述… Redis-keyString（字符串）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127.0.0.1:6379&gt; set key1 v1OK127.0.0.1:6379&gt; get key1&quot;v1&quot;127.0.0.1:6379&gt; keys *1) &quot;key1&quot;127.0.0.1:6379&gt; exists key1(integer) 1127.0.0.1:6379&gt; append key1 &quot;hello&quot; # 如果当前key不存在，就相当于set key(integer) 7127.0.0.1:6379&gt; get key1&quot;v1hello&quot;127.0.0.1:6379&gt; strlen key1(integer) 7########################################### i++127.0.0.1:6379&gt; set views 0OK127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt; incr views(integer) 1127.0.0.1:6379&gt; get views&quot;1&quot;127.0.0.1:6379&gt; decr views(integer) 0127.0.0.1:6379&gt; decr views(integer) -1127.0.0.1:6379&gt; get views&quot;-1&quot;127.0.0.1:6379&gt; incr views(integer) 0127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt; incrby views 10(integer) 10127.0.0.1:6379&gt; decrby views 5(integer) 5########################################### 字符串范围 range127.0.0.1:6379&gt; set key1 &quot;hello,kuangshen&quot;OK127.0.0.1:6379&gt; get key1&quot;hello,kuangshen&quot;127.0.0.1:6379&gt; getrange key1 0 3&quot;hell&quot;127.0.0.1:6379&gt; getrange key1 0 -1&quot;hello,kuangshen&quot;# 替换127.0.0.1:6379&gt; set key2 abcdefgOK127.0.0.1:6379&gt; get key2&quot;abcdefg&quot;127.0.0.1:6379&gt; setrange key2 1 xx(integer) 7127.0.0.1:6379&gt; get key2&quot;axxdefg&quot;########################################### setex(set with expire) # 设置过期时间# setnx(set if not exist) # 不存在再设置(在分布式锁中常常使用！)127.0.0.1:6379&gt; setex key3 30 &quot;hello&quot;OK127.0.0.1:6379&gt; ttl key3(integer) 26127.0.0.1:6379&gt; get key3&quot;hello&quot;127.0.0.1:6379&gt; setnx mykey &quot;redis&quot;(integer) 1127.0.0.1:6379&gt; keys *1) &quot;key2&quot;2) &quot;key1&quot;3) &quot;mykey&quot;4) &quot;key3&quot;127.0.0.1:6379&gt; keys *1) &quot;key2&quot;2) &quot;key1&quot;3) &quot;mykey&quot;127.0.0.1:6379&gt; setnx mykey &quot;MongoDB&quot;(integer) 0127.0.0.1:6379&gt; get mykey&quot;redis&quot;##########################################127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 # 同时设置多个值OK127.0.0.1:6379&gt; keys *1) &quot;k3&quot;2) &quot;k2&quot;3) &quot;k1&quot;127.0.0.1:6379&gt; get k1 k2 k3(error) ERR wrong number of arguments for &#x27;get&#x27; command127.0.0.1:6379&gt; mget k1 k2 k3 # 同时获得多个值1) &quot;v1&quot;2) &quot;v2&quot;3) &quot;v3&quot;127.0.0.1:6379&gt; msetnx k1 v1 k4 v4 # msetnx是一个原子性操作，要么一起成功，要么一起失败！(integer) 0127.0.0.1:6379&gt; get k4(nil)# 对象set user:1&#123;name:zhangsan,age:3&#125; # 设置一个user：1对象，值为json字符来保存一个对象# 这里的key是一个巧妙的设计： user:&#123;id&#125;:&#123;filed&#125;127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 2OK127.0.0.1:6379&gt; mget user:11) (nil)127.0.0.1:6379&gt; mget user:1:name user:1:age1) &quot;zhangsan&quot;2) &quot;2&quot;##########################################getset # 先get再set127.0.0.1:6379&gt; getset db redis # 如果不存在值，则返回nil(nil)127.0.0.1:6379&gt; get db&quot;redis&quot;127.0.0.1:6379&gt; getset db mongodb # 如果存在值，则获取原来的值&quot;redis&quot;127.0.0.1:6379&gt; get db&quot;mongodb&quot; String类似的使用场景：value除了是字符串还可以是数字 计数器 统计多单位的数量 粉丝数 对象缓存存储！ List基本数据类型，列表所有的list命令都是以l开头 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163##########################################127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; lpush list one # 将一个值或者多个值，插到列表的头部(左)(integer) 1127.0.0.1:6379&gt; lpush list two(integer) 2127.0.0.1:6379&gt; lpush list three(integer) 3127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; rpush list rigth # 将一个值或者多个值，插到列表的尾部(右)(integer) 4127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;rigth&quot;##########################################lpoprpop127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;rigth&quot;127.0.0.1:6379&gt; lpop list # 移除列表的第一个元素&quot;three&quot;127.0.0.1:6379&gt; lrange list 0 -11) &quot;two&quot;2) &quot;one&quot;3) &quot;rigth&quot;127.0.0.1:6379&gt; rpop list # 移除列表的最后一个元素&quot;rigth&quot;127.0.0.1:6379&gt; lrange list 0 -11) &quot;two&quot;2) &quot;one&quot;##########################################lindex127.0.0.1:6379&gt; lrange list 0 -11) &quot;two&quot;2) &quot;one&quot;127.0.0.1:6379&gt; lindex list 0 # 通过下标获得list中的某一个值&quot;two&quot;127.0.0.1:6379&gt; lindex list 1&quot;one&quot;##########################################llen127.0.0.1:6379&gt; lpush list one(integer) 1127.0.0.1:6379&gt; lpush list two(integer) 2127.0.0.1:6379&gt; lpush list three(integer) 3127.0.0.1:6379&gt; llen list(integer) 3##########################################移除指定的值！取关 uidlrem127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;4) &quot;one&quot;127.0.0.1:6379&gt; lrem list 1 one # 移除list集合中指定个数的value，精确匹配(integer) 1127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;127.0.0.1:6379&gt; lrem list 1 three(integer) 1127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; lpush list three(integer) 3127.0.0.1:6379&gt; keys *1) &quot;list&quot;127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;127.0.0.1:6379&gt; lrem list 2 three(integer) 2127.0.0.1:6379&gt; lrange list 0 -11) &quot;two&quot;##########################################trim：修剪 list：截断127.0.0.1:6379&gt; rpush list &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush list &quot;hello1&quot;(integer) 2127.0.0.1:6379&gt; rpush list &quot;hello2&quot;(integer) 3127.0.0.1:6379&gt; rpush list &quot;hello3&quot;(integer) 4127.0.0.1:6379&gt; rpush list &quot;hello4&quot;(integer) 5127.0.0.1:6379&gt; ltrim list 0 1 # 通过下标截取指定的长度，这个list已经被改变了，截断了只剩下截取的元素！OK127.0.0.1:6379&gt; lrange list 0 -11) &quot;hello&quot;2) &quot;hello1&quot;##########################################rpoplpush # 移除列表的最后一个元素，将他移动到新的列表中127.0.0.1:6379&gt; rpush list &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush list &quot;hello1&quot;(integer) 2127.0.0.1:6379&gt; rpush list &quot;hello2&quot;(integer) 3127.0.0.1:6379&gt; rpush list &quot;hello3&quot;(integer) 4127.0.0.1:6379&gt; rpoplpush list list1 # 移除列表的最后一个元素，将他移动到新的列表中&quot;hello3&quot;127.0.0.1:6379&gt; lrange list 0 -11) &quot;hello&quot;2) &quot;hello1&quot;3) &quot;hello2&quot;127.0.0.1:6379&gt; lrange list1 0 -11) &quot;hello3&quot;##########################################lset # 将列表中指定下标的值替换为另外一个值，更新操作127.0.0.1:6379&gt; lset list 0 itemOK127.0.0.1:6379&gt; lrange list 0 -11) &quot;item&quot;2) &quot;hello1&quot;3) &quot;hello2&quot;127.0.0.1:6379&gt; lset list 1 item1OK127.0.0.1:6379&gt; lrange list 0 -11) &quot;item&quot;2) &quot;item1&quot;3) &quot;hello2&quot;##########################################linsert # 将某个具体的value插入到列表中某个元素的前面或者后面！127.0.0.1:6379&gt; rpush list &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush list &quot;world&quot;(integer) 2127.0.0.1:6379&gt; linsert list before world other(integer) 3127.0.0.1:6379&gt; lrange list 0 -11) &quot;hello&quot;2) &quot;other&quot;3) &quot;world&quot;127.0.0.1:6379&gt; linsert list after world other1(integer) 4127.0.0.1:6379&gt; lrange list 0 -11) &quot;hello&quot;2) &quot;other&quot;3) &quot;world&quot;4) &quot;other1&quot; ########################################## 小结 实际上是一个链表，before Node after， left right都可以插入值 如果key不存在，创建新的链表 如果key存在，新增内容 如果移除了所有值，空链表，也代表不存在！ 在两边插入或者改动值，效率最高！中间元素，相对来说效率会低一点~ 消息排队！ 消息队列 （lpush rpop），栈（lpush lpop） Set(集合)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104##########################################127.0.0.1:6379&gt; sadd myset hello(integer) 1127.0.0.1:6379&gt; sadd myset kuangshen(integer) 1127.0.0.1:6379&gt; sadd myset lovekuangshen(integer) 1127.0.0.1:6379&gt; smembers myset1) &quot;lovekuangshen&quot;2) &quot;hello&quot;3) &quot;kuangshen&quot;127.0.0.1:6379&gt; sismember myset hello(integer) 1127.0.0.1:6379&gt; sismember myset world(integer) 0##########################################127.0.0.1:6379&gt; scard myset # 获取set集合中的内容元素个数(integer) 4##########################################srem 127.0.0.1:6379&gt; scard myset(integer) 4127.0.0.1:6379&gt; srem myset hello # 移除set集合中指定的元素(integer) 1127.0.0.1:6379&gt; scard myset(integer) 3127.0.0.1:6379&gt; smembers myset1) &quot;lovekuangshen2&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;##########################################set 无序不重复集合，抽随机！127.0.0.1:6379&gt; smembers myset1) &quot;lovekuangshen2&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;127.0.0.1:6379&gt; srandmember myset # 随机抽选出一个元素&quot;lovekuangshen2&quot;127.0.0.1:6379&gt; srandmember myset # 随机抽选出一个元素&quot;lovekuangshen2&quot;127.0.0.1:6379&gt; srandmember myset # 随机抽选出一个元素&quot;kuangshen&quot;127.0.0.1:6379&gt; srandmember myset 2 # 随机抽选出指定个数的元素1) &quot;lovekuangshen&quot;2) &quot;kuangshen&quot;##########################################删除指定的key，随机删除key127.0.0.1:6379&gt; smembers myset1) &quot;lovekuangshen2&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;127.0.0.1:6379&gt; spop myset #随机删除一些set中的元素&quot;kuangshen&quot;127.0.0.1:6379&gt; spop myset&quot;lovekuangshen2&quot;127.0.0.1:6379&gt; smembers myset1) &quot;lovekuangshen&quot;##########################################将一个指定的值，移动到另外一个set集合！127.0.0.1:6379&gt; sadd myset hello(integer) 1127.0.0.1:6379&gt; sadd myset world(integer) 1127.0.0.1:6379&gt; sadd myset kuangshen(integer) 1127.0.0.1:6379&gt; sadd myset2 set2(integer) 1127.0.0.1:6379&gt; smove myset myset2 kuangshen # 将一个指定的值，移动到另外一个set集合(integer) 1127.0.0.1:6379&gt; smembers(error) ERR wrong number of arguments for &#x27;smembers&#x27; command127.0.0.1:6379&gt; smembers myset1) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; smembers myset21) &quot;set2&quot;2) &quot;kuangshen&quot;##########################################微博，b站，共同关注(交集)127.0.0.1:6379&gt; sadd key1 a(integer) 1127.0.0.1:6379&gt; sadd key1 b(integer) 1127.0.0.1:6379&gt; sadd key1 c(integer) 1127.0.0.1:6379&gt; sadd key2 c(integer) 1127.0.0.1:6379&gt; sadd key2 d(integer) 1127.0.0.1:6379&gt; sadd key2 e(integer) 1127.0.0.1:6379&gt; sdiff key1 key21) &quot;b&quot;2) &quot;a&quot;127.0.0.1:6379&gt; sinter key1 key21) &quot;c&quot;127.0.0.1:6379&gt; sunion key1 key21) &quot;c&quot;2) &quot;a&quot;3) &quot;b&quot;4) &quot;d&quot;5) &quot;e&quot;########################################## 微博，A用户将所有关注的人放在一个set集合中！ 将他的粉丝也放在一个集合中！共同关注，共同爱好，二度好友，推荐好友！(六度分割理论) Hash(哈希)Map 集合，key-map! 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556127.0.0.1:6379&gt; hset myhash field1 kuangshen(integer) 1127.0.0.1:6379&gt; hget myhash field1&quot;kuangshen&quot;127.0.0.1:6379&gt; hmset myhash field1 hello field2 worldOK127.0.0.1:6379&gt; hmget myhash field1 field21) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; hgetall myhash1) &quot;field&quot;2) &quot;kuangshen&quot;3) &quot;field1&quot;4) &quot;hello&quot;5) &quot;field2&quot;6) &quot;world&quot;127.0.0.1:6379&gt; hdel myhash field1(integer) 1127.0.0.1:6379&gt; hgetall myhash1) &quot;field&quot;2) &quot;kuangshen&quot;3) &quot;field2&quot;4) &quot;world&quot;##########################################hlen127.0.0.1:6379&gt; hgetall myhash1) &quot;field&quot;2) &quot;kuangshen&quot;3) &quot;field2&quot;4) &quot;world&quot;127.0.0.1:6379&gt; hlen myhash # 获取hash表的字段数量(integer) 2##########################################127.0.0.1:6379&gt; hexists myhash field1 # 判断hash中指定字段是否存在！(integer) 0127.0.0.1:6379&gt; hexists myhash field2(integer) 1127.0.0.1:6379&gt; hgetall myhash1) &quot;field&quot;2) &quot;kuangshen&quot;3) &quot;field2&quot;4) &quot;world&quot;########################################### 只获取所有的field127.0.0.1:6379&gt; hkeys myhash1) &quot;field&quot;2) &quot;field2&quot;# 只获取所有的value127.0.0.1:6379&gt; hvals myhash1) &quot;kuangshen&quot;2) &quot;world&quot;########################################## hash变更的数据 user name age，尤其是用户信息之类的，经常变动的数据！hash更适合于对象的存储，String更加适合字符串存储！ Zset(有序集合)123456zaddzrangezrangebyscore xxx -inf +inf withscores # 显示全部的用户并且附带成绩zrevrange # 从大到小排序zrem # 移除元素zcount # 获取指定区间的成员数量 其余API，查官方文档案例思路：set 排序 存储班级成绩表，工资排序表！普通消息：1 重要消息：2 带权重进行判断！排行榜应用实现，取TOP 10 1################################################## Redis 有哪些好处 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 支持丰富数据类型，支持string，list，set，sorted set，hash 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 1）String 常用命令： set/get/decr/incr/mget等； 应用场景： String是最常用的一种数据类型，普通的key/value存储都可以归为此类； 实现方式： String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。 2）Hash 常用命令： hget/hset/hgetall等 应用场景： 我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日； 实现方式： Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。Key是用户ID, value是一个Map。这个Map的key是成员的属性名，value是属性值。这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field), 也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据。 当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的value的redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。 3）List 常用命令： lpush/rpush/lpop/rpop/lrange等； 应用场景： Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现； 实现方式： Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。 4）Set 常用命令： sadd/spop/smembers/sunion等； 应用场景： Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的； 实现方式： set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。 5）Sorted Set 常用命令： zadd/zrange/zrem/zcard等； 应用场景： Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。 实现方式： Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"},{"name":"数据类型","slug":"数据类型","permalink":"https://xmmarlowe.github.io/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}],"author":"Marlowe"},{"title":"Redis 基础知识","slug":"NoSQL/Redis-基础知识","date":"2020-12-19T08:19:14.000Z","updated":"2020-12-20T15:40:18.893Z","comments":true,"path":"2020/12/19/NoSQL/Redis-基础知识/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/19/NoSQL/Redis-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"Redis 基础知识","text":"Redis 基础知识 Redis 是单线程的！ Redis 是很快的，官方表示，Redis 是基于内存操作，CPU 不是Redis性能瓶颈，Redis 的瓶颈是根据机器的内存和网络带宽，既然可以使用单线程实现，就使用单线程了。 Redis 是C语言写的，官方提供的数据位100000+的QPS，完全不比同样的使用key-value的Memecache差。 Redis 单线程为什么还这么快？ 误区1： 高性能服务器一定是多线程的？ 误区2： 多线程(CPU上下文会切换)一定比单线程效率高？ 核心：Redis 是将所有的数据全部放在内存中的，所以说使用单线程去操作效率就是最高的，多线程(CPU上下文切换：耗时的操作！！)对于内存系统来说，如果没有上下文切换效率就是最高的！多次读写都是在一个CPU上，在内存情况下，这就是最佳的方案！","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"}],"author":"Marlowe"},{"title":"高效的一天","slug":"学习方法/高效的一天","date":"2020-12-19T01:18:48.000Z","updated":"2020-12-20T15:40:18.911Z","comments":true,"path":"2020/12/19/学习方法/高效的一天/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/19/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E9%AB%98%E6%95%88%E7%9A%84%E4%B8%80%E5%A4%A9/","excerpt":"大佬高效工作的一天…","text":"大佬高效工作的一天… 半小时整理每日重点和待办事项12整理每日计划，梳理一下今天大概要做什么事情，思考每件事情的优先级软件推荐：Notion 独立的工作区 回想昨天的工作，处理邮件 提前准备会议内容1Visio or PPT 整理要说的内容 避免多任务切换1和计算机类似，在计算机里切换任务，或者发生中断，要保存各种状态，上下文和数据，完成中断之后，还要恢复之前保存的数据，保存和恢复的过程，都要花费大量的计算，想办法尽量避免中断 在家工作划分工作和生活的界限 必要的生产力工具1iPad Pro + Notability + Notion 琐碎任务集中处理","categories":[{"name":"学习方法","slug":"学习方法","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://xmmarlowe.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"效率","slug":"效率","permalink":"https://xmmarlowe.github.io/tags/%E6%95%88%E7%8E%87/"},{"name":"工作方法","slug":"工作方法","permalink":"https://xmmarlowe.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95/"}],"author":"Marlowe"},{"title":"ES 文档的API操作详情","slug":"ElasticSearch/ES-文档的API操作详情","date":"2020-12-08T11:16:02.000Z","updated":"2020-12-10T00:43:37.401Z","comments":true,"path":"2020/12/08/ElasticSearch/ES-文档的API操作详情/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/08/ElasticSearch/ES-%E6%96%87%E6%A1%A3%E7%9A%84API%E6%93%8D%E4%BD%9C%E8%AF%A6%E6%83%85/","excerpt":"…","text":"… 编写ElasticSearchConfig 配置文件，将ES交给Spring托管 ElasticSearchConfig.java 1234567891011@Configurationpublic class ElasticSearchConfig &#123; @Bean public RestHighLevelClient restHighLevelClient() &#123; RestHighLevelClient restHighLevelClient = new RestHighLevelClient( RestClient.builder( new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;))); return restHighLevelClient; &#125;&#125; ES部分APIKuangEsApiApplicationTests.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173@SpringBootTestclass KuangEsApiApplicationTests &#123; @Autowired @Qualifier(&quot;restHighLevelClient&quot;) private RestHighLevelClient client; /** * 测试索引的创建 Request PUT kuang_index */ @Test void testCreateIndex() throws IOException &#123; // 1.创建索引请求 CreateIndexRequest request = new CreateIndexRequest(&quot;kuang_index&quot;); // 2.客户端执行请求 IndicesClient 请求后获得相应 CreateIndexResponse createIndexResponse = client.indices().create(request, RequestOptions.DEFAULT); System.out.println(createIndexResponse); &#125; /** * 测试获取索引,判断其是否存在 */ @Test void testExistsIndex() throws IOException &#123; GetIndexRequest request = new GetIndexRequest(&quot;kuang_index&quot;); boolean exists = client.indices().exists(request, RequestOptions.DEFAULT); System.out.println(exists); &#125; /** * 测试删除索引，判断是否存在 * * @throws IOException */ @Test void testDeleteIndex() throws IOException &#123; DeleteIndexRequest request = new DeleteIndexRequest(&quot;kuang_index&quot;); AcknowledgedResponse delete = client.indices().delete(request, RequestOptions.DEFAULT); System.out.println(delete.isAcknowledged()); &#125; /** * 测试添加文档 */ @Test void testAddDocument() throws IOException &#123; // 创建对象 User user = new User(&quot;狂神说&quot;, 3); // 创建请求 IndexRequest request = new IndexRequest(&quot;kuang_index&quot;); // 规则 put /kuang_index/_doc/1 request.id(&quot;1&quot;); request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(&quot;1s&quot;); // 将我们的数据放入请求 json IndexRequest source = request.source(JSON.toJSONString(user), XContentType.JSON); // 客户端发送请求,获取响应的结果 IndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT); System.out.println(indexResponse.toString()); System.out.println(indexResponse.status()); &#125; /** * 获取文档，判断是否存在 */ @Test void testIsExists() throws IOException &#123; GetRequest getRequest = new GetRequest(&quot;kuang_index&quot;, &quot;1&quot;); // 不获取返回的_source的上下文了 getRequest.fetchSourceContext(new FetchSourceContext(false)); getRequest.storedFields(&quot;_none_&quot;); boolean exists = client.exists(getRequest, RequestOptions.DEFAULT); System.out.println(exists); &#125; /** * 获取文档的信息 */ @Test void testGetDocument() throws IOException &#123; GetRequest getRequest = new GetRequest(&quot;kuang_index&quot;, &quot;1&quot;); GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT); // 打印文档的内容 System.out.println(getResponse.getSourceAsString()); // 返回的全部内容和命令是一样的 System.out.println(getResponse); &#125; /** * 更新文档的信息 */ @Test void testUpdateDocument() throws IOException &#123; UpdateRequest updateRequest = new UpdateRequest(&quot;kuang_index&quot;, &quot;1&quot;); updateRequest.timeout(&quot;1s&quot;); User user = new User(&quot;狂神说Java&quot;, 18); updateRequest.doc(JSON.toJSONString(user), XContentType.JSON); UpdateResponse updateResponse = client.update(updateRequest, RequestOptions.DEFAULT); System.out.println(updateResponse.status()); &#125; /** * 删除文档的信息 */ @Test void testDeleteDocument() throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(&quot;kuang_index&quot;, &quot;1&quot;); deleteRequest.timeout(&quot;1s&quot;); DeleteResponse deleteResponse = client.delete(deleteRequest, RequestOptions.DEFAULT); System.out.println(deleteResponse); &#125; /** * 批量插入数据 */ @Test void testBulkRequest() throws IOException &#123; BulkRequest bulkRequest = new BulkRequest(); bulkRequest.timeout(&quot;10s&quot;); List&lt;User&gt; userList = new ArrayList&lt;&gt;(); userList.add(new User(&quot;kuangshen1&quot;, 3)); userList.add(new User(&quot;kuangshen2&quot;, 3)); userList.add(new User(&quot;kuangshen3&quot;, 3)); userList.add(new User(&quot;qinjiang1&quot;, 3)); userList.add(new User(&quot;qinjiang2&quot;, 3)); userList.add(new User(&quot;qinjiang3&quot;, 3)); // 批处理请求 for (int i = 0; i &lt; userList.size(); i++) &#123; bulkRequest.add( new IndexRequest(&quot;kuang_index&quot;) .id(&quot;&quot; + (i + 1)) .source(JSON.toJSONString(userList.get(i)), XContentType.JSON)); &#125; BulkResponse bulkResponse = client.bulk(bulkRequest, RequestOptions.DEFAULT); System.out.println(bulkResponse.hasFailures()); &#125; /** * 查询 * searchRequest 搜索请求 * SearchSourceBuilder 条件构造 * HighlightBuilder 构建高亮 * TermQueryBuilder 精确查询 */ @Test void testSearch() throws IOException &#123; SearchRequest searchRequest = new SearchRequest(ESConst.ES_INDEX); // 构建搜索条件 SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); // 查询条件，我们可以使用QueryBuilder 工具来实现 TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(&quot;name&quot;, &quot;qinjiang1&quot;); sourceBuilder.query(termQueryBuilder); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); searchRequest.source(sourceBuilder); SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSON.toJSONString(searchResponse.getHits())); System.out.println(&quot;======================&quot;); for (SearchHit documentFields : searchResponse.getHits().getHits()) &#123; System.out.println(documentFields.getSourceAsMap()); &#125; &#125;&#125;","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://xmmarlowe.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ES","slug":"ES","permalink":"https://xmmarlowe.github.io/tags/ES/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://xmmarlowe.github.io/tags/SpringBoot/"},{"name":"API","slug":"API","permalink":"https://xmmarlowe.github.io/tags/API/"}],"author":"Marlowe"},{"title":"Rest风格操作","slug":"ElasticSearch/Rest风格操作","date":"2020-12-08T04:24:51.000Z","updated":"2020-12-09T08:26:40.796Z","comments":true,"path":"2020/12/08/ElasticSearch/Rest风格操作/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/08/ElasticSearch/Rest%E9%A3%8E%E6%A0%BC%E6%93%8D%E4%BD%9C/","excerpt":"","text":"关于索引的基本操作12PUT /索引名/~类型名~/文档id&#123;请求体&#125; 完成了自动增加索引！数据也成功的添加了 指定字段的类型 12345678910111213141516PUT /test2&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;age&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;birthday&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125;&#125; 创建规则 可以通过GET请求获取具体信息 查看默认信息 如果自己的文档字段没有指定，那么es会给我们默认配置字段类型！ 扩展：通过命令elasticsearch索引情况！通过GET _cat/ 可以获得es当前的很多信息！ 更新方法 以前的方法 现在的方法 删除索引通过DELETE命令删除、根据你的请求来判断是删除索引还是删除文档记录！使用RESTFUL风格是ES推荐大家使用的！ 关于文档的基本操作(重点)基本操作 添加数据 1234567PUT /kuangshen/user/2&#123; &quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 20, &quot;desc&quot;: &quot;法外狂徒张三&quot;, &quot;tags&quot;: [&quot;旅游&quot;,&quot;温暖&quot;,&quot;渣男&quot;]&#125; 获取数据 GET 1GET /kuangshen/user/1 更新数据 PUT POST _updatePUT如果不传递值就会被覆盖，POST灵活度更高 简单的搜索 1GET /kuangshen/user/1 简单的条件查询,可以根据默认的映射规则，产生基本的查询！ 1GET /kuangshen/user/_search?q=name:狂神说java 复杂操作搜索select(排序，分页，高亮，模糊查询，精准查询！) hits：索引和文档的信息查询的结果总数然后就是查询出来的具体的文档数据中心的所有东西都可以遍历出来了分数：我们可以通过分数来判断谁更加符合搜索结果 输出结果，只需要指定的字段 之后Java操作es，所有的方法和对象就是这里面的key！ 排序 分页查询数据下标还是从0开始的，和学的所有的数据结构是一样的！/search/{current}/{pagesize}布尔值查询must（and）,所有的条件都要符合 where id = 1 and name = xxx多条件查询 should（or）,所有的条件都要符合 where id = 1 or name = xxx must_not (not) 过滤器 filter 匹配多个条件 term查询是直接通过倒排索引指定的词条进行精确的查找！ 关于分词 term，直接查询精确的 match，会使用分词器解析！(先分析文档，然后再通过分析的文档进行查询！) 两个类型 text keyword keyword 字段类型不会被分词器解析 多个值匹配的精确查询 高亮查询 自定义搜索高亮条件 这些MySQL也能做，只是MySQL效率比较低！ 匹配 按照条件匹配 精确匹配 区间范围匹配 区间字段匹配 多条件查询 高亮查询","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://xmmarlowe.github.io/categories/ElasticSearch/"}],"tags":[{"name":"ES","slug":"ES","permalink":"https://xmmarlowe.github.io/tags/ES/"},{"name":"Resuful","slug":"Resuful","permalink":"https://xmmarlowe.github.io/tags/Resuful/"}],"author":"Marlowe"},{"title":"ElasticSearch之ik插件之究极大坑","slug":"环境配置之踩坑/ElasticSearch之ik插件之究极大坑","date":"2020-12-07T17:10:24.000Z","updated":"2020-12-07T17:25:12.629Z","comments":true,"path":"2020/12/08/环境配置之踩坑/ElasticSearch之ik插件之究极大坑/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/08/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%B9%8B%E8%B8%A9%E5%9D%91/ElasticSearch%E4%B9%8Bik%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%A9%B6%E6%9E%81%E5%A4%A7%E5%9D%91/","excerpt":"由于最近要做搜索引擎课设，可以用ElasticSearch做，因此，开启了ES的学习之路，也开启了ES踩坑之路，入门一小时，配环境两小时！！~","text":"由于最近要做搜索引擎课设，可以用ElasticSearch做，因此，开启了ES的学习之路，也开启了ES踩坑之路，入门一小时，配环境两小时！！~ 在elasticsearch中安装ik中文分词器，使用的elasticsearch版本是7.10.0，elasticsearch-analysis-ik版本是7.10.0。 安装后，重新启动报错，报错信息为： 12[2020-11-18T17:14:56,012][WARN ][o.e.c.r.a.AllocationService] [LAPTOP-TLVIFKFC] failing shard [AccessControlException[access denied (&quot;java.io.FilePermission&quot; &quot;D:\\Program%20Files\\elasticsearch\\elasticsearch-7.10.0\\plugins\\ik\\config\\IKAnalyzer.cfg.xml&quot; &quot;read&quot;)]], markAsStale [true]]java.security.AccessControlException: access denied (&quot;java.io.FilePermission&quot; &quot;D:\\Program%20Files\\elasticsearch\\elasticsearch-7.10.0\\plugins\\ik\\config\\IKAnalyzer.cfg.xml&quot; &quot;read&quot;) 原因是：elasticsearch安装路径中有空格造成的，如安装路径为D:\\Program Files\\elasticsearch\\elasticsearch-7.10.0，其中”Program Files”两个词中间有空格 解决方法：elasticsearch选择没有空格的文件目录下安装 前前后后下载了很多版本的插件，以及找同学烤文件，都没能解决这个问题，在百度重新搜索elasticsearch ik 7.10.0 下载的时候，出现了一篇拯救我的文章，重新安装好es所需要的文件后，将整个文件移动到没有空格的文件夹，问题才得以解决！ 参考：elasticsearch-7.10.0使用elasticsearch-analysis-ik-7.10.0分词器插件后启动报错 ES学习教程:【狂神说Java】ElasticSearch7.6.x最新完整教程通俗易懂","categories":[{"name":"环境配置之踩坑","slug":"环境配置之踩坑","permalink":"https://xmmarlowe.github.io/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%B9%8B%E8%B8%A9%E5%9D%91/"}],"tags":[{"name":"ES","slug":"ES","permalink":"https://xmmarlowe.github.io/tags/ES/"},{"name":"踩坑","slug":"踩坑","permalink":"https://xmmarlowe.github.io/tags/%E8%B8%A9%E5%9D%91/"}],"author":"Marlowe"},{"title":"Java中如何跳出多重循环","slug":"Java/Java中如何跳出多重循环","date":"2020-12-07T00:20:29.000Z","updated":"2021-03-19T13:00:33.354Z","comments":true,"path":"2020/12/07/Java/Java中如何跳出多重循环/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/07/Java/Java%E4%B8%AD%E5%A6%82%E4%BD%95%E8%B7%B3%E5%87%BA%E5%A4%9A%E9%87%8D%E5%BE%AA%E7%8E%AF/","excerpt":"Java 基础回顾…","text":"Java 基础回顾… 在JAVA中如何跳出当前的多重嵌套循环在java中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的的break语句，即可跳出 1234567891011public static void main(String[] args) &#123; ok: while (true) &#123; for (int i = 0; i &lt; 10000; i++) &#123; System.out.println(i); if (i == 200) &#123; break ok; &#125; &#125; &#125; &#125; return和 break区别breakbreak语句虽然可以独立使用，但通常主要用于switch语句中，控制程序的执行流程转移。在switch语句中，其作用是强制退出switch结构，执行switch结构之后的语句。其本质就是在单层循环结构体系中，其作用是强制退出循环结构。 returnreturn语句用来明确地从一个方法返回。也就是，return 语句使程序控制返回到调用它方法。因此，将它分类为跳转语句.有两个作用，一个是返回方法指定类型的值（这个值总是确定的）;一个是结束方法的执行（仅仅一个return语句）。return 语句可以使其从当前方法中退出，返回到调用该方法的语句处，继续程序的执行 。 exit()函数 和 return 区别exit(0)：正常运行程序并退出程序；exit(1)：非正常运行导致退出程序；return()：返回函数，若在主函数中，则会退出函数并返回一值。 具体来说： return返回函数值，是关键字； exit 是一个函数。 return是语言级别的，它表示了调用堆栈的返回；而exit是系统调用级别的，它表示结束一个进程 。 return是函数的退出(返回)；exit是进程的退出。 return是C语言提供的，exit是操作系统提供的（或者函数库中给出的）。 return用于结束一个函数的执行，将函数的执行信息传出个其他调用函数使用；exit函数是退出应用程序，删除进程使用的内存空间，并将应用程序的一个状态返回给OS，这个状态标识了应用程序的一些运行信息，这个信息和机器和操作系统有关，一般是 0 为正常退出， 非0 为非正常退出。 非主函数中调用return和exit效果很明显，但是在main函数中调用return和exit的现象就很模糊，多数情况下现象都是一致的。 参考在java中如何跳出当前的多重嵌套循环？","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://xmmarlowe.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://xmmarlowe.github.io/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"面经","slug":"面经","permalink":"https://xmmarlowe.github.io/tags/%E9%9D%A2%E7%BB%8F/"}],"author":"Marlowe"},{"title":"Swagger在线文档","slug":"Spring/Swagger在线文档","date":"2020-12-06T10:30:51.000Z","updated":"2020-12-18T02:35:43.038Z","comments":true,"path":"2020/12/06/Spring/Swagger在线文档/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/06/Spring/Swagger%E5%9C%A8%E7%BA%BF%E6%96%87%E6%A1%A3/","excerpt":"Swagger在线文档使用教程…","text":"Swagger在线文档使用教程… SpringBoot集成Swagger 新建一个SpringBoot项目==&gt;web 导入相关依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 编写HelloWorld 配置Swagger1234@Configuration@EnableSwagger2public class SwaggerConfig &#123;&#125; 测试运行 http://localhost:8080/swagger-ui.html 配置Swagger信息Swagger的bean示例Docket 123456789101112131415161718192021222324252627@Configuration@EnableSwagger2public class SwaggerConfig &#123; /** * 配置了Swagger的Docket的bean实例 * * @return */ @Bean public Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()); &#125; public ApiInfo apiInfo() &#123; // 作者信息 Contact contact = new Contact(&quot;Marlowe&quot;, &quot;https://xmmarlowe.github.io&quot;, &quot;marlowe246@qq.com&quot;); return new ApiInfo(&quot;Visit CQUT Swagger API Documentation&quot;, &quot;Api Documentation&quot;, &quot;v1.0&quot;, &quot;urn:tos&quot;, contact, &quot;Apache 2.0&quot;, &quot;http://www.apache.org/licenses/LICENSE-2.0&quot;, new ArrayList()); &#125;&#125; Swagger配置扫描接口Docket.select() 1234567891011121314151617181920212223/** * 配置了Swagger的Docket的bean实例 * * @return */ @Bean public Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() /** * RequestHandlerSelectors，配置要扫描接口的方式 * basePackage:指定要扫描的包 * any():扫描全部 * none():不扫描 * withClassAnnotation:扫描类上的注解，参数是一个注解的反射对象 * withMethodAnnotation：扫描方法上的注解 */ .apis(RequestHandlerSelectors.basePackage(&quot;com.marlowe.swagger.controller&quot;)) // paths(): 过滤什么路径 .paths(PathSelectors.ant(&quot;/marlowe/**&quot;)) .build(); &#125; 配置是否启动swagger 123456789101112131415/** * 配置了Swagger的Docket的bean实例 * * @return */ @Bean public Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) // enable是否启动Swagger，如果为false，则swagger不能在浏览器中访问 .enable(false) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.marlowe.swagger.controller&quot;)) .build(); &#125; 我只希望我的Swagger在生产环境中使用，在发布的时候不使用？ 判断是不是生产环境 flag = false 注入enable(flag)123456789101112131415161718192021/** * 配置了Swagger的Docket的bean实例 * * @return */ @Bean public Docket docket(Environment environment) &#123; // 设置要现实的swagger环境 Profiles profiles = Profiles.of(&quot;dev&quot;, &quot;test&quot;); // 获取项目的环境： boolean flag = environment.acceptsProfiles(profiles); return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) // enable是否启动Swagger，如果为false，则swagger不能在浏览器中访问 .enable(flag) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.marlowe.swagger.controller&quot;)) .build(); &#125; 配置API文档的分组1.groupName(&quot;Marlowe&quot;) 如何配置多个分组；多个Docket实例即可1234567891011121314@Beanpublic Docket docket1() &#123; return new Docket(DocumentationType.SWAGGER_2).groupName(&quot;A&quot;);&#125;@Beanpublic Docket docket2() &#123; return new Docket(DocumentationType.SWAGGER_2).groupName(&quot;B&quot;);&#125;@Beanpublic Docket docket3() &#123; return new Docket(DocumentationType.SWAGGER_2).groupName(&quot;C&quot;);&#125; 实体类配置12345678910111213141516171819package com.marlowe.swagger.pojo;import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;/** * @program: swagger-demo * @description: * @author: Marlowe * @create: 2020-12-06 19:39 **/@ApiModel(&quot;用户实体类&quot;)public class User &#123; @ApiModelProperty(&quot;用户名&quot;) public String username; @ApiModelProperty(&quot;密码&quot;) public String password;&#125; controller12345678910111213141516171819202122232425262728293031323334353637383940414243package com.marlowe.swagger.controller;import com.marlowe.swagger.pojo.User;import io.swagger.annotations.Api;import io.swagger.annotations.ApiOperation;import io.swagger.annotations.ApiParam;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;/** * @program: swagger-demo * @description: * @author: Marlowe * @create: 2020-12-06 18:07 **/@Api(tags = &quot;hello控制类&quot;)@RestControllerpublic class HelloController &#123; @GetMapping(value = &quot;/hello&quot;) public String hello() &#123; return &quot;hello&quot;; &#125; @PostMapping(value = &quot;/user&quot;) public User user() &#123; return new User(); &#125; @ApiOperation(&quot;Hello 控制类&quot;) @GetMapping(value = &quot;/hello2&quot;) public String hello2(@ApiParam(&quot;用户名&quot;) String username) &#123; return &quot;hello&quot; + username; &#125; @ApiOperation(&quot;Post 控制类&quot;) @GetMapping(value = &quot;/postt&quot;) public User post(@ApiParam(&quot;用户&quot;) User user) &#123; return user; &#125;&#125; 总结： 可以通过Swagger给一些比较难理解的属性或者接口，增加注释信息 接口文档实时更新 可以在线测试 【注意点】在正式发布的时候，关闭Swagger！！！ 处于安全考虑，并且节省内存！","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/categories/Spring/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://xmmarlowe.github.io/tags/SpringBoot/"},{"name":"Swagger","slug":"Swagger","permalink":"https://xmmarlowe.github.io/tags/Swagger/"},{"name":"配置","slug":"配置","permalink":"https://xmmarlowe.github.io/tags/%E9%85%8D%E7%BD%AE/"}],"author":"Marlowe"},{"title":"使用注解开发","slug":"Spring/使用注解开发","date":"2020-12-05T05:40:10.000Z","updated":"2020-12-05T06:18:50.748Z","comments":true,"path":"2020/12/05/Spring/使用注解开发/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/05/Spring/%E4%BD%BF%E7%94%A8%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/","excerpt":"使用注解开发…","text":"使用注解开发… 在Spring4之后，使用注解开发，必须要保证aop的包导入了使用注解需要导入context约束，增加注解的支持！ 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--开启注解的支持--&gt; &lt;context:annotation-config/&gt;&lt;/beans&gt; 1.bean2.属性如何注入12345678910@Componentpublic class User &#123; public String name; // 相当于&lt;property name=&quot;name&quot; value=&quot;marlowe2&quot;&gt; @Value(&quot;marlowe2&quot;) public void setName(String name) &#123; this.name = name; &#125;&#125; 3.衍生的注解@Component有几个衍生注解，我们再web开发中，会按照mvc三层架构分层！ dao【@Repository】 service【@Service】 controller【@Service】这四个注解的功能都是一样的，都是代表将某个类注册到Spring中，装配Bean 4.自动装配1234- @Autowired:自动装配通过类型。名字 如果Autowired不能唯一自动装配上属性，则需要通过@Qualifier(value=&quot;xxx&quot;)- @Nullable： 字段标记了这个注解，说明这个字段可以为null- @Resource： 自动装配通过名字。类型 5.作用域1234567891011@Component@Scope(&quot;prototype&quot;)public class User &#123; public String name; // 相当于&lt;property name=&quot;name&quot; value=&quot;marlowe2&quot;&gt; @Value(&quot;marlowe2&quot;) public void setName(String name) &#123; this.name = name; &#125;&#125; 6.小结xml与注解： xml： 更加万能，适用于任何场合！维护简单方便 注解： 不是自己的类使用不了，维护相对复杂！ xml与注解最佳实践： xml用来管理bean 注解只负责完成属性的注入 我们在使用的过程中，只需要注意一个问题：必须让注解生效，就需要开启注解的支持 123&lt;!--指定要扫描的包，这个包下面的注解就会生效--&gt;&lt;context:component-scan base-package=&quot;com.marlowe&quot;/&gt;&lt;context:annotation-config/&gt;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/tags/Spring/"},{"name":"注解","slug":"注解","permalink":"https://xmmarlowe.github.io/tags/%E6%B3%A8%E8%A7%A3/"}],"author":"Marlowe"},{"title":"依赖注入","slug":"Spring/依赖注入","date":"2020-12-05T04:50:54.000Z","updated":"2020-12-05T04:55:07.288Z","comments":true,"path":"2020/12/05/Spring/依赖注入/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/05/Spring/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/","excerpt":"简述依赖注入的三种方式","text":"简述依赖注入的三种方式 构造器注入见文章《IOC创建对象的方式》 Set方式注入【重点】 依赖注入：Set注入！ 依赖：bean对象的创建依赖于容器！ 注入：bean对象中的所有属性，由容器来注入！ 【环境搭建】 复杂类型123456789101112public class Address &#123; private String address; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125;&#125; 真实测试对象 12345678910public class Student &#123; private String name; private Address address; private String[] books; private List&lt;String&gt; hobbies; private Map&lt;String, String&gt; card; private Set&lt;String&gt; games; private String wife; private Properties info;&#125; beans.xml 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!--第一种，普通值注入，value--&gt; &lt;bean id=&quot;student&quot; class=&quot;com.marlowe.pojo.Student&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;marlowe&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 测试类 1234567public class MyTest &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); Student student = (Student) context.getBean(&quot;student&quot;); System.out.println(student.getName()); &#125;&#125; 完善注入信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;address&quot; class=&quot;com.marlowe.pojo.Address&quot;&gt; &lt;property name=&quot;address&quot; value=&quot;China&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;student&quot; class=&quot;com.marlowe.pojo.Student&quot;&gt; &lt;!--第一种，普通值注入，value--&gt; &lt;property name=&quot;name&quot; value=&quot;marlowe&quot;/&gt; &lt;!--第二种，Bean注入，ref--&gt; &lt;property name=&quot;address&quot; ref=&quot;address&quot;/&gt; &lt;!--数组--&gt; &lt;property name=&quot;books&quot;&gt; &lt;array&gt; &lt;value&gt;红楼梦&lt;/value&gt; &lt;value&gt;西游记&lt;/value&gt; &lt;value&gt;三国演义&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;!--List--&gt; &lt;property name=&quot;hobbies&quot;&gt; &lt;list&gt; &lt;value&gt;篮球&lt;/value&gt; &lt;value&gt;乒乓球&lt;/value&gt; &lt;value&gt;足球&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--map--&gt; &lt;property name=&quot;card&quot;&gt; &lt;map&gt; &lt;entry key=&quot;身份证&quot; value=&quot;11111111&quot;/&gt; &lt;entry key=&quot;银行卡&quot; value=&quot;22222222&quot;/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--Set--&gt; &lt;property name=&quot;games&quot;&gt; &lt;set&gt; &lt;value&gt;LoL&lt;/value&gt; &lt;value&gt;DNF&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!--null--&gt; &lt;property name=&quot;wife&quot;&gt; &lt;null/&gt; &lt;/property&gt; &lt;!--Properties--&gt; &lt;property name=&quot;info&quot;&gt; &lt;props&gt; &lt;prop key=&quot;driver&quot;&gt;11111&lt;/prop&gt; &lt;prop key=&quot;url&quot;&gt;marlowe&lt;/prop&gt; &lt;prop key=&quot;username&quot;&gt;root&lt;/prop&gt; &lt;prop key=&quot;password&quot;&gt;123456&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 扩展方式注入我们可以使用p命名空间和c命名空间进行注入官方解释： 使用: 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:c=&quot;http://www.springframework.org/schema/c&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!--p命名空间注入，可以直接注入属性的值：property--&gt; &lt;bean id=&quot;user&quot; class=&quot;com.marlowe.pojo.User&quot; p:name=&quot;marlowe&quot; p:age=&quot;18&quot;&gt;&lt;/bean&gt; &lt;!--c命名空间注入，可以通过构造器注入：construct-args--&gt; &lt;bean id=&quot;user2&quot; class=&quot;com.marlowe.pojo.User&quot; c:name=&quot;marlowe&quot; c:age=&quot;18&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; 测试： 123456@Testpublic void test2() &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;userbeans.xml&quot;); User user = (User) context.getBean(&quot;user2&quot;); System.out.println(user.toString());&#125; 注意点：p命名和c命名不能直接使用，需要导入xml约束！ 12xmlns:p=&quot;http://www.springframework.org/schema/p&quot;xmlns:c=&quot;http://www.springframework.org/schema/c&quot; bean的作用域 单例模式（spring默认机制）1&lt;bean id=&quot;user2&quot; class=&quot;com.marlowe.pojo.User&quot; c:name=&quot;marlowe&quot; c:age=&quot;18&quot; scope=&quot;singleton&quot;&gt;&lt;/bean&gt; 原型模式：每次从容器中get的时候，都会产生一个新对象！1&lt;bean id=&quot;user2&quot; class=&quot;com.marlowe.pojo.User&quot; c:name=&quot;marlowe&quot; c:age=&quot;18&quot; scope=&quot;singleton&quot;&gt;&lt;/bean&gt; 其余的request、session、application 这些只能在web开发中使用到！","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/tags/Spring/"},{"name":"DI","slug":"DI","permalink":"https://xmmarlowe.github.io/tags/DI/"}],"author":"Marlowe"},{"title":"Bean的自动装配","slug":"Spring/Bean的自动装配","date":"2020-12-05T03:55:53.000Z","updated":"2020-12-05T05:38:33.810Z","comments":true,"path":"2020/12/05/Spring/Bean的自动装配/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/05/Spring/Bean%E7%9A%84%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D/","excerpt":"bean的三种自动装配方式…","text":"bean的三种自动装配方式… 自动装配是Spring满足bean依赖的一种方式 Spring会在上下文中自动寻找，并自动给bean装配属性 在Spring中有三种装配方式 在xml中显示的配置 在java中显示配置 隐式的自动装配bean【重要】 测试环境搭建：一个人有两个宠物 12345public class People &#123; private String name; private Cat cat; private Dog dog;&#125; byName自动装配123456&lt;!--byName:会自动在容器上下文中查找和自己对象set方法后面的值对应的bean id！--&gt;&lt;bean id=&quot;people&quot; class=&quot;com.marlowe.pojo.People&quot; autowire=&quot;byName&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;陈浩南&quot;/&gt;&lt;/bean&gt; byType自动装配123456789&lt;bean class=&quot;com.marlowe.pojo.Cat&quot;/&gt;&lt;bean class=&quot;com.marlowe.pojo.Dog&quot;/&gt;&lt;!--byName:会自动在容器上下文中查找，和自己对象set方法后面的值对应的bean id！byType:会自动在容器上下文中查找，和自己对象属性类型相同的bean！--&gt;&lt;bean id=&quot;people&quot; class=&quot;com.marlowe.pojo.People&quot; autowire=&quot;byType&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;陈浩南&quot;/&gt;&lt;/bean&gt; 小结： byName的时候，需要保证所有bean的id唯一，并且这个bean需要和自动注入的属性的set方法的值一致！（原理是将set方法后面部分转换成小写，再与id进行比对，例如：setDog ==&gt; id = “dog”、setdog1 ==&gt; id = “dog1”等可以自动注入、但是setDog ==&gt; id = “Dog”就不行） byType的时候，需要保证所有bean的class唯一，并且这个bean需要和自动注入的属性的类型一致！ 使用注解实现自动装配JDK1.5支持的注解，Spring2.5就支持注解了！要使用注解须知： 导入约束。context约束 配置注解的支持 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:annotation-config/&gt;&lt;/beans&gt; @Autowired 直接在属性上使用即可！也可以在set方式上使用！ 使用Autowired，我们可以不用编写set方法了，前提是你这个自动装配的属性在IOC（Spring）容器中存在，且符合名字byName！ 科普： 1@Nullable 字段标记了这个注解，说明这个字段可以为null 123 public @interface Autowired &#123; boolean required() default true;&#125; 测试代码 12345678public class People &#123; // 如果显示定义了Autowired的required属性为false，说明这个对象可以为null，否则不允许为空 @Autowired(required = false) private Cat cat; @Autowired private Dog dog; private String name;&#125;如果@Autowired自动装配的环境比较复杂，自动装配无法通过一个注解【@Autowired】完成额时候、我们可以使用@Qualifier(value = “xxx”)去配置@Autowired的使用，指定一个唯一的bean对象注入！ 1234567@Autowired@Qualifier(value = &quot;cat11&quot;)private Cat cat;@Autowired@Qualifier(value = &quot;dog11&quot;)private Dog dog; @Resource注解 1234567public class People &#123; @Resource(name = &quot;cat1&quot;) private Cat cat; @Resource private Dog dog;&#125; 小结：@Autowired和@Resource的区别： 都是用来自动装配的，都可以放在属性字段上 @Autowired 通过byType的方式实现，而且必须要求这个对象存在！【常用】 @Resource默认通过byName的方式实现，如果找不到名字，则通过byType实现！如果两个都找不到的情况下，就报错！【常用】 执行顺序不同：@Autowired 通过byType的方式实现。@Resource默认通过byName的方式实现。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/categories/Spring/"}],"tags":[{"name":"Bean","slug":"Bean","permalink":"https://xmmarlowe.github.io/tags/Bean/"},{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/tags/Spring/"}],"author":"Marlowe"},{"title":"IOC创建对象的方式","slug":"Spring/IOC创建对象的方式","date":"2020-12-04T13:02:41.000Z","updated":"2020-12-05T04:49:49.390Z","comments":true,"path":"2020/12/04/Spring/IOC创建对象的方式/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/04/Spring/IOC%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E5%BC%8F/","excerpt":"IOC创建对象的三种方式…","text":"IOC创建对象的三种方式… 下标 1234&lt;!--第一种方式：下标赋值--&gt;&lt;bean id=&quot;user&quot; class=&quot;com.marlowe.pojo.User&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;狂神说Java&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 类型 1234&lt;!--第二种方式：不建议使用！通过类型创建--&gt;&lt;bean id=&quot;user&quot; class=&quot;com.marlowe.pojo.User&quot;&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;狂神&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 参数名 1234&lt;!--第三种方式，直接通过参数名来设置--&gt;&lt;bean id=&quot;user&quot; class=&quot;com.marlowe.pojo.User&quot;&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;狂神说Java&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 总结：在配置文件加载的时候，容器中管理的对象就已经初始化了！","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/tags/Spring/"},{"name":"IOC","slug":"IOC","permalink":"https://xmmarlowe.github.io/tags/IOC/"}],"author":"Marlowe"},{"title":"集合类不安全","slug":"并发/集合类不安全","date":"2020-12-03T13:49:32.000Z","updated":"2021-04-19T12:10:57.119Z","comments":true,"path":"2020/12/03/并发/集合类不安全/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/03/%E5%B9%B6%E5%8F%91/%E9%9B%86%E5%90%88%E7%B1%BB%E4%B8%8D%E5%AE%89%E5%85%A8/","excerpt":"111","text":"111 List不安全12345678910111213141516171819202122232425262728293031323334353637383940package com.marlowe.unsafe;import java.util.*;import java.util.concurrent.CopyOnWriteArrayList;/** * @program: juc * @description: java.util.ConcurrentModificationException 并发修改异常 * @author: Marlowe * @create: 2020-12-03 21:00 **/public class ListTest &#123; public static void main(String[] args) &#123; /** * 并发下ArrayList 不安全的 * * 解决方法： * 1、List&lt;String&gt; list = new Vector&lt;&gt;(); * 2、List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); * 3、List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); */ /** * CopyOnWrite 写入时复制 COW 计算机程序设计领域的一种优化策略 * 多个线程调用的时候，list，读取的时候，固定的，写入的（覆盖） * 在写入的时候避免覆盖，造成数据问题！ * CopyOnWriteArrayList 比 Vector 好在那里 前者是lock，后者是是synchronized */ List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; list.add(UUID.randomUUID().toString().substring(0, 5)); System.out.println(list); &#125;, String.valueOf(i)).start(); &#125; &#125;&#125; Set不安全123456789101112131415161718192021222324252627282930package com.marlowe.unsafe;import java.util.Collections;import java.util.HashSet;import java.util.Set;import java.util.UUID;import java.util.concurrent.CopyOnWriteArraySet;/** * @program: juc * @description: 同理可证 ：java.util.ConcurrentModificationException * 1、Set&lt;String&gt; set = Collections.synchronizedSet(new HashSet&lt;&gt;()); * 2、Set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;(); * @author: Marlowe * @create: 2020-12-03 21:53 **/public class SetTest &#123; public static void main(String[] args) &#123; // Set&lt;String&gt; set = new HashSet&lt;&gt;(); // Set&lt;String&gt; set = Collections.synchronizedSet(new HashSet&lt;&gt;()); Set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;(); for (int i = 0; i &lt; 30; i++) &#123; new Thread(() -&gt; &#123; set.add(UUID.randomUUID().toString().substring(0, 5)); System.out.println(set); &#125;, String.valueOf(i)).start(); &#125; &#125;&#125; HashSet 底层是什么？1234567891011public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;// add set本质就是map key是无法重复的public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;// PRESENTprivate static final Object PRESENT = new Object(); Map 不安全回顾Map基本操作 12345678910111213141516171819202122232425import java.util.UUID;import java.util.concurrent.ConcurrentHashMap;/** * @program: juc * @description: java.util.ConcurrentModificationException * @author: Marlowe * @create: 2020-12-03 22:11 **/public class MapTest &#123; public static void main(String[] args) &#123; // map是这样用的吗？不是，工作中不用HashMap // HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); Map&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;(); for (int i = 0; i &lt; 30; i++) &#123; new Thread(() -&gt; &#123; map.put(Thread.currentThread().getName(), UUID.randomUUID().toString().substring(0, 5)); System.out.println(map); &#125;, String.valueOf(i)).start(); &#125; &#125;&#125;","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"list","slug":"list","permalink":"https://xmmarlowe.github.io/tags/list/"},{"name":"线程不安全","slug":"线程不安全","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%AE%89%E5%85%A8/"}],"author":"Marlowe"},{"title":"8锁问题","slug":"并发/8锁问题","date":"2020-12-03T12:08:54.000Z","updated":"2021-04-19T12:10:56.200Z","comments":true,"path":"2020/12/03/并发/8锁问题/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/03/%E5%B9%B6%E5%8F%91/8%E9%94%81%E9%97%AE%E9%A2%98/","excerpt":"待完善…","text":"待完善… 小结 new this 具体的一个手机static Class 唯一的一个模板","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://xmmarlowe.github.io/tags/%E9%94%81/"},{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"synchronized和Lock区别","slug":"并发/synchronized和Lock区别","date":"2020-12-02T14:19:29.000Z","updated":"2021-04-26T14:28:37.552Z","comments":true,"path":"2020/12/02/并发/synchronized和Lock区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/12/02/%E5%B9%B6%E5%8F%91/synchronized%E5%92%8CLock%E5%8C%BA%E5%88%AB/","excerpt":"简述 synchronized 和 Lock 区别…","text":"简述 synchronized 和 Lock 区别… synchronized 内置的Java关键字；Lock 是一个Java类 synchronized 无法判断获取锁的状态；Lock 可以判断是否获取了锁 synchronized 会自动释放锁；Lock 必须要手动释放锁！ 如果不释放，死锁 synchronized 线程1（获得锁，阻塞）、线程2（等待、傻傻的等）；Lock 锁就不一定会等待下去 synchronized 可重入锁，不可以中断的，非公平的；Lock ，可重入锁，可以判断锁，非公平（可以自己设置） synchronized 适合锁少量的代码同步问题；Lock 适合锁大量的！ Synchronized关键字，用来加锁。Volatile只是保持变 量的线程可见性。通常适用于一个线程写，多个线程读的场景。 Volatile能不能保证线程安全？不能。Volatile关键字只能保证线程可见性，不能保证原子性。详情见站内volatile关键字一文。","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://xmmarlowe.github.io/tags/%E9%94%81/"},{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"author":"Marlowe"},{"title":"设计模式-策略","slug":"设计模式/设计模式-策略","date":"2020-11-29T12:38:08.000Z","updated":"2020-11-30T04:04:57.448Z","comments":true,"path":"2020/11/29/设计模式/设计模式-策略/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/29/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5/","excerpt":"在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。","text":"在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 介绍在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 使用场景 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 优缺点及注意优点 算法可以自由切换。 避免使用多重条件判断。 扩展性良好。 缺点 策略类会增多。 所有策略类都需要对外暴露。 注意如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 实现策略角色 123456public interface Strategy &#123; /** * 算法方法 */ public void algorithmInterface();&#125; 以下三个实现类为具体的策略角色 123456public class ConcreteStrategyA implements Strategy&#123; @Override public void algorithmInterface() &#123; System.out.println(&quot;具体的策略A&quot;); &#125;&#125; 123456public class ConcreteStrategyB implements Strategy &#123; @Override public void algorithmInterface() &#123; System.out.println(&quot;具体的策略B&quot;); &#125;&#125; 1234567public class ConcreteStrategyC implements Strategy &#123; @Override public void algorithmInterface() &#123; System.out.println(&quot;具体的策略C&quot;); &#125;&#125; Context上下文 1234567891011121314public class Context &#123; private Strategy strategy; public Context(Strategy strategy) &#123; this.strategy = strategy; &#125; /** * 上下文接口,执行对应策略 */ public void executeStrategy() &#123; strategy.algorithmInterface(); &#125;&#125; 客户端 123456789101112131415public class Client &#123; public static void main(String[] args) &#123; Context context; context = new Context(new ConcreteStrategyA()); context.executeStrategy(); context = new Context(new ConcreteStrategyB()); context.executeStrategy(); context = new Context(new ConcreteStrategyC()); context.executeStrategy(); &#125;&#125; 结果： 123具体的策略A具体的策略B具体的策略C","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"行为型模式","slug":"行为型模式","permalink":"https://xmmarlowe.github.io/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"策略","slug":"策略","permalink":"https://xmmarlowe.github.io/tags/%E7%AD%96%E7%95%A5/"}],"author":"Marlowe"},{"title":"JsonUtils","slug":"自定义工具类/JsonUtils","date":"2020-11-27T13:34:41.000Z","updated":"2020-12-11T02:07:56.029Z","comments":true,"path":"2020/11/27/自定义工具类/JsonUtils/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/27/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7%E7%B1%BB/JsonUtils/","excerpt":"","text":"123456789101112131415161718192021222324252627282930package com.kuang.utils;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializationFeature;import java.text.SimpleDateFormat;public class JsonUtils &#123; public static String getJson(Object object) &#123; return getJson(object,&quot;yyyy-MM-dd HH:mm:ss&quot;); &#125; public static String getJson(Object object,String dateFormat) &#123; ObjectMapper mapper = new ObjectMapper(); //不使用时间差的方式 mapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false); //自定义日期格式对象 SimpleDateFormat sdf = new SimpleDateFormat(dateFormat); //指定日期格式 mapper.setDateFormat(sdf); try &#123; return mapper.writeValueAsString(object); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125;","categories":[{"name":"自定义工具类","slug":"自定义工具类","permalink":"https://xmmarlowe.github.io/categories/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7%E7%B1%BB/"}],"tags":[{"name":"Json","slug":"Json","permalink":"https://xmmarlowe.github.io/tags/Json/"},{"name":"Utils","slug":"Utils","permalink":"https://xmmarlowe.github.io/tags/Utils/"}],"author":"Marlowe"},{"title":"设计模式-代理","slug":"设计模式/设计模式-代理","date":"2020-11-27T08:36:13.000Z","updated":"2021-03-17T07:13:40.626Z","comments":true,"path":"2020/11/27/设计模式/设计模式-代理/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/27/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86/","excerpt":"在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。","text":"在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 介绍在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 主要解决的问题在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 优缺点及注意优点 职责清晰。 高扩展性。 智能化。缺点 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 注意 和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。 实现静态代理角色分析: 抽象角色：一般会使用接口或者抽象类来解决 真实角色：被代理的角色 代理角色：代理真实角色，代理真实角色后，我们一般会做一些附属操作 客户：访问代理对象的人！ 接口1234567public interface Rent &#123; /** * 出租房屋 */ public void rent();&#125; 真实角色123456public class Landlord implements Rent &#123; @Override public void rent() &#123; System.out.println(&quot;房东要出租房子！&quot;); &#125;&#125; 代理角色12345678910111213141516171819202122232425262728293031public class Proxy implements Rent &#123; private Landlord landlord; public Proxy() &#123; &#125; public Proxy(Landlord landlord) &#123; this.landlord = landlord; &#125; @Override public void rent() &#123; seeHouse(); landlord.rent(); signContract(); fee(); &#125; public void seeHouse() &#123; System.out.println(&quot;中介带你看房&quot;); &#125; public void signContract() &#123; System.out.println(&quot;签合同&quot;); &#125; public void fee() &#123; System.out.println(&quot;收中介费&quot;); &#125;&#125; 客户端访问代理角色1234567891011public class Client &#123; public static void main(String[] args) &#123; // 房东要租房子 Landlord landlord = new Landlord(); // 代理,中介帮房东租房子，但是 代理一般会有一些附属操作 Proxy proxy = new Proxy(landlord); // 你不用面对房东，直接找中介即可 proxy.rent(); &#125;&#125; 12345结果：中介带你看房房东要出租房子！签合同收中介费 Spring AOP 代理模式的好处： 可以是真实角色的操作更加纯粹！不用去关注一些公共的业务 公共也就交给代理角色！实现了业务的分工！ 公共业务发生扩展的时候，方便集中管理！ 缺点： 一个真实的角色就会产生一个代理角色；代码量会翻倍，开发效率会变低~ 动态代理 动态代理和静态代理角色一样 动态代理的代理类是动态生成的，不是我们直接写好的！ 动态代理分为两大类：基于接口的动态代理，基于类的动态代理 基于接口 — JDK动态代理 基于类：cglib java字节码实现：javasist 需要两节两个类：Proxy，InvocationHandler：调用处理程序 动态代理的好处： 可以使真实角色的操作更加纯粹！不用去关注一些公共的业务 公共也就交给代理角色！实现了业务的分工！ 公共业务发生扩展的时候，方便集中管理！ 一个动态代理类代理的是一个接口，一般就是对应的一类业务 一个动态代理类可以代理多个类，只要实现了同一接口即可。 接口123456789public interface UserService &#123; public void add(); public void delete(); public void update(); public void query();&#125; 实现类12345678910111213141516171819202122public class UserServiceImpl implements UserService&#123; @Override public void add() &#123; System.out.println(&quot;增加了一个用户&quot;); &#125; @Override public void delete() &#123; System.out.println(&quot;删除了一个用户&quot;); &#125; @Override public void update() &#123; System.out.println(&quot;修改了一个用户&quot;); &#125; @Override public void query() &#123; System.out.println(&quot;查询了一个用户&quot;); &#125;&#125; 动态代理工具类（通用方法）12345678910111213141516171819202122232425262728293031323334353637383940public class ProxyInvocationHandlerUtil implements InvocationHandler &#123; /** * 被代理的接口 */ private Object target; public void setTarget(Object target) &#123; this.target = target; &#125; /** * 生成得到代理类 * * @return */ public Object getProxy() &#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; /** * 处理代理实例，并返回结果 * * @param proxy * @param method * @param args * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; log(method.getName()); Object result = method.invoke(target, args); return result; &#125; public void log(String msg) &#123; System.out.println(&quot;[Debug] 使用了&quot; + msg + &quot;方法&quot;); &#125;&#125; 客户端访问代理角色12345678910111213public class Client2 &#123; public static void main(String[] args) &#123; // 真实角色 UserServiceImpl userService = new UserServiceImpl(); // 代理角色，不存在 ProxyInvocationHandlerUtil pihu = new ProxyInvocationHandlerUtil(); // 设置需要代理的对象 pihu.setTarget(userService); // 动态生成代理类 UserService proxy = (UserService) pihu.getProxy(); proxy.add(); &#125;&#125; 123结果：[Debug] 使用了add方法增加了一个用户","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"代理","slug":"代理","permalink":"https://xmmarlowe.github.io/tags/%E4%BB%A3%E7%90%86/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://xmmarlowe.github.io/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}],"author":"Marlowe"},{"title":"设计模式-单例","slug":"设计模式/设计模式-单例","date":"2020-11-22T23:17:03.000Z","updated":"2021-04-28T12:25:07.712Z","comments":true,"path":"2020/11/23/设计模式/设计模式-单例/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/23/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B/","excerpt":"单例模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。","text":"单例模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 介绍单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。 这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 注意： 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 使用场景： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。优缺点及注意 优点 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。 避免对资源的多重占用（比如写文件操作）。缺点没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。注意getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 实现饿汉式12345678910111213141516171819202122232425262728package com.marlowe.singleton;/** * @program: GoF23 * @description: 饿汉式 * @author: Marlowe * @create: 2020-11-23 15:07 **/public class Hungry &#123; /** * 可能会浪费空间 */ private byte[] data1 = new byte[1024 * 1024]; private byte[] data2 = new byte[1024 * 1024]; private byte[] data3 = new byte[1024 * 1024]; private Hungry() &#123; &#125; private final static Hungry HUNGRY = new Hungry(); public static Hungry getInstance() &#123; return HUNGRY; &#125;&#125; DCL(Double CheckLock 双重校验锁(线程安全、效率高))懒汉式，深究！注意： 如果不使用volatile关键词修饰，可能会导致拿到的对象是未被初始化的。具体原因见代码注释部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.marlowe.singleton;import java.lang.reflect.Constructor;import java.lang.reflect.Field;/** * @program: GoF23 * @description: 懒汉式 * @author: Marlowe * @create: 2020-11-23 15:11 **/public class LazyMan &#123; private static boolean marlowe = false; private LazyMan() &#123; synchronized (LazyMan.class) &#123; if (marlowe == false) &#123; marlowe = true; &#125; else &#123; throw new RuntimeException(&quot;不要试图使用反射破坏异常&quot;); &#125; &#125; System.out.println(Thread.currentThread().getName() + &quot;ok&quot;); &#125; private volatile static LazyMan lazyMan; /** * 双重检测所模式的 懒汉式单例 DCL懒汉式 * * @return */ public static LazyMan getInstance() &#123; if (lazyMan == null) &#123; synchronized (LazyMan.class) &#123; if (lazyMan == null) &#123; // 创建对象不是原子性操作，可能导致对象未初始化 lazyMan = new LazyMan(); /** * 分三步完成 * * 1. 分配内存空间 * 2. 执行构造方法，初始化对象 * 3. 把这个对象指向分配的内存空间 * * 预期执行顺序 1-&gt;2-&gt;3 * 由于JVM具有指令重排的特性 实际顺序可能是1-&gt;3-&gt;2 * 指令重排在单线程的环境下不会出现问题，但是在多线程环境下可能会导致一个线程获得还没有初始化的实例 * 例如：A线程执行了1,3，此时B线程调用getInstance() 后发现 lazyMan 不为空，因此直接返回 lazyMan * 但此时 lazyMan 还未被初始化。使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行 * */ &#125; &#125; &#125; return lazyMan; &#125; /** * 反射 * * @param args */ public static void main(String[] args) throws Exception &#123; Field marlowe = LazyMan.class.getDeclaredField(&quot;marlowe&quot;); marlowe.setAccessible(true); Constructor&lt;LazyMan&gt; declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance = declaredConstructor.newInstance(); LazyMan instance2 = declaredConstructor.newInstance(); marlowe.set(instance, false); System.out.println(instance); System.out.println(instance2); &#125;&#125; DCL单例为什么要加volatile我们把上面写的DDL单例拿过来，加入不加volatile，如下： 1234567891011121314public class SingleInstance &#123; private SingleInstance() &#123;&#125; private static SingleInstance INSTANCE; public static SingleInstance getInstance() &#123; if (INSTANCE == null) &#123; synchronized (SingleInstance.class) &#123; if (INSTANCE == null) &#123; INSTANCE = new SingleInstance(); &#125; &#125; &#125; return INSTANCE; &#125;&#125; 当 INSTANCE = new SingleInstance() 创建实例对象时，并不是原子操作，它是分三步来完成的： 创建内存空间。 执行构造函数，初始化（init） 将INSTANCE引用指向分配的内存空间 上述正常步骤按照1–&gt;2–&gt;3来执行的，但是，我们知道，JVM为了优化指令，提高程序运行效率，允许指令重排序。正是有了指令重排序的存在，那么就有可能按照1–&gt;3–&gt;2步骤来执行，这时候，当线程a执行步骤3完毕，在执行步骤2之前，被切换到线程b上，这时候instance判断为非空，此时线程b直接来到return instance语句，拿走instance然后使用，接着就顺理成章地报错（对象尚未初始化）。 synchronized虽然保证了线程的原子性（即synchronized块中的语句要么全部执行，要么一条也不执行），但单条语句编译后形成的指令并不是一个原子操作（即可能该条语句的部分指令未得到执行，就被切换到另一个线程了）。 volatile关键字其中一个作用就是禁止指令重排序，所以DCL单例必须要加volatile volatile作用： 保证被修饰的变量对所有线程的可见性。 禁止指令重排序优化。 静态内部类12345678910111213141516171819202122package com.marlowe.singleton;/** * @program: GoF23 * @description: 静态内部类 * @author: Marlowe * @create: 2020-11-23 15:32 **/public class Holder &#123; private Holder() &#123; &#125; public static Holder getInstance() &#123; return InnerClass.HOLDER; &#125; public static class InnerClass &#123; private static final Holder HOLDER = new Holder(); &#125;&#125; 单例不安全，因为有反射12345678910111213141516171819202122232425262728293031package com.marlowe.singleton;import java.lang.reflect.Constructor;import java.lang.reflect.InvocationTargetException;/** * @program: GoF23 * @description: enum 是什么？ 本身也是一个class类 * @author: Marlowe * @create: 2020-11-23 15:49 **/public enum EnumSingleton &#123; INSTANCE; public EnumSingleton getInstance() &#123; return INSTANCE; &#125;&#125;class Test &#123; public static void main(String[] args) throws IllegalAccessException, InvocationTargetException, InstantiationException, NoSuchMethodException &#123; EnumSingleton instance1 = EnumSingleton.INSTANCE; Constructor&lt;EnumSingleton&gt; declaredConstructor = EnumSingleton.class.getDeclaredConstructor(String.class, int.class); declaredConstructor.setAccessible(true); EnumSingleton instance2 = declaredConstructor.newInstance(); System.out.println(instance1); System.out.println(instance2); &#125;&#125; 枚举类型的最终反编译原码里面是有参构造方法 经验之谈 单例对象 占用资源少，不需要延时加载，枚举 好于 饿汉 单例对象 占用资源多，需要延时加载，静态内部类 好于 懒汉式 参考文献blog.unclezs.com","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"单例","slug":"单例","permalink":"https://xmmarlowe.github.io/tags/%E5%8D%95%E4%BE%8B/"},{"name":"创建型模式","slug":"创建型模式","permalink":"https://xmmarlowe.github.io/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}],"author":"Marlowe"},{"title":"设计模式-工厂","slug":"设计模式/设计模式-工厂","date":"2020-11-20T08:49:24.000Z","updated":"2020-12-05T04:44:01.060Z","comments":true,"path":"2020/11/20/设计模式/设计模式-工厂/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/20/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82/","excerpt":"工厂设计模式很常用，分为简单工厂，工厂方法和抽象工厂。","text":"工厂设计模式很常用，分为简单工厂，工厂方法和抽象工厂。 核心本质 实例化对象不使用new，用工厂方法代替 将选择实现类，创建对象统一管理和控制。从而将调用者跟我们实现类解耦 OOP七大原则 开闭原则：一个软件的实体应当对扩展开放，对修改关闭 依赖倒转原则：要针对接口编程，不要针对实现编程 迪米特法则：只与你直接的朋友通信，而避免与陌生人通信 应用场景 JDK中Calendar的getInstance方法 JDBC中的Connection对象的获取 Spring中IOC容器创建管理bean对象 反射中Class对象的newInstance方法 三种模式简单工厂(Simple Factory)用来生产同一等级结构中的任意产品（对于增加新的产品，需要扩展已有代码） 如下图需要扩展一类新车–Ford，需要扩展车工厂里面的代码 Car接口 123456789101112package com.marlowe.factory.simple;/** * @program: GoF23 * @description: 车接口 * @author: Marlowe * @create: 2020-11-20 17:00 **/public interface Car &#123; public void name();&#125; 以下两个实体类实现Car接口 123456789101112131415package com.marlowe.factory.simple;/** * @program: GoF23 * @description: 宝马 * @author: Marlowe * @create: 2020-11-20 17:01 **/public class Bmw implements Car &#123; @Override public void name() &#123; System.out.println(&quot;我是宝马！&quot;); &#125;&#125; 123456789101112131415package com.marlowe.factory.simple;/** * @program: GoF23 * @description: 特斯拉 * @author: Marlowe * @create: 2020-11-20 17:01 **/public class Tesla implements Car&#123; @Override public void name() &#123; System.out.println(&quot;我是特斯拉！&quot;); &#125;&#125; CarFactory工厂类 1234567891011121314151617181920212223242526272829303132333435363738394041package com.marlowe.factory.simple;/** * @program: GoF23 * @description: 汽车工厂 * 静态工厂模式 * 开闭原则 * @author: Marlowe * @create: 2020-11-20 17:02 **/public class CarFactory &#123; /** * 方法一 * * @param car * @return */ public static Car getCar(String car) &#123; if (&quot;宝马&quot;.equals(car)) &#123; return new Bmw(); &#125; else if (&quot;特斯拉&quot;.equals(car)) &#123; return new Tesla(); &#125; else &#123; return null; &#125; &#125; /** * 方法二 * * @return */ public static Car getBmw() &#123; return new Bmw(); &#125; public static Car getTesla() &#123; return new Tesla(); &#125;&#125; 主类 1234567891011121314151617181920212223package com.marlowe.factory.simple;/** * @program: GoF23 * @description: 顾客 * @author: Marlowe * @create: 2020-11-20 17:03 **/public class Comsumer &#123; public static void main(String[] args) &#123; System.out.println(&quot;通过方式1获取:&quot;); Car car1 = CarFactory.getCar(&quot;宝马&quot;); Car car2 = CarFactory.getCar(&quot;特斯拉&quot;); car1.name(); car2.name(); System.out.println(&quot;通过方式2获取:&quot;); Car bmw = CarFactory.getBmw(); Car tesla = CarFactory.getTesla(); bmw.name(); tesla.name(); &#125;&#125; 1234567结果：通过方式1获取:我是宝马！我是特斯拉！通过方式2获取:我是宝马！我是特斯拉！ 工厂方法(Factory Method)用来生产同一等级结构中的固定产品（支持增加任意产品） 如下图需要扩展一类新车–Ford，横向扩展即可 Car接口 123456789101112package com.marlowe.factory.method;/** * @program: GoF23 * @description: 车接口 * @author: Marlowe * @create: 2020-11-20 17:00 **/public interface Car &#123; public void name();&#125; 以下两个实体类实现Car接口 123456789101112131415package com.marlowe.factory.method;/** * @program: GoF23 * @description: 宝马 * @author: Marlowe * @create: 2020-11-20 17:01 **/public class Bmw implements Car &#123; @Override public void name() &#123; System.out.println(&quot;我是宝马！&quot;); &#125;&#125; 123456789101112131415package com.marlowe.factory.method;/** * @program: GoF23 * @description: 特斯拉 * @author: Marlowe * @create: 2020-11-20 17:01 **/public class Tesla implements Car &#123; @Override public void name() &#123; System.out.println(&quot;我是特斯拉！&quot;); &#125;&#125; CarFactory接口 123456789101112package com.marlowe.factory.method;/** * @program: GoF23 * @description: 工厂方法模式 * @author: Marlowe * @create: 2020-11-20 18:54 **/public interface CarFactory &#123; Car getCar();&#125; 以下两个类实现CarFactory接口 123456789101112131415package com.marlowe.factory.method;/** * @program: GoF23 * @description: * @author: Marlowe * @create: 2020-11-20 18:55 **/public class BmwFactory implements CarFactory &#123; @Override public Car getCar() &#123; return new Bmw(); &#125;&#125; 123456789101112131415package com.marlowe.factory.method;/** * @program: GoF23 * @description: * @author: Marlowe * @create: 2020-11-20 18:55 **/public class TeslaFactory implements CarFactory &#123; @Override public Car getCar() &#123; return new Tesla(); &#125;&#125; 主类 123456789101112131415161718192021package com.marlowe.factory.method;import com.marlowe.factory.simple.CarFactory;/** * @program: GoF23 * @description: 顾客 * @author: Marlowe * @create: 2020-11-20 17:03 **/public class Comsumer &#123; public static void main(String[] args) &#123; Car car1 = new TeslaFactory().getCar(); Car car2 = new BmwFactory().getCar(); Car car3 = new FordFactory().getCar(); car1.name(); car2.name(); car3.name(); &#125;&#125; 1234结果：我是特斯拉！我是宝马！我是福特！ 抽象工厂(Abstract Factory)围绕一个超级工厂创建其他工厂，该工厂又称为其他工厂的工厂 抽象工厂模式提供了一个创建一系列相关或者相互依赖对象的接口，无需指定它们具体的类 抽象产品工厂 123456789101112131415161718192021222324package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 抽象产品工厂 * @author: Marlowe * @create: 2020-11-21 10:54 **/public interface IProductFactory &#123; /** * 生产手机 * * @return */ IPhoneProduct iPhoneProduct(); /** * 生产路由器 * * @return */ IRouterProduct iRouterProduct();&#125; 小米工厂 1234567891011121314151617181920package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 小米工厂 * @author: Marlowe * @create: 2020-11-21 10:57 **/public class XiaomiFactory implements IProductFactory &#123; @Override public IPhoneProduct iPhoneProduct() &#123; return new XiaomiPhone(); &#125; @Override public IRouterProduct iRouterProduct() &#123; return new XiaomiRouter(); &#125;&#125; 华为工厂 1234567891011121314151617181920package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 华为工厂 * @author: Marlowe * @create: 2020-11-21 10:57 **/public class HuaweiFactory implements IProductFactory &#123; @Override public IPhoneProduct iPhoneProduct() &#123; return new HuaweiPhone(); &#125; @Override public IRouterProduct iRouterProduct() &#123; return new HuaweiRouter(); &#125;&#125; 手机产品接口 123456789101112131415161718192021222324252627282930package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 手机产品接口 * @author: Marlowe * @create: 2020-11-20 22:38 **/public interface IPhoneProduct &#123; /** * 开机 */ void start(); /** * 关机 */ void shutdown(); /** * 打电话 */ void call(); /** * 发信息 */ void sendMessage();&#125; 以下小米手机和华为手机分别实现手机产品接口 1234567891011121314151617181920212223242526272829303132package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 小米手机 * @author: Marlowe * @create: 2020-11-20 22:41 **/public class XiaomiPhone implements IPhoneProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开小米手机&quot;); &#125; @Override public void shutdown() &#123; System.out.println(&quot;关闭小米手机&quot;); &#125; @Override public void call() &#123; System.out.println(&quot;小米手机打电话&quot;); &#125; @Override public void sendMessage() &#123; System.out.println(&quot;小米手机发信息&quot;); &#125;&#125; 123456789101112131415161718192021222324252627282930package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 华为手机 * @author: Marlowe * @create: 2020-11-20 22:44 **/public class HuaweiPhone implements IPhoneProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开华为手机&quot;); &#125; @Override public void shutdown() &#123; System.out.println(&quot;关闭华为手机&quot;); &#125; @Override public void call() &#123; System.out.println(&quot;华为手机打电话&quot;); &#125; @Override public void sendMessage() &#123; System.out.println(&quot;华为手机发信息&quot;); &#125;&#125; 路由器产品接口 123456789101112131415161718192021222324252627282930package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 路由器产品接口 * @author: Marlowe * @create: 2020-11-20 22:40 **/public interface IRouterProduct &#123; /** * 开机 */ void start(); /** * 关机 */ void shutdown(); /** * 打开wifi */ void openWifi(); /** * 设置 */ void setting();&#125; 以下小米路由器和华为路由器分别实现路由器产品接口 12345678910111213141516171819202122232425262728293031package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 小米路由器 * @author: Marlowe * @create: 2020-11-20 22:46 **/public class XiaomiRouter implements IRouterProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开小米路由器&quot;); &#125; @Override public void shutdown() &#123; System.out.println(&quot;关闭小米路由器&quot;); &#125; @Override public void openWifi() &#123; System.out.println(&quot;打开小米路由器wifi&quot;); &#125; @Override public void setting() &#123; System.out.println(&quot;设置小米路由器&quot;); &#125;&#125; 12345678910111213141516171819202122232425262728293031package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 华为路由器 * @author: Marlowe * @create: 2020-11-20 22:46 **/public class HuaweiRouter implements IRouterProduct &#123; @Override public void start() &#123; System.out.println(&quot;打开华为路由器&quot;); &#125; @Override public void shutdown() &#123; System.out.println(&quot;关闭华为路由器&quot;); &#125; @Override public void openWifi() &#123; System.out.println(&quot;打开华为路由器wifi&quot;); &#125; @Override public void setting() &#123; System.out.println(&quot;设置华为路由器&quot;); &#125;&#125; 主类 12345678910111213141516171819202122232425262728293031package com.marlowe.factory.abstract1;/** * @program: GoF23 * @description: 客户端 * @author: Marlowe * @create: 2020-11-21 11:01 **/public class Client &#123; public static void main(String[] args) &#123; System.out.println(&quot;===============小米系列产品=================&quot;); XiaomiFactory xiaomiFactory = new XiaomiFactory(); IPhoneProduct iPhoneProduct = xiaomiFactory.iPhoneProduct(); iPhoneProduct.call(); iPhoneProduct.sendMessage(); IRouterProduct iRouterProduct = xiaomiFactory.iRouterProduct(); iRouterProduct.openWifi(); System.out.println(); System.out.println(&quot;===============华为系列产品=================&quot;); HuaweiFactory huaweiFactory = new HuaweiFactory(); iPhoneProduct = huaweiFactory.iPhoneProduct(); iPhoneProduct.call(); iPhoneProduct.sendMessage(); IRouterProduct iRouterProduct1 = huaweiFactory.iRouterProduct(); iRouterProduct1.openWifi(); &#125;&#125; 12345678910结果：===============小米系列产品=================小米手机打电话小米手机发信息打开小米路由器wifi===============华为系列产品=================华为手机打电话华为手机发信息打开华为路由器wifi 适用场景： 客户端（应用层）不依赖与产品类实例如何被创建、实现等细节 强调一系列相关的产品对象（属于同一产品族）一起使用创建对象需要大量重复代码 提供一个产品类的库，所有的产品以同样的接口出现，从而使得客户端不依赖于具体的实现 优点 具体产品在应用层的代码隔离，无需关心创建的细节 将一个系列的产品统一到一起管理 缺点 规定了所有可能被创建的产品集合，产品族中扩展新的产品困难 增加了系统的抽象性和理解难度 小结 简单工厂模式（静态工厂模式）虽然某种程度上不符合设计原则，但实际使用最多！ 工厂方法模式不修改已有类的前提下，通过新增新的工厂类实现扩展。 抽象工厂模式不可以增加产品，可以增加产品族！","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"创建型模式","slug":"创建型模式","permalink":"https://xmmarlowe.github.io/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"工厂","slug":"工厂","permalink":"https://xmmarlowe.github.io/tags/%E5%B7%A5%E5%8E%82/"}],"author":"Marlowe"},{"title":"设计模式-模板","slug":"设计模式/设计模式-模板","date":"2020-11-20T07:06:57.000Z","updated":"2020-12-05T04:44:01.103Z","comments":true,"path":"2020/11/20/设计模式/设计模式-模板/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/20/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A8%A1%E6%9D%BF/","excerpt":"一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。","text":"一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 介绍在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 主要解决了一些方法通用，却在每一个子类都重新写了这一方法。 使用场景： 有多个子类共有的方法，且逻辑相同。 重要的、复杂的方法，可以考虑为模板方法。 优缺点及注意优点 封装不变部分，扩展可变部分。 提取公共代码，便于维护。 行为由父类控制，子类实现。 缺点每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 注意事项为防止恶意操作，一般模板方法都加上 final 关键词。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.marlowe;/** * @program: GoF23 * @description: 模板方法模式 * @author: Marlowe * @create: 2020-11-21 16:11 **/public class TemplateMethodPattern &#123; public static void main(String[] args) &#123; Cooking cooking = new CookingFood(); cooking.cook(); &#125;&#125;/** * 做饭抽象类 */abstract class Cooking &#123; protected abstract void step1(); protected abstract void step2(); /** * 模板方法 */ public final void cook() &#123; System.out.println(&quot;开始做饭:&quot;); step1(); step2(); System.out.println(&quot;做饭结束:&quot;); &#125;&#125;/** * 抽象类的具体实现 */class CookingFood extends Cooking &#123; @Override protected void step1() &#123; System.out.println(&quot;放鸡蛋和西红柿&quot;); &#125; @Override protected void step2() &#123; System.out.println(&quot;少放盐多放味精&quot;); &#125;&#125; 12345结果：开始做饭:放鸡蛋和西红柿少放盐多放味精做饭结束:","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"模板","slug":"模板","permalink":"https://xmmarlowe.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"行为型模式","slug":"行为型模式","permalink":"https://xmmarlowe.github.io/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}],"author":"Marlowe"},{"title":"对链表进行插入排序","slug":"题解/对链表进行插入排序","date":"2020-11-19T16:37:34.000Z","updated":"2020-12-05T04:44:01.019Z","comments":true,"path":"2020/11/20/题解/对链表进行插入排序/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/20/%E9%A2%98%E8%A7%A3/%E5%AF%B9%E9%93%BE%E8%A1%A8%E8%BF%9B%E8%A1%8C%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","excerpt":"","text":"147. 对链表进行插入排序对链表进行插入排序。 插入排序的动画演示如上。从第一个元素开始，该链表可以被认为已经部分排序（用黑色表示）。每次迭代时，从输入数据中移除一个元素（用红色表示），并原地将其插入到已排好序的链表中。 插入排序算法： 插入排序是迭代的，每次只移动一个元素，直到所有元素可以形成一个有序的输出列表。 每次迭代中，插入排序只从输入数据中移除一个待排序的元素，找到它在序列中适当的位置，并将其插入。 重复直到所有输入数据插入完为止。 示例 1： 12输入: 4-&gt;2-&gt;1-&gt;3输出: 1-&gt;2-&gt;3-&gt;4 示例 2： 12输入: -1-&gt;5-&gt;3-&gt;4-&gt;0输出: -1-&gt;0-&gt;3-&gt;4-&gt;5 分析由gif可以看出，链表在插入排序过程中由排序好的部分和当前节点以及后面的节点组成，因此可以去排序好部分的下一个元素作为当前待排序节点，当当前节点为null时，所有节点排序结束。 具体步骤如下：12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode insertionSortList(ListNode head) &#123; // 如果头节点为空，直接返回 if(head == null)&#123; return head; &#125; // 新建哑节点，保存头结点信息 ListNode dummy = new ListNode(0); dummy.next = head; // 排序好部分最后一个元素 ListNode lastSorted = head; // 当前节点（待排序元素） ListNode curr = head.next; while(curr != null)&#123; // 如果当前元素不用排序，将排序链表增长，也即lastSorted后移 if(lastSorted.val &lt;= curr.val)&#123; lastSorted = lastSorted.next; &#125;else&#123; // 从头结点开始找，pre保存前一个元素 ListNode pre = dummy; while(pre.next.val &lt;= curr.val)&#123; pre = pre.next; &#125; // 将curr节点插入到对应位置 lastSorted.next = curr.next; curr.next = pre.next; pre.next = curr; &#125; // 更新当前节点为排序好链表下一个节点 curr = lastSorted.next; &#125; return dummy.next; &#125;&#125;","categories":[{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"java","slug":"java","permalink":"https://xmmarlowe.github.io/tags/java/"},{"name":"链表","slug":"链表","permalink":"https://xmmarlowe.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"插入排序","slug":"插入排序","permalink":"https://xmmarlowe.github.io/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"}],"author":"Marlowe"},{"title":"设计模式-外观","slug":"设计模式/设计模式-外观","date":"2020-11-18T14:05:41.000Z","updated":"2020-12-05T04:44:01.066Z","comments":true,"path":"2020/11/18/设计模式/设计模式-外观/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/18/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82/","excerpt":"要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。外观模式提供一个高层次的接口，使得子系统更易使用。","text":"要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。外观模式提供一个高层次的接口，使得子系统更易使用。 介绍外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。 这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。传统模式 外观模式 优缺点及注意优点 为复杂的模块或子系统提供外界访问的模块。 子系统相对独立。 预防低水平人员带来的风险。 缺点 不符合开闭原则。所谓的开闭原则是软件工程里面一个最基本的原则：对扩展开放，对修改关闭。换句话说，你的系统可以提供新的功能模块而不必进行修改。 注意事项在层次化结构中，可以使用外观模式定义系统中每一层的入口。 实现12345678910111213141516171819202122232425262728293031323334353637383940414243package com.marlowe;/** * @program: GoF23 * @description: 外观模式 * @author: Marlowe * @create: 2020-11-21 17:04 **/public class FacadePattern &#123; public static void main(String[] args) &#123; Facade facade = new Facade(); System.out.println(facade.prove()); &#125;&#125;class SubFlow1 &#123; boolean isTrue() &#123; return true; &#125;&#125;class SubFlow2 &#123; boolean isOk() &#123; return true; &#125;&#125;class SubFlow3 &#123; boolean isGoodMan() &#123; return true; &#125;&#125;class Facade &#123; SubFlow1 subFlow1 = new SubFlow1(); SubFlow2 subFlow2 = new SubFlow2(); SubFlow3 subFlow3 = new SubFlow3(); boolean prove() &#123; return subFlow1.isTrue() &amp;&amp; subFlow2.isOk() &amp;&amp; subFlow3.isGoodMan(); &#125;&#125; 12结果：true","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://xmmarlowe.github.io/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"外观","slug":"外观","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%96%E8%A7%82/"}],"author":"Marlowe"},{"title":"DockerFile","slug":"Docker/DockerFile","date":"2020-11-16T17:06:17.000Z","updated":"2020-12-05T04:44:00.874Z","comments":true,"path":"2020/11/17/Docker/DockerFile/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/17/Docker/DockerFile/","excerpt":"","text":"dockerfile 是用来构建docker镜像的文件！","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://xmmarlowe.github.io/tags/Docker/"}],"author":"Marlowe"},{"title":"容器数据卷","slug":"Docker/容器数据卷","date":"2020-11-16T12:10:54.000Z","updated":"2020-12-05T04:44:00.882Z","comments":true,"path":"2020/11/16/Docker/容器数据卷/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/16/Docker/%E5%AE%B9%E5%99%A8%E6%95%B0%E6%8D%AE%E5%8D%B7/","excerpt":"","text":"什么是容器数据卷docker的理念回顾将应用和环境打包成一个镜像！数据？如果数据都在容器中，那么容器一删除，数据就会丢失！==需求：数据可以持久化==MySQL，容器删了，删库跑路！==需求：MySQL数据可以存储在本地！==容器之间可以有一个数据共享的技术！Docker容器中产生的数据，同步到本地！这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！总结一句话：容器的持久化和同步操作！容器建也是可以数据共享的！ 使用数据卷 方式一：直接使用命令来挂载 -v 123456docker run -it -v 主机目录：容器内目录# 测试[root@hecs-x-large-2-linux-20200425095544 home]# docker run -it -v /home/ceshi:/home centos /bin/bash# 启动起来的时候我们可以通过docker inspect 容器id 测试：1、停止容器2、宿主机上修改文件3、启动容器4、容器内的数据依旧是同步的！好处：我们以后修改只需要在本地修改即可，容器内会自动同步！ 实战：安装MySQL思考：MySQL的数据持久化问题！ 123456789101112131415161718# 获取镜像[root@hecs-x-large-2-linux-20200425095544 home]# docker pull mysql:5.7# 运行容器，需要做数据挂载！ # 安装启动mysql，需要配置密码的，这是注意点# 官当测试： docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag# 启动我们的-d 后台运行-p 端口映射-v 卷挂载-e 环境配置--name 容器名字[root@hecs-x-large-2-linux-20200425095544 home]# docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql01 mysql:5.7# 启动成功之后，我们在本地使用navcat来连接测试一下# navcat-连接到服务器的3310 ----3310和容器内的3306映射，这个时候我们就可以连接上了！# 在本地测试创建一个数据库，查看一下我们的映射路径是否ok！ 加入我们将容器删除发现，我们挂载到本地的数据卷依旧没有丢失，这就实现了容器数据持久化功能！ 具名和匿名挂载12345678910111213141516171819# 匿名挂载-v 容器内路径！docker run -d -P --name nginx01 -v /etc/nginx nginx# 查看所有的 volume 的情况[root@hecs-x-large-2-linux-20200425095544 ~]# docker volume lsDRIVER VOLUME NAMElocal 7be1d9b8c43e3b6bedc76ab75894eb8b8a8423e83ef2c4e9cf8b4a22ee4d9f2b# 这里发现，这种就是匿名挂载，我们在 -v 只写了容器内路径，没有写容器外路径！# 具名挂载[root@hecs-x-large-2-linux-20200425095544 ~]# docker run -d -P --name nginx03 -v juming-nginx:/etc/nginx nginx86efd65c8724a4485ae7bb75b75ec8ed62a225cb33d0c75ed1b6b3652500f5e9[root@hecs-x-large-2-linux-20200425095544 ~]# docker volume lslocal juming-nginx# 通过 -v 卷名：容器内路径# 查看一下这个卷 所有docker容器内的卷，没有指定目录的情况下都是在/var/lib/docker/volume/xxx/_data我们通过具名挂载可以方便的找到我们的一个卷，大多数情况在使用的具名挂载 1234如何确定是具名挂载还是匿名挂载，还是指定路径挂载！-v 容器内路径 # 匿名挂载-v 卷名：容器内路径 # 具名挂载-v /宿主机路径:容器内路径 # 指定路径挂载！ 拓展： 123456789# 通过 -v 容器内路径：ro rw 改变读写权限ro readonly # 只读rw readwrite # 可读可写# 一旦这个设置了容器权限。容器对我们挂载出来的内容就限定了！docker run -d -P --name nginx03 -v juming-nginx:/etc/nginx:/etc/nginx:ro nginxdocker run -d -P --name nginx03 -v juming-nginx:/etc/nginx:/etc/nginx:rw nginx# ro 只要看到ro就说明这个路径只能通过宿主机来操作，容器内部是无法操作！ 初识DockerfileDockerfile就是用来构建docker镜像的构建文件！ 命令脚本！先体验一下！通过这个脚本可以生成镜像，镜像是一层一层的，脚本一个个的命令，每个命令都是一层！ 1234567891011# 创建一个dockerfile文件，名字可以随机 建议Dockerfile# 文件中的内容 指令(大写) 参数FROM centosVOLUME [&quot;volume01&quot;,&quot;volume02&quot;]CMD echo &quot;---end---&quot;CMD /bin/bash# 这里的每个命令，就是镜像的一层！ 1# 启动自己写的容器 这个卷和外部一定有一个同步的目录！ 这种方式我们未来使用的十分多，因为我们通常会构建自己的镜像！假设构建镜像时候没有挂载卷，要手动镜像挂载 -v 卷名:容器内路径！ 数据卷容器多个mysql同步数据！ 123# 测试：可以删除docker01，查看一下docker02和docker03是否还可以访问这个文件# 测试依旧可以访问(拷贝的概念) 多个mysql实现数据共享 12345[root@hecs-x-large-2-linux-20200425095544 home]# docker run -d -p 3310:3306 -v /etc/mysql/conf.d -v /var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql01 mysql:5.7[root@hecs-x-large-2-linux-20200425095544 home]# docker run -d -p 3310:3306 -e MYSQL_ROOT_PASSWORD=root --name mysql02 --volumes-form mysql01 mysql:5.7# 这个时候，可以实现两个容器数据同步！ 结论：容器之间配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用为止。但是一旦持久到了本地，这个时候，本地的数据是不会删除的！","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://xmmarlowe.github.io/tags/Docker/"}],"author":"Marlowe"},{"title":"Docker镜像讲解","slug":"Docker/Docker镜像讲解","date":"2020-11-16T11:46:45.000Z","updated":"2020-12-05T04:44:00.878Z","comments":true,"path":"2020/11/16/Docker/Docker镜像讲解/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/16/Docker/Docker%E9%95%9C%E5%83%8F%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"如何提交一个自己的镜像 commit镜像1234docker commit 提交容器成为一个新的副本# 命令和git原理类似docker commit -m=&quot;提交的描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名：[TAG] 实战测试 1234567891011# 1、启动一个默认的tomcat[root@hecs-x-large-2-linux-20200425095544 ~]# docker run -it -p 8080:8080 tomcat# 2、发现这个默认的tomcat是没有webapps应用，镜像的原因，官方的镜像默认webapps下面是没有文件的！# 3、我自己拷贝进去了基本的文件root@186285ef065e:/usr/local/tomcat# cp -r webapps.dist/* webapps# 4、将我们操作过的容器通过commit提交为一个镜像！我们以后就使用我们修改过的镜像即可，这就是我们自己的一个修改的镜像[root@hecs-x-large-2-linux-20200425095544 ~]# docker commit -a=&quot;marlowe&quot; -m=&quot;add web app&quot; 186285ef065e tomcat02:1.0 1如果你想要保存当前容器的状态，就可以通过commit来提交，获得一个镜像，就好比以前学习VM的时候，快照！ 到这里才算是入门Docker！","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://xmmarlowe.github.io/tags/Docker/"}],"author":"Marlowe"},{"title":"Docker常用命令","slug":"Docker/Docker常用命令","date":"2020-11-11T08:16:31.000Z","updated":"2020-12-05T04:44:01.217Z","comments":true,"path":"2020/11/11/Docker/Docker常用命令/","link":"","permalink":"https://xmmarlowe.github.io/2020/11/11/Docker/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"帮助命令123docker version # 显示docker的版本信息docker info # 显示docker的系统信息，包括镜像和容器的数量docker 命令 --help # 帮助命令 帮助文档地址：https://docs.docker.com/reference/ 镜像命令docker images 查看所有本地的主机上的镜像 123456789[root@hecs-x-large-2-linux-20200425095544 home]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmysql 8.0 db2b37ec6181 2 weeks ago 545MBmysql latest db2b37ec6181 2 weeks ago 545MBhello-world latest bf756fb1ae65 10 months ago 13.3kB# 可选项 -a，--all # 列出所有的镜像 -q，--quiet # 只显示镜像的id docker search 搜索镜像 12345678910[root@hecs-x-large-2-linux-20200425095544 home]# docker search mysqlNAME DESCRIPTION STARS OFFICIAL mysql MySQL is a widely used, open-source relation… 10148 [OK] # 可选项，通过收藏来过滤--filter=STARS=3000 # 搜索出来的镜像就是STARS大于3000的[root@hecs-x-large-2-linux-20200425095544 home]# docker search mysql --filter=stars=3000NAME DESCRIPTION STARS OFFICIAL AUTOMATEDmysql MySQL is a widely used, open-source relation… 10148 [OK] mariadb MariaDB is a community-developed fork of MyS… 3737 [OK] docker pull 下载镜像 12345678910111213141516171819202122# 下载镜像 docker pull 镜像名[:tag][root@hecs-x-large-2-linux-20200425095544 ~]# docker pull mysql:8.08.0: Pulling from library/mysql # 如果不写tag，默认就是latestbb79b6b2107f: Pull complete 49e22f6fb9f7: Pull complete 842b1255668c: Pull complete 9f48d1f43000: Pull complete c693f0615bce: Pull complete 8a621b9dbed2: Pull complete 0807d32aef13: Pull complete a56aca0feb17: Pull complete de9d45fd0f07: Pull complete 1d68a49161cc: Pull complete d16d318b774e: Pull complete 49e112c55976: Pull complete Digest: sha256:8c17271df53ee3b843d6e16d46cff13f22c9c04d6982eb15a9a47bd5c9ac7e2d # 签名Status: Downloaded newer image for mysql:8.0docker.io/library/mysql:8.0 # 真实地址# 等价于它docker pull mysqldocker pull docker.io/library/mysql:8.0 docker rmi 删除镜像 123[root@hecs-x-large-2-linux-20200425095544 ~]# docker rmi -f 镜像id # 删除指定的镜像[root@hecs-x-large-2-linux-20200425095544 ~]# docker rmi -f 镜像id 镜像id # 删除多个镜像[root@hecs-x-large-2-linux-20200425095544 ~]# docker rmi -f $(docker images -aq) # 删除全部的镜像 容器命令说明：我们有了镜像才可以创建容器，linux，下载一个centos镜像来测试学习 1docker pull centos 新建容器并启动 123456789101112131415161718192021222324docker run[可选参数] image# 参数说明--name=&quot;Name&quot; 容器名字 tomcat01 tomcat02 用来区分容器-d 后台方式运行-it 使用交互方式运行，进入容器查看内容-p 指定容器的端口 -p 8080:8080 -p ip:主机端口：容器端口 -p 主机端口：容器端口（常用） -p 容器端口 容器端口-P 随机指定端口# 测试，启动并进入容器[root@hecs-x-large-2-linux-20200425095544 ~]# docker run -it centos /bin/bash[root@9b4676b718b5 /]# ls # 查看容器内的centos，基础版本，很多命令都是不完善的！bin etc lib lost+found mnt proc run srv tmp vardev home lib64 media opt root sbin sys usr# 从容器中退回主机[root@9b4676b718b5 /]# exitexit[root@hecs-x-large-2-linux-20200425095544 ~]# lsinstall.sh 列出所有运行的容器 123456789101112# docker ps 命令 # 列出当前正在运行的容器-a # 列出当前正在运行的容器 + 带出历史运行过的容器-n=? # 显示最近创建的容器-q # 只显示容器的编号[root@hecs-x-large-2-linux-20200425095544 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@hecs-x-large-2-linux-20200425095544 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9b4676b718b5 centos &quot;/bin/bash&quot; 26 minutes ago Exited (0) 16 minutes ago festive_feistelc8c1137aaa4e bf756fb1ae65 &quot;/hello&quot; 5 hours ago Exited (0) 5 hours ago confident_cannon 退出容器 12345exit # 容器停止并退出Ctrl + P + Q # 容器不停止退出[root@hecs-x-large-2-linux-20200425095544 ~]# docker run -it centos /bin/bash[root@9d6ac1f17089 /]# [root@hecs-x-large-2-linux-20200425095544 ~]# 删除容器 123docker rm 容器id # 删除指定的容器，不能删除正在运行的容器，如果要强制删除 rm -f docker rm -f $(docker ps -aq) # 删除所有的容器docker ps -a -q|xargs docker rm # 删除所有的容器，使用管道 启动和容器的操作 1234docker start 容器id # 启动容器docker restart 容器id # 重启容器docker stop 容器id # 停止当前正在运行的容器docker kill 容器id # 强制停止当前容器 常用其他命令 后台启动容器 1234567# 命令 docker run -d 镜像名：[root@hecs-x-large-2-linux-20200425095544 ~]# docker run -d centos# 问题docker ps，发现 centos停止了# 常见的坑！！ docker容器使用后台运行，就唏嘘有一个前台进程，docker发现没有应用，就自动停止# nginx，容器启动后，发现自己没有提供服务，就会立刻停止，就是没有程序了 查看日志 12345678910111213 docker logs -f -t --tail 容器id ,没有日志 # 自己编写一段shell脚本 [root@hecs-x-large-2-linux-20200425095544 ~]# docker run -d centos /bin/bash -c &quot;while true;do echo kuangshen; sleep 1;done&quot;[root@hecs-x-large-2-linux-20200425095544 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESaadc743a101c centos &quot;/bin/bash -c &#x27;while…&quot; 4 seconds ago Up 3 seconds tender_moser # 显示日志 -tf # 显示日志 -tail number # 要显示日志条数 [root@hecs-x-large-2-linux-20200425095544 ~]# docker logs -tf --tail 10 284eaba4616b 查看容器中进程信息 ps 12345# 命令 docker top 容器id [root@hecs-x-large-2-linux-20200425095544 ~]# docker top 284eaba4616bUID PID PPID C STIME TTY TIME CMDroot 15211 15194 0 18:31 ? 00:00:00 /bin/bash -c while true;do echo kuangshen; sleep 1;doneroot 15918 15211 0 18:37 ? 00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 1 查看镜像的元数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211# 命令docker inspect 容器id# 测试[root@hecs-x-large-2-linux-20200425095544 ~]# docker inspect 284eaba4616b[ &#123; &quot;Id&quot;: &quot;284eaba4616b4e748dc87a6aedf14d3b7bb508ef28d77cf215f01677a9149ae6&quot;, &quot;Created&quot;: &quot;2020-11-12T10:31:46.264703694Z&quot;, &quot;Path&quot;: &quot;/bin/bash&quot;, &quot;Args&quot;: [ &quot;-c&quot;, &quot;while true;do echo kuangshen; sleep 1;done&quot; ], &quot;State&quot;: &#123; &quot;Status&quot;: &quot;running&quot;, &quot;Running&quot;: true, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 15211, &quot;ExitCode&quot;: 0, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2020-11-12T10:31:46.559658378Z&quot;, &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot; &#125;, &quot;Image&quot;: &quot;sha256:0d120b6ccaa8c5e149176798b3501d4dd1885f961922497cd0abef155c869566&quot;, &quot;ResolvConfPath&quot;: &quot;/var/lib/docker/containers/284eaba4616b4e748dc87a6aedf14d3b7bb508ef28d77cf215f01677a9149ae6/resolv.conf&quot;, &quot;HostnamePath&quot;: &quot;/var/lib/docker/containers/284eaba4616b4e748dc87a6aedf14d3b7bb508ef28d77cf215f01677a9149ae6/hostname&quot;, &quot;HostsPath&quot;: &quot;/var/lib/docker/containers/284eaba4616b4e748dc87a6aedf14d3b7bb508ef28d77cf215f01677a9149ae6/hosts&quot;, &quot;LogPath&quot;: &quot;/var/lib/docker/containers/284eaba4616b4e748dc87a6aedf14d3b7bb508ef28d77cf215f01677a9149ae6/284eaba4616b4e748dc87a6aedf14d3b7bb508ef28d77cf215f01677a9149ae6-json.log&quot;, &quot;Name&quot;: &quot;/dazzling_roentgen&quot;, &quot;RestartCount&quot;: 0, &quot;Driver&quot;: &quot;overlay2&quot;, &quot;Platform&quot;: &quot;linux&quot;, &quot;MountLabel&quot;: &quot;&quot;, &quot;ProcessLabel&quot;: &quot;&quot;, &quot;AppArmorProfile&quot;: &quot;&quot;, &quot;ExecIDs&quot;: null, &quot;HostConfig&quot;: &#123; &quot;Binds&quot;: null, &quot;ContainerIDFile&quot;: &quot;&quot;, &quot;LogConfig&quot;: &#123; &quot;Type&quot;: &quot;json-file&quot;, &quot;Config&quot;: &#123;&#125; &#125;, &quot;NetworkMode&quot;: &quot;default&quot;, &quot;PortBindings&quot;: &#123;&#125;, &quot;RestartPolicy&quot;: &#123; &quot;Name&quot;: &quot;no&quot;, &quot;MaximumRetryCount&quot;: 0 &#125;, &quot;AutoRemove&quot;: false, &quot;VolumeDriver&quot;: &quot;&quot;, &quot;VolumesFrom&quot;: null, &quot;CapAdd&quot;: null, &quot;CapDrop&quot;: null, &quot;Capabilities&quot;: null, &quot;Dns&quot;: [], &quot;DnsOptions&quot;: [], &quot;DnsSearch&quot;: [], &quot;ExtraHosts&quot;: null, &quot;GroupAdd&quot;: null, &quot;IpcMode&quot;: &quot;private&quot;, &quot;Cgroup&quot;: &quot;&quot;, &quot;Links&quot;: null, &quot;OomScoreAdj&quot;: 0, &quot;PidMode&quot;: &quot;&quot;, &quot;Privileged&quot;: false, &quot;PublishAllPorts&quot;: false, &quot;ReadonlyRootfs&quot;: false, &quot;SecurityOpt&quot;: null, &quot;UTSMode&quot;: &quot;&quot;, &quot;UsernsMode&quot;: &quot;&quot;, &quot;ShmSize&quot;: 67108864, &quot;Runtime&quot;: &quot;runc&quot;, &quot;ConsoleSize&quot;: [ 0, 0 ], &quot;Isolation&quot;: &quot;&quot;, &quot;CpuShares&quot;: 0, &quot;Memory&quot;: 0, &quot;NanoCpus&quot;: 0, &quot;CgroupParent&quot;: &quot;&quot;, &quot;BlkioWeight&quot;: 0, &quot;BlkioWeightDevice&quot;: [], &quot;BlkioDeviceReadBps&quot;: null, &quot;BlkioDeviceWriteBps&quot;: null, &quot;BlkioDeviceReadIOps&quot;: null, &quot;BlkioDeviceWriteIOps&quot;: null, &quot;CpuPeriod&quot;: 0, &quot;CpuQuota&quot;: 0, &quot;CpuRealtimePeriod&quot;: 0, &quot;CpuRealtimeRuntime&quot;: 0, &quot;CpusetCpus&quot;: &quot;&quot;, &quot;CpusetMems&quot;: &quot;&quot;, &quot;Devices&quot;: [], &quot;DeviceCgroupRules&quot;: null, &quot;DeviceRequests&quot;: null, &quot;KernelMemory&quot;: 0, &quot;KernelMemoryTCP&quot;: 0, &quot;MemoryReservation&quot;: 0, &quot;MemorySwap&quot;: 0, &quot;MemorySwappiness&quot;: null, &quot;OomKillDisable&quot;: false, &quot;PidsLimit&quot;: null, &quot;Ulimits&quot;: null, &quot;CpuCount&quot;: 0, &quot;CpuPercent&quot;: 0, &quot;IOMaximumIOps&quot;: 0, &quot;IOMaximumBandwidth&quot;: 0, &quot;MaskedPaths&quot;: [ &quot;/proc/asound&quot;, &quot;/proc/acpi&quot;, &quot;/proc/kcore&quot;, &quot;/proc/keys&quot;, &quot;/proc/latency_stats&quot;, &quot;/proc/timer_list&quot;, &quot;/proc/timer_stats&quot;, &quot;/proc/sched_debug&quot;, &quot;/proc/scsi&quot;, &quot;/sys/firmware&quot; ], &quot;ReadonlyPaths&quot;: [ &quot;/proc/bus&quot;, &quot;/proc/fs&quot;, &quot;/proc/irq&quot;, &quot;/proc/sys&quot;, &quot;/proc/sysrq-trigger&quot; ] &#125;, &quot;GraphDriver&quot;: &#123; &quot;Data&quot;: &#123; &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/9f2dc5029ecc2e3355d547bc678a613bc9fcaf84e23692e9ae8d36b010c2392a-init/diff:/var/lib/docker/overlay2/ab2394ffb62a3a589a4794ed317cdec52ff1b73d6c0025a32b56cfa266fe4d97/diff&quot;, &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/9f2dc5029ecc2e3355d547bc678a613bc9fcaf84e23692e9ae8d36b010c2392a/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/9f2dc5029ecc2e3355d547bc678a613bc9fcaf84e23692e9ae8d36b010c2392a/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/9f2dc5029ecc2e3355d547bc678a613bc9fcaf84e23692e9ae8d36b010c2392a/work&quot; &#125;, &quot;Name&quot;: &quot;overlay2&quot; &#125;, &quot;Mounts&quot;: [], &quot;Config&quot;: &#123; &quot;Hostname&quot;: &quot;284eaba4616b&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/bash&quot;, &quot;-c&quot;, &quot;while true;do echo kuangshen; sleep 1;done&quot; ], &quot;Image&quot;: &quot;centos&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &quot;org.label-schema.build-date&quot;: &quot;20200809&quot;, &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;, &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;, &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;, &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot; &#125; &#125;, &quot;NetworkSettings&quot;: &#123; &quot;Bridge&quot;: &quot;&quot;, &quot;SandboxID&quot;: &quot;da70a9e57940a409d3f4827907ee892aa3a9a20aa2575fbeffd380cedfc6b03a&quot;, &quot;HairpinMode&quot;: false, &quot;LinkLocalIPv6Address&quot;: &quot;&quot;, &quot;LinkLocalIPv6PrefixLen&quot;: 0, &quot;Ports&quot;: &#123;&#125;, &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/da70a9e57940&quot;, &quot;SecondaryIPAddresses&quot;: null, &quot;SecondaryIPv6Addresses&quot;: null, &quot;EndpointID&quot;: &quot;9e9c2139cd06d068313f00e7e7ec3bf9411a3344792d962fffecd4324d1ff87a&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;Networks&quot;: &#123; &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;7a8c920abbd19ce06b9315879005e6d73adea85afc13f16ca1bd88c49bf5694b&quot;, &quot;EndpointID&quot;: &quot;9e9c2139cd06d068313f00e7e7ec3bf9411a3344792d962fffecd4324d1ff87a&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;DriverOpts&quot;: null &#125; &#125; &#125; &#125;] 进入当前正在运行的容器 12345678910111213141516171819202122# 我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置# 命令 docker exec -it 容器id bashShell# 测试[root@hecs-x-large-2-linux-20200425095544 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe60fd257e7cf mysql:8.0 &quot;docker-entrypoint.s…&quot; 6 hours ago Up 6 hours 33060/tcp, 0.0.0.0:3307-&gt;3306/tcp mysql[root@hecs-x-large-2-linux-20200425095544 ~]# docker exec -it e60fd257e7cf /bin/bashroot@e60fd257e7cf:/# lsbin docker-entrypoint-initdb.d home media proc sbin tmpboot entrypoint.sh lib mnt root srv usrdev etc lib64 opt run sys varroot@e60fd257e7cf:/# ps -ef# 方式2 docker attach 容器id# docker exec # 进入容器后开启一个新的终端，可以在里面操作（常用）# docker attach # 进入容器正在执行的终端，不会启动新的进程 从容器内拷贝文件到主机上 12345678910111213141516171819202122232425262728293031docker cp 容器id：容器内路径 目的的主机路径# 查看当前主机目录下[root@hecs-x-large-2-linux-20200425095544 home]# lschn hello.java hh leo Marlowe www[root@hecs-x-large-2-linux-20200425095544 home]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES37b64bd24047 centos &quot;/bin/bash&quot; About a minute ago Up About a minute funny_williamse60fd257e7cf mysql:8.0 &quot;docker-entrypoint.s…&quot; 7 hours ago Up 7 hours 33060/tcp, 0.0.0.0:3307-&gt;3306/tcp mysql# 进入docker容器内部[root@hecs-x-large-2-linux-20200425095544 home]# docker attach 37b64bd24047[root@37b64bd24047 /]# cd /home[root@37b64bd24047 home]# ls# 在容器内新建一个文件[root@37b64bd24047 home]# touch test.java[root@37b64bd24047 home]# lstest.java[root@37b64bd24047 home]# exitexit[root@hecs-x-large-2-linux-20200425095544 home]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe60fd257e7cf mysql:8.0 &quot;docker-entrypoint.s…&quot; 7 hours ago Up 7 hours 33060/tcp, 0.0.0.0:3307-&gt;3306/tcp mysql# 将这文件拷贝出来到主机上[root@hecs-x-large-2-linux-20200425095544 home]# docker cp 37b64bd24047:/home/test.java /home [root@hecs-x-large-2-linux-20200425095544 home]# lschn hello.java hh leo Marlowe test.java www# 拷贝是一个手动过程，未来我们使用 -v 卷的技术，可以实现，自动同步 /home /home Docker 安装nginx 123456789101112131415161718192021# 1.搜索镜像 search 建议大家去docker搜素，可以看帮助文档# 2.下载镜像 pull# 3.运行测试[root@hecs-x-large-2-linux-20200425095544 home]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest c39a868aad02 7 days ago 133MBmysql 8.0 db2b37ec6181 2 weeks ago 545MBmysql latest db2b37ec6181 2 weeks ago 545MBcentos latest 0d120b6ccaa8 3 months ago 215MB# -d后台运行# --name 给容器命名# -p 宿主机端口，容器内部端口[root@hecs-x-large-2-linux-20200425095544 home]# docker run -d --name nginx01 -p 3344:80 nginx100d4c411f6d16c5ff4e630f521f59448d065cb2b201bd0b3a1ea6840045e955[root@hecs-x-large-2-linux-20200425095544 home]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES100d4c411f6d nginx &quot;/docker-entrypoint.…&quot; 8 seconds ago Up 7 seconds 0.0.0.0:3344-&gt;80/tcp nginx01e60fd257e7cf mysql:8.0 &quot;docker-entrypoint.s…&quot; 7 hours ago Up 7 hours 33060/tcp, 0.0.0.0:3307-&gt;3306/tcp mysql[root@hecs-x-large-2-linux-20200425095544 home]# curl localhost:3344 作业练习 Docker 安装 Nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 1.搜索镜像 search 建议去docker搜索，可以看到帮助文档# 2.下载镜像 pull# 3.运行测试[root@hecs-x-large-2-linux-20200425095544 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest c39a868aad02 9 days ago 133MBmysql 8.0 db2b37ec6181 3 weeks ago 545MBmysql latest db2b37ec6181 3 weeks ago 545MBcentos latest 0d120b6ccaa8 3 months ago 215MB# -d 后台运行# --name 容器命名# -p 宿主机端口：容器内端口[root@hecs-x-large-2-linux-20200425095544 ~]# docker run -d --name nginx01 -p 3344:80 nginx[root@hecs-x-large-2-linux-20200425095544 ~]# curl localhost:3344&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;# 进入容器[root@hecs-x-large-2-linux-20200425095544 ~]# docker exec -it nginx01 /bin/bashroot@100d4c411f6d:/# whereis nginxnginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx 思考问题：我们每次改动nginx配置文件，都需要进入容器内部？十分麻烦，我要是可以在容器外部提供一个映射路径，达到在容器修改文件名，容器内部就可以自动修改？ -v 数据卷！ 作业2：docker装tomcat 123456789101112131415161718# 官方安装docker run -it --rm tomcat:9.0# 我们之前的启动都是后台，停止了容器之后，容器还是可以查到， docker run -it --rm 一般用来测试，用完就删除# 下载再启用docker pull tomcat# 启动运行docker run -d -p 3355:8080 --name tomcat01 tomcat# 测试访问没有问题# 进入容器[root@hecs-x-large-2-linux-20200425095544 ~]# docker exec -it tomcat01 /bin/bash# 发现问题：1.linux命令少了，2.没有webapps，阿里云镜像的原因，默认是最小的镜像，左右不必要的都删除掉。# 保证最小可运行的环境！ 思考问题：我们以后要部署项目，如果每次都要进入容器是不是十分麻烦？我要是可以在容器外提供一个映射路径，webapps，我们在外部放置项目，就自动同步到内部就好了！ 作业：部署es+kibana 123456789101112131415161718192021222324252627282930313233# es 暴露的端口很多# es 十分的耗内存# es的数据一般需要放置到安全目录！ 挂载# --net somenetwork ？ 网络配置# 下载启动docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:7.6.2# 启动后非常卡 linux卡住了，docker status 查看cpu状态# es十分耗内存；# 查看 docker stats# 测试es是否成功了[root@hecs-x-large-2-linux-20200425095544 ~]# curl localhost:9200&#123; &quot;name&quot; : &quot;6e4e7e14f10d&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;C4GbFU9pQ7m0WT6ko_pkJA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.6.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;, &quot;build_date&quot; : &quot;2020-03-26T06:34:37.794943Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.4.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 12# 增加内存限制，修改配置文件 -e 环境配置修改docker run -d --name elasticsearch02 -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms64m -Xmx512m&quot; elasticsearch:7.6.2 作业：使用kibana连接es？思考网络如何才能连接过去！ 可视化 portainer(先用这个)1docker run -d -p 8088:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer Rancher(CI/CD再用) 什么是portainer？Docker图形化界面管理工具！提供一个后台面板供我们操作！ 1docker run -d -p 8088:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://xmmarlowe.github.io/tags/Docker/"}],"author":"Marlowe"},{"title":"二叉树的前中后序非递归遍历算法","slug":"题解/二叉树的前中后序非递归遍历算法","date":"2020-10-12T14:01:09.000Z","updated":"2020-12-05T04:44:01.014Z","comments":true,"path":"2020/10/12/题解/二叉树的前中后序非递归遍历算法/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%A2%98%E8%A7%A3/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E4%B8%AD%E5%90%8E%E5%BA%8F%E9%9D%9E%E9%80%92%E5%BD%92%E9%81%8D%E5%8E%86%E7%AE%97%E6%B3%95/","excerpt":"","text":"二叉树的前中后序非递归遍历算法学过数据结构的同学都知道二叉树的深度优先遍历算法有三种，前序，中序，后序遍历。 前序：根–&gt;左–&gt;右 中序：左–&gt;根–&gt;右 后序：左–&gt;右–&gt;根 不难发现，后序遍历和前序遍历有相似的地方，如果我们将后序遍历变成根右左的顺序，将结果集翻转后就会变成前序的根左右顺序。 前中后序非递归遍历的核心算法：前序遍历：123456789101112while(root != null || !stack.isEmpty())&#123; // 一直往左边走 while(root != null)&#123; res.add(root.val); stack.push(root); root = root.left; &#125; // 开始回退 TreeNode cur = stack.pop(); // 往右边走 root = cur.right;&#125; 后序遍历：123456789101112131415while(root != null || !stack.isEmpty())&#123; // 一直往右边走 while(root != null)&#123; res.add(root.val); stack.push(root); root = root.right; &#125; // 开始回退 TreeNode cur = stack.pop(); // 往左边走 root = cur.left; // 反转，使变成后序遍历 Collections.reverse(res);&#125; 中序遍历：12345678910111213while(root != null || !stack.isEmpty())&#123; // 碰到根节点，压栈 while(root != null)&#123; stack.push(root); // 往左边走 root = root.left; &#125; // 开始回退 root = stack.pop(); res.add(root.val); // 往右边走 root = root.right;&#125; 前中后序递归遍历的核心算法：前序遍历：1234567public void dfs(TreeNode root)&#123; while(root != null)&#123; res.add(root.val); dfs(root.left); dfs(root.right); &#125;&#125; 中序遍历：1234567public void dfs(TreeNode root)&#123; while(root != null)&#123; dfs(root.left); res.add(root.val); dfs(root.right); &#125;&#125; 后序遍历：1234567public void dfs(TreeNode root)&#123; while(root != null)&#123; dfs(root.left); dfs(root.right); res.add(root.val); &#125;&#125;","categories":[{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}],"author":"Marlowe"},{"title":"Map集合的统计每个字符出现次数的两种方法","slug":"题解/Map集合的统计每个字符出现次数的两种方法","date":"2020-10-12T13:53:51.000Z","updated":"2020-12-05T04:44:00.949Z","comments":true,"path":"2020/10/12/题解/Map集合的统计每个字符出现次数的两种方法/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%A2%98%E8%A7%A3/Map%E9%9B%86%E5%90%88%E7%9A%84%E7%BB%9F%E8%AE%A1%E6%AF%8F%E4%B8%AA%E5%AD%97%E7%AC%A6%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/","excerpt":"","text":"Map集合的统计每个字符出现次数的两种方法一、map.containsKey()方法Map可以出现在k与v的映射中，v为null的情况。Map集合允许值对象为null，并且没有个数限制，所以当get()方法的返回值为null时，可能有两种情况，一种是在集合中没有该键对象，另一种是该键对象没有映射任何值对象，即值对象为null。因此，在Map集合中不应该利用get()方法来判断是否存在某个键，而应该利用containsKey()方法来判断。 1234567891011121314151617/** * map.containsKey()方法 * * @param nums */ public static void test1(int[] nums) &#123; HashMap&lt;Integer, Integer&gt; cnt = new HashMap&lt;&gt;(); for (int num : nums) &#123; if (!cnt.containsKey(num)) &#123; cnt.put(num, 1); &#125; else &#123; cnt.put(num, cnt.get(num) + 1); &#125; &#125; // 遍历HashMap pnt(cnt); &#125; 1234567原始数组：int[] nums &#x3D; new int[]&#123;1, 2, 2, 3, 5, 5, 5, 9, 1, 1&#125;;结果： 1出现的次数：3 2出现的次数：2 3出现的次数：1 5出现的次数：3 9出现的次数：1 二、map.getOrDefault()方法 当Map集合中有这个key时，就使用这个key值，如果没有就使用默认值defaultValue 。 12345678910111213/** * map.getOrDefault()方法 * * @param nums */ public static void test2(int[] nums) &#123; HashMap&lt;Integer, Integer&gt; cnt = new HashMap&lt;&gt;(); for (int num : nums) &#123; cnt.put(num, cnt.getOrDefault(num, 0) + 1); &#125; // 遍历HashMap pnt(cnt); &#125; 1234567原始数组：int[] nums = new int[]&#123;1, 2, 2, 3, 5, 5, 5, 9, 1, 1&#125;;结果： 1出现的次数：3 2出现的次数：2 3出现的次数：1 5出现的次数：3 9出现的次数：1 三、demo源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.util.HashMap;import java.util.Map;/** * @program: leecode1 * @description: * @author: Marlowe * @create: 2020-09-07 15:28 **/public class map集合统计每个字符出现的次数 &#123; public static void main(String[] args) &#123; int[] nums = new int[]&#123;1, 2, 2, 3, 5, 5, 5, 9, 1, 1&#125;; test1(nums); test2(nums); &#125; /** * map.containsKey()方法 * * @param nums */ public static void test1(int[] nums) &#123; HashMap&lt;Integer, Integer&gt; cnt = new HashMap&lt;&gt;(); for (int num : nums) &#123; if (!cnt.containsKey(num)) &#123; cnt.put(num, 1); &#125; else &#123; cnt.put(num, cnt.get(num) + 1); &#125; &#125; pnt(cnt); &#125; /** * map.getOrDefault()方法 * * @param nums */ public static void test2(int[] nums) &#123; HashMap&lt;Integer, Integer&gt; cnt = new HashMap&lt;&gt;(); for (int num : nums) &#123; cnt.put(num, cnt.getOrDefault(num, 0) + 1); &#125; pnt(cnt); &#125; /** * 遍历HashMap */ public static void pnt(HashMap&lt;Integer, Integer&gt; map) &#123; for (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123; int num = entry.getKey(); int count = entry.getValue(); System.out.println(num + &quot;出现的次数：&quot; + count); &#125; &#125;&#125;","categories":[{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"}],"author":"Marlowe"},{"title":"Leetcode组合总和1-4题题解","slug":"题解/Leetcode组合总和1-4题题解","date":"2020-10-12T13:52:22.000Z","updated":"2020-12-05T04:44:00.946Z","comments":true,"path":"2020/10/12/题解/Leetcode组合总和1-4题题解/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%A2%98%E8%A7%A3/Leetcode%E7%BB%84%E5%90%88%E6%80%BB%E5%92%8C1-4%E9%A2%98%E9%A2%98%E8%A7%A3/","excerpt":"","text":"Leetcode组合总和1-4题题解Leecode最近几天的每日一题都是组合总和问题，预测明天是组合总和Ⅳ，因此，提前将组合总和的所有题目刷了，前三题的思路都差不多，最后一题做法有所不同： 组合总和：candidates 中的数字可以无限制重复被选取。 组合总和Ⅱ： candidates 中的每个数字在每个组合中只能使用一次。 组合总和Ⅲ：组合中只允许有1-9的数字，并且每种组合中不存在重复的数字。 组合总和Ⅳ：找出符合要求组合的个数。 39. 组合总和给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 说明： 所有数字（包括 target）都是正整数。 解集不能包含重复的组合。 示例 1： 123456输入：candidates &#x3D; [2,3,6,7], target &#x3D; 7,所求解集为：[ [7], [2,2,3]] 示例 2： 1234567输入：candidates &#x3D; [2,3,5], target &#x3D; 8,所求解集为：[ [2,2,2,2], [2,3,3], [3,5]] 提示： 1 &lt;= candidates.length &lt;= 30 1 &lt;= candidates[i] &lt;= 200 candidate 中的每个元素都是独一无二的。 1 &lt;= target &lt;= 500 题解（dfs，回溯算法）分析：此类问题可以画出树形图，然后就会发现此题可以用dfs+回溯算法解决，用到的数据结构为双端队列，具有栈和队列的性质，其定义方式为：Deque stack = new ArrayDeque();具体步骤见代码。 具体步骤如下：1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; // 保存结果集 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 获取数组的长度 int len = candidates.length; //如果数组为空，直接返回空集合 if(len == 0)&#123; return res; &#125; // 双端队列，保存临时路径 Deque&lt;Integer&gt; path = new ArrayDeque(); // 深度优先遍历求所有结果集 dfs(candidates,0,len,target,path,res); return res; &#125; public void dfs(int[] candidates,int start,int len,int target,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; // 如果选多了，也即target &lt; 0,直接return if(target &lt; 0)&#123; return; &#125; // 找到一条路径 if(target == 0)&#123; // 将路径加入结果集 res.add(new ArrayList(path)); &#125; // 从下标为start的数开始寻找 for(int i = start; i &lt; len; i++)&#123; // 将当前元素入栈 path.addLast(candidates[i]); // 由于可以选择重复的元素，因此i不变，但是选择了东西，target对应减少 dfs(candidates,i,len,target - candidates[i],path,res); // 回到之前的状态 path.removeLast(); &#125; &#125;&#125; 40. 组合总和 II给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的每个数字在每个组合中只能使用一次。 说明： 所有数字（包括目标数）都是正整数。 解集不能包含重复的组合。 示例 1: 12345678输入: candidates &#x3D; [10,1,2,7,6,1,5], target &#x3D; 8,所求解集为:[ [1, 7], [1, 2, 5], [2, 6], [1, 1, 6]] 示例 2: 123456输入: candidates &#x3D; [2,5,2,1,2], target &#x3D; 5,所求解集为:[ [1,2,2], [5]] 题解（dfs，回溯算法，哈希表）分析：此题和组合总和的区别在于 candidates 中的每个数字在每个组合中只能使用一次，并且解集不能包含重复的元素，因此可用哈希表对重复解集去重，具体步骤看下方代码注释。 具体步骤如下：1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) &#123; // 将原始数组排序 Arrays.sort(candidates); // 获取数组长度 int len = candidates.length; // 结果集列表 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 双端队列 Deque&lt;Integer&gt; path = new ArrayDeque(); // 深度优先遍历 + 回溯 dfs(candidates,0,len,target,path,res); // 去重，因为解集不能有重复元素 HashSet&lt;List&lt;Integer&gt;&gt; set = new HashSet(); for(List&lt;Integer&gt; list : res)&#123; set.add(list); &#125; // 将HashSet转换为List集合 return new ArrayList(set); &#125; public void dfs(int[] candidates,int start,int len,int target,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; // 如果选多了，也即target &lt; 0,直接return if(target &lt; 0)&#123; return; &#125; // 找到一条路径 if(target == 0)&#123; // 将路径加入结果集 res.add(new ArrayList(path)); &#125; for(int i = start; i &lt; len; i++)&#123; // 将当前元素入栈 path.addLast(candidates[i]); // 由于数组中的元素只能用一次，因此i + 1,并且target减少 dfs(candidates,i+1,len,target - candidates[i],path,res); // 回到之前的状态 path.removeLast(); &#125; &#125;&#125; 216. 组合总和 III 找出所有相加之和为 n 的 k 个数的组合。组合中只允许含有 1 - 9 的正整数，并且每种组合中不存在重复的数字。 说明： 所有数字都是正整数。 解集不能包含重复的组合。 示例 1: 12输入: k &#x3D; 3, n &#x3D; 7输出: [[1,2,4]] 示例 2: 12输入: k &#x3D; 3, n &#x3D; 9输出: [[1,2,6], [1,3,5], [2,3,4]] 题解（dfs，回溯算法）分析：此题和组合总和Ⅱ的区别在于在1-9中选择数据,并且每个数据只能选一次，且只需返回长度为k的路径,因此需对结果集进行筛选，具体步骤看下方代码注释。 具体步骤如下：12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) &#123; // 手动将1-9加入数组arr中 int[] arr = new int[]&#123;1,2,3,4,5,6,7,8,9&#125;; // 初始结果集 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 最终结果集 List&lt;List&lt;Integer&gt;&gt; res1 = new ArrayList(); // 临时路径 Deque&lt;Integer&gt; path = new ArrayDeque(); // 深度优先遍历求出所有解集 dfs(arr,0,n,path,res); // 选出符合长度为k的解集 for(List&lt;Integer&gt; list : res)&#123; if(list.size() == k)&#123; res1.add(list); &#125; &#125; return res1; &#125; public void dfs(int[] arr,int start,int n ,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; // 如果选多了，也即n &lt; 0,直接return if(n &lt; 0)&#123; return; &#125; // 找到一条路径 if(n == 0)&#123; // 将路径加入结果集 res.add(new ArrayList(path)); &#125; for(int i = start; i &lt; 9; i++)&#123; // 将当前元素入栈 path.addLast(arr[i]); // 由于数组中的元素只能用一次，因此i + 1,并且n减少 dfs(arr,i + 1,n - arr[i],path,res); // 回到之前的状态 path.removeLast(); &#125; &#125;&#125; 377. 组合总和 Ⅳ给定一个由正整数组成且不存在重复数字的数组，找出和为给定目标正整数的组合的个数。 示例: 12345678910111213141516nums &#x3D; [1, 2, 3]target &#x3D; 4所有可能的组合为：(1, 1, 1, 1)(1, 1, 2)(1, 2, 1)(1, 3)(2, 1, 1)(2, 2)(3, 1)请注意，顺序不同的序列被视作不同的组合。因此输出为 7。 进阶：如果给定的数组中含有负数会怎么样？问题会产生什么变化？我们需要在题目中添加什么限制来允许负数的出现？ 题解（1.dfs,回溯算法 2.动态规划）分析：此题和组合总和类似，区别在于求出所有解集后，还需求出解集的全排列，并返回全排列的个数。 组合总数前三题都是同样的套路，只是在结果处理以及中间过程有略微差别，但是这题不同的是要求结果集的全排列，因此，我就想用第一题的算法 + 全排列算法求出此题，代码如demo1，结果超时，代码逻辑是没有问题的，但题目所给数据过大，导致算全排列的时候使用过多时间，因此未通过。 查看题解，发现正确的解法为动态规划，根据分析可以得到状态转移方程： dp[i] = dp[i - nums[0]] + dp[i - nums[1]] + dp[i - nums[2]]...... 例如nums = [1,3,4],target = 7; dp[7] = dp[6] + dp[4] + dp[3]; 具体代码见demo2 具体步骤如下：demo1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class Solution &#123; public int combinationSum4(int[] nums, int target) &#123; Arrays.sort(nums); int sum = 0; // 保存结果集 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 获取数组的长度 int len = nums.length; // 双端队列，保存临时路径 Deque&lt;Integer&gt; path = new ArrayDeque(); // 深度优先遍历求所有结果集 dfs(nums,0,len,target,path,res); // 求出解集中的所有情况 for(List&lt;Integer&gt; list : res)&#123; sum += isok(list); &#125; return sum; &#125; // 求出所有解集 public void dfs(int[] nums,int start,int len,int target,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; if(target &lt; 0)&#123; return; &#125; if(target == 0)&#123; res.add(new ArrayList(path)); &#125; for(int i = start; i &lt; len; i++)&#123; path.addLast(nums[i]); // 可以重复使用，因此i不用+1 dfs(nums,i,len,target - nums[i],path,res); path.removeLast(); &#125; &#125; // 求出列表的所有组合情况 public int isok(List&lt;Integer&gt; list)&#123; int[] nums = new int[list.size()]; for(int i = 0 ; i &lt; nums.length; i++)&#123; nums[i] = list.get(i); &#125; int len = nums.length; Deque&lt;Integer&gt; path = new ArrayDeque(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 布尔数组，用于标记改数是否使用过 boolean[] used = new boolean[len]; dfs2(nums,len,0,used,path,res); return res.size(); &#125; // 求全排列 public void dfs2(int[] nums,int len,int depth,boolean[] used,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; if(depth == len)&#123; res.add(new ArrayList(path)); return; &#125; for(int i = 0 ; i &lt; len; i++)&#123; if(used[i])&#123; continue; &#125; // 因为有重复元素，所以在下一层碰到相同元素会使结果重复，相对于全排列，进一步剪枝 if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1])&#123; continue; &#125; // 回溯算法经典步骤 // 先将当前数字加入栈，并将使用过的元素标记为true path.addLast(nums[i]); used[i] = true; dfs2(nums,len,depth + 1,used,path,res); // 回到之前的状态 path.removeLast(); used[i] = false; &#125; &#125;&#125; demo2 123456789101112131415class Solution &#123; public int combinationSum4(int[] nums, int target) &#123; int[] dp = new int[target + 1]; dp[0] = 1; for(int i = 0; i &lt;= target; i++)&#123; for(int num : nums)&#123; if(num &lt;= i)&#123; dp[i] += dp[i - num]; &#125; &#125; &#125; return dp[target]; &#125;&#125; :smile:以上题解仅限于个人理解，如有更好的方法或者更高效的解法，请移步至评论区，谢谢！","categories":[{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://xmmarlowe.github.io/tags/Leetcode/"}],"author":"Marlowe"},{"title":"Leetcode全排列1-2题题解","slug":"题解/Leetcode全排列1-2题题解","date":"2020-10-12T13:49:35.000Z","updated":"2020-12-05T04:44:00.939Z","comments":true,"path":"2020/10/12/题解/Leetcode全排列1-2题题解/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%A2%98%E8%A7%A3/Leetcode%E5%85%A8%E6%8E%92%E5%88%971-2%E9%A2%98%E9%A2%98%E8%A7%A3/","excerpt":"","text":"Leetcode全排列1-2题题解对于全排列问题，可能我们很多人从小在数学课上都做过，并且都能由一定的规律将所有排列情况写出来，但如何用编码的方式求解此类问题成了我的问题，或许也成是你们还未解决的问题，其实这类问题的套路都是 dfs + 回溯算法，然后，根据题目要求进行剪枝，我将通过下面两题来讲解这类问题具体做法。 46. 全排列给定一个 没有重复 数字的序列，返回其所有可能的全排列。 示例: 12345678910输入: [1,2,3]输出:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 题解（dfs，回溯算法）分析：由于是回溯算法，因此，会用到栈，通常我们所学的栈是这种用法 Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;();,但在Stack的源码中发现了Deque&lt;Integer&gt; stack = new ArrayDeque&lt;Integer&gt;();这种用法，百度之后，知道了Deque : （double-ended queue，双端队列）是一种具有队列和栈的性质的数据结构。双端队列中的元素可以从两端弹出，相比list增加运算符重载。 具体步骤如下：1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; // 数组长度 int len = nums.length; // 结果集 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 双端队列，保存临时路径 Deque&lt;Integer&gt; path = new ArrayDeque(); // 布尔数组，保存改数字是否使用过 boolean[] used = new boolean[len]; // 深度优先遍历求所有结果集 dfs(nums,len,0,used,path,res); return res; &#125; public void dfs(int[] nums,int len,int depth,boolean[] used,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; // 如果到达最深的一层 if(depth == len)&#123; // 将当前路径加入结果集 res.add(new ArrayList(path)); return; &#125; for(int i = 0 ; i &lt; len; i++)&#123; // 判断当前数字是否用过 if(used[i])&#123; continue; &#125; // 回溯算法经典步骤 // 先将当前数字加入栈，并将使用过的元素标记为true path.addLast(nums[i]); used[i] = true; dfs(nums,len,depth + 1,used,path,res); // 回到之前的状态 path.removeLast(); used[i] = false; &#125; &#125;&#125; 47. 全排列 II给定一个可包含重复数字的序列，返回所有不重复的全排列。 示例: 1234567输入: [1,1,2]输出:[ [1,1,2], [1,2,1], [2,1,1]] 题解（dfs，回溯算法）分析：此题和全排列解法类似，唯一的差别在于可选数组nums中存在重复的数字，可能会产生重复的路径，因此，需要在判断当前数字是否用过后，再次判断上一次使用的数字和当前数字是否相同，如果相同，进行剪枝，具体差别见代码。 具体步骤如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123; // 数组长度 int len = nums.length; // 对数组排序 Arrays.sort(nums); // 结果集 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 双端队列，保存临时路径 Deque&lt;Integer&gt; path = new ArrayDeque(); // 布尔数组，保存改数字是否使用过 boolean[] used = new boolean[len]; // 深度优先遍历求所有结果集 dfs(nums,len,0,used,path,res); return res; &#125; public void dfs(int[] nums,int len,int depth,boolean[] used,Deque&lt;Integer&gt; path,List&lt;List&lt;Integer&gt;&gt; res)&#123; // 如果到达最深的一层 if(depth == len)&#123; // 将当前路径加入结果集 res.add(new ArrayList(path)); return; &#125; for(int i = 0 ; i &lt; len; i++)&#123; // 判断当前数字是否用过 if(used[i])&#123; continue; &#125; // 因为有重复元素，所以在下一层碰到相同元素会使结果重复，相对于全排列，进一步剪枝 if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) &#123; continue; &#125; // 回溯算法经典步骤 // 先将当前数字加入栈，并将使用过的元素标记为true path.addLast(nums[i]); used[i] = true; dfs(nums,len,depth + 1,used,path,res); // 回到之前的状态 path.removeLast(); used[i] = false; &#125; &#125;&#125; :smile:以上题解仅限于个人理解，如有更好的方法或者更高效的解法，请移步至评论区，谢谢！","categories":[{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://xmmarlowe.github.io/tags/Leetcode/"}],"author":"Marlowe"},{"title":"Leetcode两数-四数之和题解","slug":"题解/Leetcode两数-四数之和题解","date":"2020-10-12T13:35:23.000Z","updated":"2020-12-05T04:44:00.942Z","comments":true,"path":"2020/10/12/题解/Leetcode两数-四数之和题解/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%A2%98%E8%A7%A3/Leetcode%E4%B8%A4%E6%95%B0-%E5%9B%9B%E6%95%B0%E4%B9%8B%E5%92%8C%E9%A2%98%E8%A7%A3/","excerpt":"","text":"Leecode两数-四数之和题解最近两天做了两数之和，四数之和，并且之前也做过三数之和，感觉这几道题解法都差不多，并且用同样的方法能求解n数之和。 1. 两数之和给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。 示例: 1234给定 nums &#x3D; [2, 7, 11, 15], target &#x3D; 9因为 nums[0] + nums[1] &#x3D; 2 + 7 &#x3D; 9所以返回 [0, 1] 题解（哈希表）分析：利用哈希map，key存放数字，value存放索引，遍历数组，依次取一个数，然后计算出另外一个数，如果哈希map中存在，直接取出索引，返回结果，如果不存在，向哈希map中添加当前元素和对应的下标。 具体步骤如下：1234567891011121314151617class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; // key存放数字，value存放index HashMap&lt;Integer,Integer&gt; map = new HashMap(); for(int i = 0; i &lt; nums.length;i++)&#123; int num2 = target - nums[i]; // 如果哈希map中存在当前数，直接返回i和当前数的下标 if(map.containsKey(num2))&#123; return new int[] &#123; map.get(num2), i &#125;; &#125;else&#123; // 将当前数放入哈希map map.put(nums[i],i); &#125; &#125; return null; &#125;&#125; 15. 三数之和给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 示例： 1234567给定数组 nums &#x3D; [-1, 0, 1, 2, -1, -4]，满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]] 题解（排序，双指针）分析：此题要求出三个数的和为0的结果集，则只需对原数组排序，然后从最小的数开始选，接着设置左右指针，如果当前三个数和为0，将这三个数加入结果集，继续寻找，如果当前三个数和大于0，右指针左移，小于0，左指针右移。 具体步骤如下：12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123; int len = nums.length; List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList(); //如果数组为空 或者长度小于三 直接返回空 if(nums == null || len &lt;3) return ans; //对数组排序 Arrays.sort(nums); for(int i = 0 ; i &lt; len;i++)&#123; //如果当前最小的数大于0，直接结束循环 if(nums[i] &gt; 0) break; //去重 if(i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) continue; //设置左右指针 int left = i + 1; int right = len - 1; while(left &lt; right)&#123; int sum = nums[i] + nums[left] + nums[right]; if( sum == 0)&#123; ans.add(Arrays.asList(nums[i],nums[left],nums[right])); //左边元素去重 while(left &lt; right &amp;&amp; nums[left] == nums[left + 1]) left++; //右边元素去重 while(left &lt; right &amp;&amp; nums[right] == nums[right - 1]) right--; //移动左右指针 left++; right--; &#125; if(sum &gt; 0) right--; if(sum &lt; 0) left++; &#125; &#125; return ans; &#125;&#125; 18. 四数之和给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。 注意： 答案中不可以包含重复的四元组。 示例： 12345678给定数组 nums &#x3D; [1, 0, -1, 0, -2, 2]，和 target &#x3D; 0。满足要求的四元组集合为：[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]] 题解（排序，双指针）分析：此题要求出四个数的和为target的结果集，则只需对原数组排序，然后将四数之和降为三数之和，接着设置左右指针，如果当前四个数和为target，将这四个数加入结果集，继续寻找，如果当前四个数和大于target，右指针左移，小于0，左指针右移，具体步骤见代码注释。 具体步骤如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) &#123; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); // 边界条件判断 if(nums == null || nums.length &lt; 4)&#123; return res; &#125; // 对原数组排序 Arrays.sort(nums); // 获取原数组长度 int l = nums.length; for(int i = 0; i &lt; l - 3; i++)&#123; // 去重 if( i &gt; 0 &amp;&amp; nums[i] == nums[i-1])&#123; continue; &#125; // 如果当前数加上后面最小的三个数都比target大，直接跳出 if(nums[i] + nums[i + 1] + nums[i + 2] + nums[i + 3] &gt; target)&#123; break; &#125; // 如果当前数加上最大的三个数逗比target小，跳过当前数 if(nums[i] + nums[l - 3] + nums[l - 2] + nums[l - 1] &lt; target)&#123; continue; &#125; // 同上（n数之和直接重复此操作即可） for(int j = i + 1; j &lt; l - 2; j++)&#123; if(j &gt; i + 1 &amp;&amp; nums[j] == nums[j - 1])&#123; continue; &#125; if(nums[i] + nums[j] + nums[j + 1] + nums[j + 2] &gt; target)&#123; break; &#125; if(nums[i] + nums[j] + nums[l - 1] + nums[l - 2] &lt; target)&#123; continue; &#125; // 将n树之和转为两数之和 int left = j + 1; int right = l - 1; while(left &lt; right)&#123; int sum = nums[i] + nums[j] + nums[left] + nums[right]; if(sum == target)&#123; // 加入结果集 res.add(Arrays.asList(nums[i],nums[j],nums[left],nums[right])); // 去重 while(left &lt; right &amp;&amp; nums[left] == nums[left + 1])&#123; left++; &#125; left++; // 去重 while(left &lt; right &amp;&amp; nums[right] == nums[right - 1])&#123; right--; &#125; right--; &#125;else if(sum &gt; target)&#123; right--; &#125;else&#123; left++; &#125; &#125; &#125; &#125; return res; &#125;&#125; 由三数之和和四数之和可以得出n数之和的解法，思想是一样的，都是枚举，去重，再将最后两个数的和转换为双指针，降低时间复杂度","categories":[{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://xmmarlowe.github.io/tags/Leetcode/"}],"author":"Marlowe"},{"title":"test","slug":"随笔/test","date":"2020-10-12T12:35:34.000Z","updated":"2020-12-02T15:04:50.067Z","comments":true,"path":"2020/10/12/随笔/test/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%9A%8F%E7%AC%94/test/","excerpt":"","text":"testhexohello,world!","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://xmmarlowe.github.io/tags/test/"}]},{"title":"我的第一篇博客","slug":"随笔/我的第一篇博客","date":"2020-10-12T12:20:20.000Z","updated":"2021-05-05T09:08:19.969Z","comments":true,"path":"2020/10/12/随笔/我的第一篇博客/","link":"","permalink":"https://xmmarlowe.github.io/2020/10/12/%E9%9A%8F%E7%AC%94/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"我的第一篇博客记录一下最近使用hexo搭建的博客 &ensp;&ensp;周六晚上开始搭建，安装node、npm等等，碰到了一系列问题，换了一个主题后，总算把博客整体框架搭建好了，接着周日本是完整的一天，但早上九点多才起床，到实验室接近10点了，继续研究配置文件，以及主题的源代码，但是没啥效果，github有时候也抽风，就问了问学长,最后重新配置了仓库，总算解决了。&ensp;&ensp;周一中午开始研究上传到github以及自动部署脚本文件，到了晚上都没解决，最后才知道博客仓库只是部署编译出来的网站静态文件，如果想要使用github进行代码托管，只有新建一个代码库，把所有文件上传上去。脚本文件如下 12345678910111213@echo offD:cd D:\\PersonalFile\\HexoBlogecho &#39;start git sync&#39;git add .git add -Agit add -ugit commit -m &quot;update...&quot;git pull HexoBlog mastergit push HexoBlog mastercall hexo ghexo d","categories":[{"name":"随笔","slug":"随笔","permalink":"https://xmmarlowe.github.io/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"test","slug":"test","permalink":"https://xmmarlowe.github.io/tags/test/"},{"name":"随笔","slug":"随笔","permalink":"https://xmmarlowe.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"public、private、protected、default的区别","slug":"Java/public、private、protected、default的区别","date":"2020-04-20T05:49:35.000Z","updated":"2021-04-23T14:22:55.683Z","comments":true,"path":"2020/04/20/Java/public、private、protected、default的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/20/Java/public%E3%80%81private%E3%80%81protected%E3%80%81default%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"publicJava语言中访问限制最宽的修饰符，一般称之为“公共的”。被其修饰的类、属性以及方法不仅可以跨类访问，而且允许跨包（package）访问。 privateJava语言中对访问权限限制的最窄的修饰符，一般称之为“私有的”。被其修饰的类、属性以及方法只能被该类的对象访问，其子类不能访问，更不能允许跨包访问。 protected介于public 和 private 之间的一种访问修饰符，一般称之为“保护形”。被其修饰的类、属性以及方法只能被类本身的方法及子类访问，即使子类在不同的包中也可以访问。 default即不加任何访问修饰符，通常称为“默认访问模式”。该模式下，只允许在同一个包中进行访问。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"public","slug":"public","permalink":"https://xmmarlowe.github.io/tags/public/"},{"name":"private","slug":"private","permalink":"https://xmmarlowe.github.io/tags/private/"},{"name":"protected","slug":"protected","permalink":"https://xmmarlowe.github.io/tags/protected/"},{"name":"default","slug":"default","permalink":"https://xmmarlowe.github.io/tags/default/"}],"author":"Marlowe"},{"title":"JDK1.8新特性","slug":"Java/JDK1-8新特性","date":"2020-04-16T07:55:02.000Z","updated":"2021-04-23T14:22:41.706Z","comments":true,"path":"2020/04/16/Java/JDK1-8新特性/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/16/Java/JDK1-8%E6%96%B0%E7%89%B9%E6%80%A7/","excerpt":"Java 8 (又称为 jdk 1.8) 是 Java 语言开发的一个主要版本。 Oracle 公司于 2014 年 3 月 18 日发布 Java 8 ，它支持函数式编程，新的 JavaScript 引擎，新的日期 API，新的Stream API 等。","text":"Java 8 (又称为 jdk 1.8) 是 Java 语言开发的一个主要版本。 Oracle 公司于 2014 年 3 月 18 日发布 Java 8 ，它支持函数式编程，新的 JavaScript 引擎，新的日期 API，新的Stream API 等。 Lambda 表达式Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 以下是lambda表达式的重要特征: 可选类型声明： 不需要声明参数类型，编译器可以统一识别参数值。 可选的参数圆括号： 一个参数无需定义圆括号，但多个参数需要定义圆括号。 可选的大括号： 如果主体包含了一个语句，就不需要使用大括号。 可选的返回关键字： 如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定明表达式返回了一个数值。 变量作用域lambda 表达式只能引用标记了 final 的外层局部变量，这就是说不能在 lambda 内部修改定义在域外的局部变量，否则会编译错误。 1234567891011121314public class Java8Tester &#123; final static String salutation = &quot;Hello! &quot;; public static void main(String args[])&#123; GreetingService greetService1 = message -&gt; System.out.println(salutation + message); greetService1.sayMessage(&quot;Runoob&quot;); &#125; interface GreetingService &#123; void sayMessage(String message); &#125;&#125; 我们也可以直接在 lambda 表达式中访问外层的局部变量： 1234567891011public class Java8Tester &#123; public static void main(String args[]) &#123; final int num = 1; Converter&lt;Integer, String&gt; s = (param) -&gt; System.out.println(String.valueOf(param + num)); s.convert(2); // 输出结果为 3 &#125; public interface Converter&lt;T1, T2&gt; &#123; void convert(int i); &#125;&#125; lambda 表达式的局部变量可以不用声明为 final，但是必须不可被后面的代码修改（即隐性的具有 final 的语义） 12345int num = 1; Converter&lt;Integer, String&gt; s = (param) -&gt; System.out.println(String.valueOf(param + num));s.convert(2);num = 5; //报错信息：Local variable num defined in an enclosing scope must be final or effectively final 在 Lambda 表达式当中不允许声明一个与局部变量同名的参数或者局部变量。 12String first = &quot;&quot;; Comparator&lt;String&gt; comparator = (first, second) -&gt; Integer.compare(first.length(), second.length()); //编译会出错 方法引用方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 方法引用通过方法的名字来指向一个方法。 方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 方法引用使用一对冒号 :: 。 下面，我们在 Car 类中定义了 4 个方法作为例子来区分 Java 中 4 种不同方法的引用。 12345678910111213141516171819202122232425package com.runoob.main; @FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; class Car &#123; //Supplier是jdk1.8的接口，这里和lamda一起使用了 public static Car create(final Supplier&lt;Car&gt; supplier) &#123; return supplier.get(); &#125; public static void collide(final Car car) &#123; System.out.println(&quot;Collided &quot; + car.toString()); &#125; public void follow(final Car another) &#123; System.out.println(&quot;Following the &quot; + another.toString()); &#125; public void repair() &#123; System.out.println(&quot;Repaired &quot; + this.toString()); &#125;&#125; 构造器引用： 它的语法是Class::new，或者更一般的Class&lt; T &gt;::new实例如下： 12final Car car = Car.create( Car::new );final List&lt; Car &gt; cars = Arrays.asList( car ); 静态方法引用： 它的语法是Class::static_method，实例如下： 1cars.forEach( Car::collide ); 特定类的任意对象的方法引用： 它的语法是Class::method实例如下： 1cars.forEach( Car::repair ); 特定对象的方法引用： 它的语法是instance::method实例如下： 12final Car police = Car.create( Car::new );cars.forEach( police::follow ); 默认方法简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。 我们只需在方法名前面加个 default 关键字即可实现默认方法。 为什么要有这个特性？首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类，目前的 java 8 之前的集合框架没有 foreach 方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。 语法默认方法语法格式如下： 12345public interface Vehicle &#123; default void print()&#123; System.out.println(&quot;我是一辆车!&quot;); &#125;&#125; 多个默认方法一个接口有默认方法，考虑这样的情况，一个类实现了多个接口，且这些接口有相同的默认方法，以下实例说明了这种情况的解决方法： 1234567891011public interface Vehicle &#123; default void print()&#123; System.out.println(&quot;我是一辆车!&quot;); &#125;&#125; public interface FourWheeler &#123; default void print()&#123; System.out.println(&quot;我是一辆四轮车!&quot;); &#125;&#125; 第一个解决方案是创建自己的默认方法，来覆盖重写接口的默认方法： 12345public class Car implements Vehicle, FourWheeler &#123; default void print()&#123; System.out.println(&quot;我是一辆四轮汽车!&quot;); &#125;&#125; 第二种解决方案可以使用 super 来调用指定接口的默认方法： 12345public class Car implements Vehicle, FourWheeler &#123; public void print()&#123; Vehicle.super.print(); &#125;&#125; 静态默认方法Java 8 的另一个特性是接口可以声明（并且可以提供实现）静态方法,通过类名.方法名调用。例如： 123456789public interface Vehicle &#123; default void print()&#123; System.out.println(&quot;我是一辆车!&quot;); &#125; // 静态方法 static void blowHorn()&#123; System.out.println(&quot;按喇叭!!!&quot;); &#125;&#125; 新工具新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。 Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。 Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。 这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。 元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。 123+--------------------+ +------+ +------+ +---+ +-------+| stream of elements +-----&gt; |filter+-&gt; |sorted+-&gt; |map+-&gt; |collect|+--------------------+ +------+ +------+ +---+ +-------+ 以上的流程转换为 Java 代码为： 123456List&lt;Integer&gt; transactionsIds = widgets.stream() .filter(b -&gt; b.getColor() == RED) .sorted((x,y) -&gt; x.getWeight() - y.getWeight()) .mapToInt(Widget::getWeight) .sum(); 生成流在 Java 8 中, 集合接口有两个方法来生成流： stream() − 为集合创建串行流。 parallelStream() − 为集合创建并行流。 12List&lt;String&gt; strings = Arrays.asList(&quot;abc&quot;, &quot;&quot;, &quot;bc&quot;, &quot;efg&quot;, &quot;abcd&quot;,&quot;&quot;, &quot;jkl&quot;);List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList()); forEachStream 提供了新的方法 ‘forEach’ 来迭代流中的每个数据。以下代码片段使用 forEach 输出了10个随机数： 12Random random = new Random();random.ints().limit(10).forEach(System.out::println); mapmap 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数： 123List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);// 获取对应的平方数List&lt;Integer&gt; squaresList = numbers.stream().map( i -&gt; i*i).distinct().collect(Collectors.toList()); filterfilter 方法用于通过设置的条件过滤出元素。以下代码片段使用 filter 方法过滤出空字符串： 123List&lt;String&gt;strings = Arrays.asList(&quot;abc&quot;, &quot;&quot;, &quot;bc&quot;, &quot;efg&quot;, &quot;abcd&quot;,&quot;&quot;, &quot;jkl&quot;);// 获取空字符串的数量long count = strings.stream().filter(string -&gt; string.isEmpty()).count(); limitlimit 方法用于获取指定数量的流。 以下代码片段使用 limit 方法打印出 10 条数据： 12Random random = new Random();random.ints().limit(10).forEach(System.out::println); sortedsorted 方法用于对流进行排序。以下代码片段使用 sorted 方法对输出的 10 个随机数进行排序： 12Random random = new Random();random.ints().limit(10).sorted().forEach(System.out::println); 并行（parallel）程序parallelStream 是流并行处理程序的代替方法。以下实例我们使用 parallelStream 来输出空字符串的数量： 123List&lt;String&gt; strings = Arrays.asList(&quot;abc&quot;, &quot;&quot;, &quot;bc&quot;, &quot;efg&quot;, &quot;abcd&quot;,&quot;&quot;, &quot;jkl&quot;);// 获取空字符串的数量long count = strings.parallelStream().filter(string -&gt; string.isEmpty()).count(); Date Time API加强对日期与时间的处理。 在旧版的 Java 中，日期时间 API 存在诸多问题，其中有： 非线程安全 − java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 设计很差 − Java的日期/时间类的定义并不一致，在java.util和java.sql的包中都有日期类，此外用于格式化和解析的类在java.text包中定义。java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期，将其纳入java.sql包并不合理。另外这两个类都有相同的名字，这本身就是一个非常糟糕的设计。 时区处理麻烦 − 日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calendar和java.util.TimeZone类，但他们同样存在上述所有的问题。 Java 8 在 java.time 包下提供了很多新的 API。以下为两个比较重要的 API： Local(本地) − 简化了日期时间的处理，没有时区的问题。 Zoned(时区) − 通过制定的时区处理日期时间。 新的java.time包涵盖了所有处理日期，时间，日期/时间，时区，时刻（instants），过程（during）与时钟（clock）的操作。 Optional 类Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。 Optional 类的引入很好的解决空指针异常。 类声明以下是一个 java.util.Optional&lt;T&gt; 类 的声明： 1public final class Optional&lt;T&gt; extends Object Optional 实例我们可以通过以下实例来更好的了解 Optional 类的使用： 1234567891011121314151617181920212223242526272829303132import java.util.Optional; public class Java8Tester &#123; public static void main(String args[])&#123; Java8Tester java8Tester = new Java8Tester(); Integer value1 = null; Integer value2 = new Integer(10); // Optional.ofNullable - 允许传递为 null 参数 Optional&lt;Integer&gt; a = Optional.ofNullable(value1); // Optional.of - 如果传递的参数是 null，抛出异常 NullPointerException Optional&lt;Integer&gt; b = Optional.of(value2); System.out.println(java8Tester.sum(a,b)); &#125; public Integer sum(Optional&lt;Integer&gt; a, Optional&lt;Integer&gt; b)&#123; // Optional.isPresent - 判断值是否存在 System.out.println(&quot;第一个参数值存在: &quot; + a.isPresent()); System.out.println(&quot;第二个参数值存在: &quot; + b.isPresent()); // Optional.orElse - 如果值存在，返回它，否则返回默认值 Integer value1 = a.orElse(new Integer(0)); //Optional.get - 获取值，值需要存在 Integer value2 = b.get(); return value1 + value2; &#125;&#125; 执行以上脚本，输出结果为： 12345$ javac Java8Tester.java $ java Java8Tester第一个参数值存在: false第二个参数值存在: true10 Nashorn, JavaScript 引擎Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://xmmarlowe.github.io/tags/JDK/"}],"author":"Marlowe"},{"title":"8种基本类型的包装类和常量池","slug":"Java/8种基本类型的包装类和常量池","date":"2020-04-16T05:40:01.000Z","updated":"2021-04-23T14:20:50.810Z","comments":true,"path":"2020/04/16/Java/8种基本类型的包装类和常量池/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/16/Java/8%E7%A7%8D%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8C%85%E8%A3%85%E7%B1%BB%E5%92%8C%E5%B8%B8%E9%87%8F%E6%B1%A0/","excerpt":"","text":"Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；前面 4 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，Character创建了数值在[0,127]范围的缓存数据，Boolean 直接返回True Or False。如果超出对应范围仍然会去创建新的对象。 为啥把缓存设置为[-128，127]区间？（参见issue/461）性能和资源之间的权衡。 123public static Boolean valueOf(boolean b) &#123; return (b ? TRUE : FALSE);&#125; 123456789private static class CharacterCache &#123; private CharacterCache()&#123;&#125; static final Character cache[] = new Character[127 + 1]; static &#123; for (int i = 0; i &lt; cache.length; i++) cache[i] = new Character((char)i); &#125; &#125; 两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。 123456789Integer i1 = 33;Integer i2 = 33;System.out.println(i1 == i2);// 输出 trueInteger i11 = 333;Integer i22 = 333;System.out.println(i11 == i22);// 输出 falseDouble i3 = 1.2;Double i4 = 1.2;System.out.println(i3 == i4);// 输出 false Integer 缓存源代码： 12345678/***此方法将始终缓存-128 到 127（包括端点）范围内的值，并可以缓存此范围之外的其他值。*/ public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 应用场景： Integer i1=40；Java 在编译的时候会直接将代码封装成 Integer i1=Integer.valueOf(40);，从而使用常量池中的对象。 Integer i1 = new Integer(40);这种情况下会创建新的对象。 123Integer i1 = 40;Integer i2 = new Integer(40);System.out.println(i1==i2);//输出 false Integer 比较更丰富的一个例子: 12345678910111213Integer i1 = 40;Integer i2 = 40;Integer i3 = 0;Integer i4 = new Integer(40);Integer i5 = new Integer(40);Integer i6 = new Integer(0);System.out.println(&quot;i1=i2 &quot; + (i1 == i2));System.out.println(&quot;i1=i2+i3 &quot; + (i1 == i2 + i3));System.out.println(&quot;i1=i4 &quot; + (i1 == i4));System.out.println(&quot;i4=i5 &quot; + (i4 == i5));System.out.println(&quot;i4=i5+i6 &quot; + (i4 == i5 + i6)); System.out.println(&quot;40=i5+i6 &quot; + (40 == i5 + i6)); 结果： 123456i1=i2 truei1=i2+i3 truei1=i4 falsei4=i5 falsei4=i5+i6 true40=i5+i6 true 解释： 语句 i4 == i5 + i6，因为+这个操作符不适用于 Integer 对象，首先 i5 和 i6 进行自动拆箱操作，进行数值相加，即 i4 == 40。然后 Integer 对象无法与数值进行直接比较，所以 i4 自动拆箱转为 int 值 40，最终这条语句转为 40 == 40 进行数值比较。 参考8 种基本类型的包装类和常量池","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"包装类","slug":"包装类","permalink":"https://xmmarlowe.github.io/tags/%E5%8C%85%E8%A3%85%E7%B1%BB/"},{"name":"常量池","slug":"常量池","permalink":"https://xmmarlowe.github.io/tags/%E5%B8%B8%E9%87%8F%E6%B1%A0/"}],"author":"Marlowe"},{"title":"String类和常量池","slug":"Java/String类和常量池","date":"2020-04-16T05:39:36.000Z","updated":"2021-04-23T14:22:59.741Z","comments":true,"path":"2020/04/16/Java/String类和常量池/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/16/Java/String%E7%B1%BB%E5%92%8C%E5%B8%B8%E9%87%8F%E6%B1%A0/","excerpt":"","text":"String 对象的两种创建方式： 12345String str1 = &quot;abcd&quot;;//先检查字符串常量池中有没有&quot;abcd&quot;，如果字符串常量池中没有，则创建一个，然后 str1 指向字符串常量池中的对象，如果有，则直接将 str1 指向&quot;abcd&quot;&quot;；String str2 = new String(&quot;abcd&quot;);//堆中创建一个新的对象String str3 = new String(&quot;abcd&quot;);//堆中创建一个新的对象System.out.println(str1==str2);//falseSystem.out.println(str2==str3);//false 这两种不同的创建方法是有差别的。 第一种方式是在常量池中拿对象； 第二种方式是直接在堆内存空间创建一个新的对象。 记住一点：只要使用 new 方法，便需要创建新的对象。 String 类型的常量池比较特殊。它的主要使用方法有两种： 直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，JDK1.7之前（不包含1.7）的处理方式是在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用，JDK1.7以及之后的处理方式是在常量池中记录此字符串的引用，并返回该引用。 123456String s1 = new String(&quot;计算机&quot;);String s2 = s1.intern();String s3 = &quot;计算机&quot;;System.out.println(s2);//计算机System.out.println(s1 == s2);//false，因为一个是堆内存中的 String 对象一个是常量池中的 String 对象，System.out.println(s3 == s2);//true，因为两个都是常量池中的 String 对象 字符串拼接: 12345678910String str1 = &quot;str&quot;;String str2 = &quot;ing&quot;;String str3 = &quot;str&quot; + &quot;ing&quot;;//常量池中的对象String str4 = str1 + str2; //在堆上创建的新的对象 String str5 = &quot;string&quot;;//常量池中的对象System.out.println(str3 == str4);//falseSystem.out.println(str3 == str5);//trueSystem.out.println(str4 == str5);//false 尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 StringBuilder 或者 StringBuffer。 String s1 = new String(“abc”);这句话创建了几个字符串对象？将创建 1 或 2 个字符串。如果池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。如果池中没有字符串常量“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象。 验证： 1234String s1 = new String(&quot;abc&quot;);// 堆内存的地址值String s2 = &quot;abc&quot;;System.out.println(s1 == s2);// 输出 false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。System.out.println(s1.equals(s2));// 输出 true 结果： 12falsetrue","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"常量池","slug":"常量池","permalink":"https://xmmarlowe.github.io/tags/%E5%B8%B8%E9%87%8F%E6%B1%A0/"},{"name":"String","slug":"String","permalink":"https://xmmarlowe.github.io/tags/String/"}],"author":"Marlowe"},{"title":"final finally finalize的区别","slug":"Java/final-finally-finalize的区别","date":"2020-04-15T14:37:21.000Z","updated":"2021-04-23T14:21:28.552Z","comments":true,"path":"2020/04/15/Java/final-finally-finalize的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/15/Java/final-finally-finalize%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"简单概述final 、 finally 、 finalize三个关键字的区别…","text":"简单概述final 、 finally 、 finalize三个关键字的区别… final可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表示该变量是一个常量不能被重新赋值。 finally一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。 finalize是一个方法，属于Object类的一个方法，而Object类是所有类的父类，该方法一般由垃圾回收器来调用，当我们调用System的gc()方法的时候，由垃圾回收器调用finalize(),回收垃圾。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"finally","slug":"finally","permalink":"https://xmmarlowe.github.io/tags/finally/"},{"name":"final","slug":"final","permalink":"https://xmmarlowe.github.io/tags/final/"},{"name":"finalize","slug":"finalize","permalink":"https://xmmarlowe.github.io/tags/finalize/"}],"author":"Marlowe"},{"title":"Java高并发之锁总结","slug":"并发/Java高并发之锁总结","date":"2020-04-11T13:37:12.000Z","updated":"2021-04-29T14:29:46.990Z","comments":true,"path":"2020/04/11/并发/Java高并发之锁总结/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/11/%E5%B9%B6%E5%8F%91/Java%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%94%81%E6%80%BB%E7%BB%93/","excerpt":"","text":"Java线程锁机制是怎样的？ JAVA的锁就是在对象的Markword中记录一个锁状态。无锁，偏向锁，轻量级锁，重量级锁对应不同的锁状态。 JAVA的锁机制就是根据资源竞争的激烈程度不断进行锁升级的过程。 锁的分类1. 乐观锁与悲观锁 乐观锁 对共享数据进行访问时，乐观锁总是认为不会有其他线程修改数据修改数据。 于是直接执行操作，只是在更新时检查数据是否已经被其他线程修改。 如果没有被修改，则操作执行成功；否则，添加其他补偿措施。 常见的补偿措施是不断尝试，直到成功。 Java中的非阻塞同步都是采用这种乐观的并发策略，乐观锁在Java中是通过使用无锁编程来实现，最常使用的CAS操作。 比如，线程安全的原子类的自增操作，就是通过循环的CAS操作实现的。 悲观锁 对共享数据进行访问时，悲观锁总是认为一定会有其他线程修改数据。如果不加锁，肯定会出问题。 因此，悲观锁无论是否出现共享数据的争用，在访问数据时都会先加锁。 Java中同步互斥都是采用这种悲观的并发策略，synchronized关键字和Lock接口的实现类都是悲观锁。 2. 独占锁和共享锁 独占锁 又叫排它锁，同一个锁对象，同一时刻只允许一个线程获取到锁。 如果线程T对数据A加上独占锁后，其他线程不能对该数据再加任何类型的锁（包括独占锁和共享锁），自己可以对数据进行读操作或者写操作。 独占锁允许线程对数据进行读写操作。 Java中的 synchronized关键字、Mutex、ReentrantLock、ReentrantReadWriteLock 中写锁，都是独占锁。 共享锁 同一个所对象，同一时刻允许多个线程获取到锁。 线程T对数据A加上共享锁，则其他线程只能对数据A加共享锁，不能加独占锁。 共享锁只允许对数据进行读操作。 java中ReentrantReadWriteLock中读锁是共享锁。 ReentrantReadWriteLock读写锁的获取： 同步状态不为0，如果有其他线程获取到读锁或者当前线程不是持有写锁的线程，则获取写锁失败进入阻塞状态；否则，当前线程是持有写锁的线程，直接通过setState()方法增加写状态。 同步状态为0，直接通过compareAndSetState()方法实现写状态的CAS增加，并将当前线程设置为持有写锁的线程。 如果有其他线程获取到了写锁，则获取读锁失败进入阻塞状态。 如果写锁未被获取或者该线程为持有写锁的线程，则获取读锁成功，通过compareAndSetState()方法实现读状态的CAS增加 独占锁和共享锁都是通过AQS实现的，tryAcquire()或者tryAcquireShared()方法支持独占式或者共享式的获取同步状态。 3. 公平锁和非公平锁 公平锁 当锁被释放，按照阻塞的先后顺序获取锁，即同步队列头节点中的线程将获取锁。 公平锁可以保证锁的获取按照FIFO原则，但需要进行大量的线程切换，导致吞吐率较低。 非公平锁： 当锁被释放，所有阻塞的线程都可以争抢获取锁的资格，可能导致先阻塞的线程最后获取锁。 非公平锁虽然可能造成线程饥饿，但极少进行线程的切换，保证了更大的吞吐量。 Java中ReentrantLock和ReentrantReadWriteLock支持公平和非公平访问，而synchronized关键字只支持非公平访问。 公平与非公平可以通过构造函数的fair参数进行指定，默认是false，即默认为非公平的获取锁。 公平和非公平都是依靠AQS实现的，公平使用FairSync同步器，非公平使用NoFairSync同步器。123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 4. 可重入锁和非可重入锁 可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 可重入锁： 已经获取锁的线程再次获取该锁而不被锁所阻塞，需要解决线程再次获取锁和锁的最终释放两个问题。 可重入锁可以一定程度的避免死锁。 非可重入锁： 已经获取锁的线程再次获取该锁，会因为需要等待自身释放锁而被阻塞。 非可重入锁容易造成当前线程死锁，从而使整个队列中线程永久阻塞。 Java中的synchronized关键字、ReentrantLock锁和ReentrantReadWriteLock锁都支持重进入，其中ReentrantReadWriteLock的读锁是支持重进入的共享锁，写锁是支持重进入的独占锁。 5.无锁VS偏向锁VS轻量级锁VS重量级锁 synchronized关键字实现同步的基础是每个对象都是一个锁，它依靠对象头存储锁。 无锁、偏向锁、轻量级锁、重量级锁都是专门针对synchronized关键字设计的、级别从低到高的4种状态。 注意： 锁状态只能升级，不能降级。 对象头中的第一个字宽叫做Mark Word，用于存储对象的hashCode、分代年龄、锁等信息。 其中最后2 bit的标志位，用于标记锁的状态。根据标志位的不同，可以有如下几种状态： 无锁 不对资源进行锁定，所有的线程都可以访问并修改同一资源，但同一时刻只有一个线程能修改成功。 无锁的修改操作依靠循环实现： 如果没有争用，修改成功并退出循环；否则，循环尝试修改操作，直到成功。 无锁无法全面代替有锁，但在某些场景下具有非常高的性能。 无锁的经典实现： CAS操作。 偏向锁 出现的原因： 在无竞争的情况下，同一线程可能多次进入同一个同步块，即多次获取同一个锁。 如果进入和退出同步块都使用CAS操作来加锁和解锁，则会消耗一定的资源。 于是通过CAS操作将线程ID存储到Mark Word中，线程再次进入或退出同步块时，直接检查Mark Word中是否存储指向当前线程的偏向锁。 如果存储了，则直接进入或退出同步块。 偏向锁可以在无竞争的情况下，尽量减少不必要的轻量级锁执行路径。轻量级锁的加锁和解锁都需要CAS操作，而偏向锁只有将线程ID存储到Mark Word中时才执行一次CAS操作。 偏向锁的释放： 当有其他线程竞争偏向锁时，持有偏向锁的线程会释放锁偏向锁。 释放时，会根据锁对象是否处于锁定状态而恢复到不同的状态。 如果锁对象处于未锁定状态，撤销偏向后恢复到无锁的状态（0 + 01 ）；如果锁对象处于锁定状态，撤销偏向后恢复到轻量级锁的状态（00）。 偏向锁在JDK1.6及以后，默认是启用的，即-XX:+UseBiasedLocking。可以通过-XX:-UseBiasedLocking关闭偏向锁。 ​偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。 轻量级锁 多个线程竞争同步资源时，没有获取到资源的线程自旋等待锁的释放。 加锁过程： 线程进入同步块时，如果同步对象处于无锁状态（0 + 01），JVM 首先在当前线程的栈帧中开辟一块叫做锁记录（Lock Record）的空间，用于存储同步对象的Mark Word的拷贝。这个拷贝加了一个前缀，叫Displaced Mark Word。 然后通过CAS操作将同步对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向同步对象的Mark Word。 如果这个更新动作成功，则当前线程拥有了该对象的锁，Mark Word中的标志位更新为00，表示对象处于轻量级锁定状态。 如果更新动作失败，JVM首先会检查同步对象的Mark Word是否指向当前线程的栈帧。如果是，说明当前线程已经持有了该对象的锁，可以直接进入同步块继续执行；否则，说明存在多线程竞争锁。 轻量级锁升级为重量级锁 若当前只有一个线程在等待，则通过自旋进行等待。自旋超过一定的次数，轻量级锁升级为重量级锁。 若一个线程持有锁，一个线程自旋等待锁，又有第三个线程想要获取锁，轻量级锁升级为重量级锁。 锁的释放： 通过CAS操作，将Lock Record中的Displaced Mark Word与对象中的Mark Word进行替换。 替换成功，同步状态完成；替换失败，说明有其他线程尝试获取过该锁，释放锁的同时需要唤醒被挂起的线程。 重量级锁 多线程竞争同步资源时，没有获取到资源的线程阻塞等待锁的释放。 轻量级锁升级为重量级锁，锁的标志位变成10，Mark Word中存储的是指向重量级锁的指针。 所有等待锁的线程都会进入阻塞状态。 锁升级过程锁升级的顺序为： 无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁，且锁升级的顺序是不可逆的。 线程第一次获取锁获时锁的状态为偏向锁，如果下次还是这个线程获取锁，则锁的状态不变，否则会升级为CAS轻量级锁；如果还有线程竞争获取锁，如果线程获取到了轻量级锁没啥事了，如果没获取到会自旋，自旋期间获取到了锁没啥事，超过了10次还没获取到锁，锁就升级为重量级的锁，此时如果其他线程没获取到重量级锁，就会被阻塞等待唤起，此时效率就低了。 升级图解 什么是锁降级？一个线程执行写操作，先获取写锁，再获取读锁，完成写操作后先释放写锁，接下来的程序里可能要依赖写操作后的变量值，待程序全部执行完后再释放读锁。先释放了写锁，只剩下了读锁，称之为“锁降级”。 为什么需要锁降级？一句话：为了保证数据可见性。假设线程A修改了数据，释放了写锁，这个时候线程T获得了写锁，修改了数据，然后也释放了写锁，线程A读取数据的时候，读到的是线程T修改的，并不是线程A自己修改的，那么在使用修改后的数据时，就会忽略线程A之前的修改结果。因此通过锁降级来保证数据每次修改后的可见性。 6. 自旋锁与自适应自旋锁 自旋锁： 阻塞或唤醒一个线程都需要从用户态切换到内核态去完成，会对性能造成很大影响。 有时一个线程持有锁的时间很短，如果在很短的时间内让后续获取锁的线程都进入阻塞态，这是很不值得。 可以让后续线程持有CPU时间等待一会，这个等待需要执行忙循环（自旋） 来实现。 自旋等待的时间由自旋次数来衡量，默认为10，可以使用-XX:PreBlockSpin来进行设置。 如果在自旋等待中，持有锁的线程释放该锁，当前线程可以不必阻塞直接获取同步资源。 如果超过自旋次数仍未获取成功，则使用传统的方法将其阻塞。 自旋锁的实现原理： 循环的CAS操作 自旋锁的缺点： 自旋锁虽然避免了线程的切换开销，但是会占用CPU时间。 如果每个等待获取锁的线程总是自旋规定的次数，却又没有等到锁的释放，这样就白白浪费了CPU时间。 自旋锁在JDK1.4.2中引入，默认是关闭的；在JDK1.6中变成默认开启，并为了解决自旋锁中浪费CPU资源的问题，而引入了自适应自旋锁。 自适应自旋锁： 自适应意味着自旋的次数不再固定，而是根据上一次在同一个锁自旋的次数和锁的拥有者的状态来决定。 如果在同一个锁对象上自旋刚刚成功获取过锁，并持有锁的线程处于运行状态，则可以认为这一次自旋也很可能成功，允许它自旋更长的时间。 如果在一个锁上，自旋很少成功，则下一次可以省略自旋过程，直接阻塞线程，避免浪费处理器资源。 一些问题轻量级锁一定比重量级锁快吗？在回答这个问题之前，我们先来了解一下：什么是轻量级锁？什么是重量级锁？ 锁概念轻量级锁是 JDK 1.6 新增的概念，是相对于传统的重量级锁而已的一种状态，在 JDK 1.5 时，synchronized 是需要通过操作系统自身的互斥量（mutex lock）来实现，然而这种实现方式需要通过用户态与和核心态的切换来实现，但这个切换的过程会带来很大的性能开销，所以在 JDK 1.6 就引入了轻量级锁来避免此问题的发生。 轻量级锁执行过程再讲轻量级锁执行过程之前，要先从虚拟机的对象头开始说起，HotSpot 的对象头（Object Header）分为两部分： Mark Word 区域，用于存储对象自身的运行时数据，如哈希码（HashCode）、GC 分带年龄等； 用于存储指向方法区对象类型数据的指针（如果是数组对象的话，还有一个存储数组长度的额外信息）。 Mark Word 在 32 位系统中，有 32bit 空间，其中： 25bit 用来存储 HashCode； 4bit 用来存储对象的分带年龄； 2bit 用来存储锁标志位，01=可偏向锁、00=轻量级锁、10=重量级锁； 1bit 固定为 0。 再说会轻量级锁的执行过程，在代码进入同步块的时候，如果此对象没有被线程所占用，虚拟机会先将此线程的栈帧拷贝一份存储在当前对象的 Lock Record (锁记录) 区域中。 然后虚拟机再使用 CAS (Compare and Swap, 比较并交换) 将本线程的 Mark Word 更新为指向对象 Lock Record 区域的指针，如果更新成功，则表示这个线程拥有了该对象，轻量级锁添加成功，如果更新失败，虚拟机会先检查对象 Mark Word 是否指向了当前线程的线帧，如果是则表明此线程已经拥有了此锁，如果不是，则表明该锁已经被其他线程占用了。如果有两条以上的线程在争抢死锁，那么锁就会膨胀为重量锁，Mark Word 中存储的就是指向重量级锁的互斥量指针，后面等待锁的线程也会进入阻塞状态。 从以上的过程，我们可以看出轻量级锁可以理解为是通过 CAS 实现的，理想的情况下是整个同步周期内不存在锁竞争，那么轻量锁可以有效的提高程序的同步性能，然而，如果情况相反，轻量级锁不但要承担 CAS 的开销还要承担互斥量的开销，这种情况下轻量级锁就会比重量级锁更慢，这就是我们本文的答案。 总结轻量级锁不是在任何情况下都比重量级锁快的，要看同步块执行期间有没有多个线程抢占资源的情况，如果有，那么轻量级线程要承担 CAS + 互斥量锁的性能消耗，就会比重量锁执行的更慢。 打开偏向锁是否效率一定会提升?为什么?偏向锁（不太需要竞争的，一般一个线程）未必会提高，尤其是当你知道一定会有大量线程去竞争的时候。打开偏向锁偏向锁还有一个锁撤销的过程（把ID撕下来）。 为什么要延迟4s？偏向锁默认是在JVM启动4s后再初始化偏向锁，可用如下参数修改启动时间，设为0则表示立即启用。之所以这么设计是因为JVM启动的时候，如果立即启动偏向，有可能会因为线程竞争太激烈导致产生太多安全点挂起。-XX:BiasedLockingStartupDelay=0 参考Java高并发之锁总结、常见的面试问题Java并发编程五 同步之ReentrantLock与Condition","categories":[{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://xmmarlowe.github.io/tags/%E9%94%81/"},{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"}],"author":"Marlowe"},{"title":"Java中的集合类及关系图","slug":"Java/Java中的集合类及关系图","date":"2020-04-11T02:07:50.000Z","updated":"2021-04-23T14:22:30.557Z","comments":true,"path":"2020/04/11/Java/Java中的集合类及关系图/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/11/Java/Java%E4%B8%AD%E7%9A%84%E9%9B%86%E5%90%88%E7%B1%BB%E5%8F%8A%E5%85%B3%E7%B3%BB%E5%9B%BE/","excerpt":"","text":"List 和 Set 继承自 Collection 接口。 Set 无序不允许元素重复。HashSet 和 TreeSet 是两个主要的实现类。 List 有序且允许元素重复。ArrayList、LinkedList 和 Vector 是三个主要的实现 类。 Map 也属于集合系统，但和 Collection 接口没关系。Map 是 key 对 value 的映 射集合，其中 key 列就是一个集合。key 不能重复，但是 value 可以重复。 HashMap、TreeMap 和 Hashtable 是三个主要的实现类。 SortedSet 和 SortedMap 接口对元素按指定规则排序，SortedMap 是对 key 列 进行排序。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"集合类","slug":"集合类","permalink":"https://xmmarlowe.github.io/tags/%E9%9B%86%E5%90%88%E7%B1%BB/"},{"name":"类图","slug":"类图","permalink":"https://xmmarlowe.github.io/tags/%E7%B1%BB%E5%9B%BE/"}],"author":"Marlowe"},{"title":"抽象类和接口的区别","slug":"Java/抽象类和接口的区别","date":"2020-04-11T01:51:44.000Z","updated":"2021-04-23T14:21:00.865Z","comments":true,"path":"2020/04/11/Java/抽象类和接口的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/11/Java/%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"抽象类抽象类是用来捕捉子类的通用特性的 。它不能被实例化，只能被用作子类的超类。抽象类是被用来创建继承层级里子类的模板。 抽象类不能被实例化只能被继承； 包含抽象方法的一定是抽象类，但是抽象类不一定含有抽象方法； 抽象类中的抽象方法的修饰符只能为public或者protected，默认为public； 一个子类继承一个抽象类，则子类必须实现父类抽象方法，否则子类也必须定义为抽象类； 抽象类可以包含属性、方法、构造方法，但是构造方法不能用于实例化，主要用途是被子类调用。 接口接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。接口只是一种形式，接口自身不能做任何事情。 接口可以包含变量、方法；变量被隐士指定为public static final，方法被隐士指定为public abstract（JDK1.8之前）； 接口支持多继承，即一个接口可以extends多个接口，间接的解决了Java中类的单继承问题； 一个类可以实现多个接口； JDK1.8中对接口增加了新的特性：（1）、默认方法（default method）：JDK 1.8允许给接口添加非抽象的方法实现，但必须使用default关键字修饰；定义了default的方法可以不被实现子类所实现，但只能被实现子类的对象调用；如果子类实现了多个接口，并且这些接口包含一样的默认方法，则子类必须重写默认方法；（2）、静态方法（static method）：JDK 1.8中允许使用static关键字修饰一个方法，并提供实现，称为接口静态方法。接口静态方法只能通过接口调用（接口名.静态方法名）。 相同点 都不能被实例化 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。 不同点 接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。 实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。 接口强调特定功能的实现，而抽象类强调所属关系。 接口成员变量默认为public static final，必须赋初值，不能被修改；其所有的成员方法都是public、abstract的。抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被private、static、synchronized和native等修饰，必须以分号结尾，不带花括号。 什么时候使用抽象类和接口 如果你拥有一些方法并且想让它们中的一些有默认实现，那么使用抽象类吧。 如果你想实现多重继承，那么你必须使用接口。由于Java不支持多继承，子类不能够继承多个类，但可以实现多个接口。因此你就可以使用接口来解决它。 如果基本功能在不断改变，那么就需要使用抽象类。如果不断改变基本功能并且使用接口，那么就需要改变所有实现了该接口的类。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"抽象类","slug":"抽象类","permalink":"https://xmmarlowe.github.io/tags/%E6%8A%BD%E8%B1%A1%E7%B1%BB/"},{"name":"接口","slug":"接口","permalink":"https://xmmarlowe.github.io/tags/%E6%8E%A5%E5%8F%A3/"}],"author":"Marlowe"},{"title":"JVM 垃圾收集器","slug":"Java/JVM-垃圾收集器","date":"2020-04-10T14:39:51.000Z","updated":"2021-05-04T02:49:55.048Z","comments":true,"path":"2020/04/10/Java/JVM-垃圾收集器/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/10/Java/JVM-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","excerpt":"","text":"不同的垃圾收集器下图是HotSpot虚拟机1.6版Undate 22d的所有收集器： JVM 垃圾收集器 注： 如果两个收集器之间存在连线，就说明它们可以搭配使用。 七种垃圾收集器:1. Serial（串行GC）-复制Serial是一个新生代收集器，曾经是JDK1.3.1之前新生代唯一的垃圾收集器。采用复制算法。 Serial是一个单线程收集器，会使用一个CPU、一条线程去完成垃圾回收，并且在进行垃圾回收的时候必须暂停其他所有的工作线程，直到垃圾收集结束（这被称为“Stop The World”）。 Serial收集器仍然是虚拟机运行在Client模式下的默认新生代收集器。它的优点是：简单而高效（与其他收集器的单线程比）。对于限定单个CPU的环境来说，Seria收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 Serial/Serial Old收集器运行示意图如下： 2. ParNew（并行GC）复制ParNew收集器也是一个新生代收集器，是Serial收集器的多线程版本。也采用复制算法。除了使用多条线程进行垃圾回收之外，其他行为与Serial收集器一样。 ParNew收集器在单CPU的环境中效果不会比Serial收集器更好，甚至由于存在线程交互的开销，性能可能会更差。 ParNew收集器在多CPU环境下是更高效的，它默认开启的收集线程数与CPU的数量相同。 ParNew/Serial Old收集器运行示意图如下： 3. Parallel Scavenge（并行回收GC）标记-复制Parallel Scavenge收集器也是一个新生代收集器。也是用复制算法，同时也是并行的多线程收集器。 Parallel Scavenge收集器的特点是关注点与其他收集器不同，Parallel Scavenge的关注点是“吞吐量（Throughput）”，吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)。其他收集器关注的是“垃圾收集时的停顿时间”。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户的体验； 而高吞吐量则可以最高效率地利用CPU时间，尽快地完成程序的运算任务，适合在后台运算不需要太多交互的任务。 Parallel Scavenge收集器可以通过参数控制最大垃圾收集停顿时间和吞吐量大小。注意：GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的。因为：系统把新生代空间调小一些，收集的速度就快一些，也就导致垃圾收集要更频繁（空间不够用），比如原来10秒收集一次，一次停顿100毫秒，现在5秒收集一次，每次停顿70毫秒，停顿时间的确在下降，但吞吐量也降下来了。 此外Parallel Scavenge收集器可通过参数开关控制GC自动动态调整参数来提供最合适的停顿时间或最大吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。 自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。 注： Parallel Scavenge收集器无法与CMS收集器配合使用。（原因是Parallel Scavenge收集器及G1收集器都没有使用传统的GC收集器代码框架，而是另外独立实现的） 4. Serial Old（MSC）（串行GC）标记-整理Serial Old是Serial收集器的老年代版本。同样是一个单线程收集器，使用“标记-整理”算法。这个收集器的主要意义是被Client模式下的虚拟机使用。在Server模式下，它主要还有两大用途：一个是在JDK1.5及以前的版本中与Parallel Scavenge收集器搭配使用，另外一个就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure的时候使用。 5. CMS(Concurrent Mark Sweep)（并发GC）标记-清除CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。最符合重视服务响应速度。希望系统停顿时间最短的应用。 该收集器是基于“标记-清除”算法实现的。过程分为4个步骤： 初始标记（CMS initial mark）、并发标记（CMS concurrent mark）、重新标记（CMS remark）、并发清除（CMS concurrent sweep）. 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 核心思想，就是将STW打散，让-部分GC线程与用户线程并发执行。整个GC过程分为四个阶段 初始标记阶段: STW只标记出根对象直接引用的对象。 并发标记:继续标记其他对象，与应用程序是并发执行。 重新标记: STW 对并发执行阶段的对象进行重新标记。 并发清除:并行。将产生的垃圾清除。清除过程中，应用程序又会不断的产生新的垃圾，叫做浮动垃圾。这些垃圾就要留到下一次GC过程中清除。 Concurrent Mark Sweep收集器运行示意图如下： 6. Parallel Old（并行GC）标记-整理Parallel Old是Parallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法。单线程的老年代Serial Old收集器在服务端性能比较差，即使新生代使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果。 在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge收集器加上Parallel Old收集器组合使用。 Parallel Scavenge/ Parallel Old收集器运行示意图如下： 7. G1(Garbage First)（JDK1.7update14才可以正式商用）G1收集器是一款面向服务端应用的收集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发收集器，并且它能建立可预测的停顿时间模型。 在G1中分代概念仍然保留。虽然G1不需要和其他收集器配合，可以独立管理GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象，以获取更好的收集效果。 G1将内存分成多个大小相等的独立区域，虽然还保留着新生代和老年代的概念，但是新生代和老年代不再是物理隔离的，它们都是一部分Region(不需要连续)的集合。 GC分四个阶段 初始标记标记出GCRoot直接引用的对象。STW 标记Region,通过RSet标记出上-个阶段标记的Region引用到的Old区Region。 并发标记阶段:跟CMS的步骤是差不多的。只是遍历的范围不再是整个Old区，而只需要遍历第二步标记出来的Region。 重新标记:跟CMS中的重 新标记过程是差不多的。 垃圾清理:与CMS不同的是，G1可以采用拷贝算法，直接将整个Region中的对象拷贝到另一个Region。而这个阶段，G1只选择垃圾较多的Region来清理，并不是完全清理。 G1收集器的优点： 1）空间整合： G1从整体看是基于标记-整理算法实现的收集器，从局部看是基于复制算法。这两种算法都意味着G1运行期间不会产生大量内存空间碎片。 2）可预测的停顿： 降低停顿时间是G1和CMS共同关注的，但G1能建立可预测的停顿时间模型，让使用者明确指定在一个长度为M毫秒的时间片段内，GC的时间不得超过N毫秒。 3）有计划的垃圾回收： G1可以有计划的在Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆的价值大小(回收所获得的空间大小，以及回收所需要的时间)，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。这就是Garbage-First的由来。 说明： 1~3用于年轻代垃圾回收：年轻代的垃圾回收称为minor GC 4~6用于年老代垃圾回收（当然也可以用于方法区的回收）：年老代的垃圾回收称为full GC G1独立完成”分代垃圾回收” 注意： 并行与并发 并行：多条垃圾回收线程同时操作 并发：垃圾回收线程与用户线程一起操作 一些问题什么是STW？STW: Stop-The-World。是在垃圾回收算法执行过程当中，需要将JVM内存冻结的一种状态。在STW状态下，JAVA的所有线程都是停止执行的-GC线程除外，native方法可以执行， 但是，不能与JVM交互。GC各种算法优化的重点，就是减少STW,同时这也是JVM调优的重点。 什么是三色标记？CMS的核心算法就是三色标记。 三色标记:是一种逻辑上的抽象。将每个内存对象分成三种颜色。黑色: 表示自己和成员变量都已经标记完毕。灰色: 自己标记完了，但是成员变量还没有完全标记完。白色: 自己未标记完。 CMS通过增量标记increment update的方式来解决漏标的问题。 参考JVM几种垃圾回收器介绍读《深入理解java虚拟机》（三）垃圾回收器","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://xmmarlowe.github.io/tags/GC/"}],"author":"Marlowe"},{"title":"finally中的代码真的一定会执行吗？","slug":"Java/finally中的代码真的一定会执行吗？","date":"2020-04-10T14:17:23.000Z","updated":"2021-04-23T14:21:36.777Z","comments":true,"path":"2020/04/10/Java/finally中的代码真的一定会执行吗？/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/10/Java/finally%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%A0%81%E7%9C%9F%E7%9A%84%E4%B8%80%E5%AE%9A%E4%BC%9A%E6%89%A7%E8%A1%8C%E5%90%97%EF%BC%9F/","excerpt":"finally中的代码在某些情况下不一定能执行…","text":"finally中的代码在某些情况下不一定能执行… 在执行异常处理代码之前程序已经返回 1234567891011public static boolean getTrue(boolean flag) &#123; if (flag) &#123; return flag; &#125; try &#123; flag = true; return flag; &#125; finally &#123; System.out.println(&quot;我是一定会执行的代码？&quot;); &#125; &#125; 如果上述代码传入的参数为true那finally中的代码就不会执行了。 在执行异常处理代码之前程序抛出异常 123456789public static boolean getTrue(boolean flag) &#123; int i = 1/0; try &#123; flag = true; return flag; &#125; finally &#123; System.out.println(&quot;我是一定会执行的代码？&quot;); &#125; &#125; 这里会抛出异常，finally中的代码同样不会执行。原理同1中差不多，只有与 finally 相对应的 try 语句块得到执行的情况下，finally 语句块才会执行。就算try语句执行了finally中的代码一定会执行吗，答案是no，请看下面两种情况。 finally之前执行了System.exit() 123456789public static boolean getTrue(boolean flag) &#123; try &#123; flag = true; System.exit(1); return flag; &#125; finally &#123; System.out.println(&quot;我是一定会执行的代码？&quot;); &#125; &#125; System.exit是用于结束当前正在运行中的java虚拟机，参数为0代表程序正常退出，非0代表程序非正常退出。道理也很简单整个程序都结束了，拿什么来执行finally呢。 所有后台线程终止时，后台线程会突然终止 12345678910111213141516public static void main(String[] args) &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(5); &#125; catch (Exception e) &#123; &#125;finally&#123; System.out.println(&quot;我是一定会执行的代码？&quot;); &#125; &#125; &#125;); t1.setDaemon(true);//设置t1为后台线程 t1.start(); System.out.println(&quot;我是主线程中的代码,主线程是非后台线程。&quot;); &#125; 上述代码，后台线程t1中有finally块，但在执行前，主线程终止了，导致后台线程立即终止，故finally块无法执行 总结： 与finally相对应的try语句得到执行的情况下，finally才有可能执行。 finally执行前，程序或线程终止，finally不会执行。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"finally","slug":"finally","permalink":"https://xmmarlowe.github.io/tags/finally/"}],"author":"Marlowe"},{"title":"Java对象的创建过程","slug":"Java/Java对象的创建过程","date":"2020-04-09T07:30:21.000Z","updated":"2021-04-23T14:22:14.341Z","comments":true,"path":"2020/04/09/Java/Java对象的创建过程/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/09/Java/Java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B/","excerpt":"","text":"对象的创建 Step1:类加载检查虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 Step2:分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 内存分配的两种方式：（补充内容，需要掌握） 选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的. 内存分配并发问题（补充内容，需要掌握） 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 Step3:初始化零值内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 Step4:设置对象头初始化零值完成之后，虚拟机要对对象进行必要的设置， 例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 Step5:执行 init 方法在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 参考Java对象的创建过程","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"对象","slug":"对象","permalink":"https://xmmarlowe.github.io/tags/%E5%AF%B9%E8%B1%A1/"}],"author":"Marlowe"},{"title":"JVM垃圾回收算法","slug":"Java/JVM垃圾回收算法","date":"2020-04-09T07:13:36.000Z","updated":"2021-04-25T08:14:02.108Z","comments":true,"path":"2020/04/09/Java/JVM垃圾回收算法/","link":"","permalink":"https://xmmarlowe.github.io/2020/04/09/Java/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/","excerpt":"","text":"两个概念：新生代： 存放生命周期较短的对象的区域。老年代： 存放生命周期较长的对象的区域。 相同点： 都在Java堆上。 1. 标记-清除算法执行步骤： 标记：遍历内存区域，对需要回收的对象打上标记。 清除：再次遍历内存，对已经标记过的内存进行回收。 图解： 缺点： 效率问题；遍历了两次内存空间（第一次标记，第二次清除）。 空间问题：容易产生大量内存碎片，当再需要一块比较大的内存时，无法找到一块满足要求的，因而不得不再次出发GC。 2. 复制算法将内存划分为等大的两块，每次只使用其中的一块。当一块用完了，触发GC时，将该块中存活的对象复制到另一块区域，然后一次性清理掉这块没有用的内存。下次触发GC时将那块中存活的的又复制到这块，然后抹掉那块，循环往复。 图解 优点 相对于标记–清理算法解决了内存的碎片化问题。 效率更高（清理内存时，记住首尾地址，一次性抹掉）。 缺点： 内存利用率不高，每次只能使用一半内存。 改进 研究表明，新生代中的对象大都是“朝生夕死”的，即生命周期非常短而且对象活得越久则越难被回收。在发生GC时，需要回收的对象特别多，存活的特别少，因此需要搬移到另一块内存的对象非常少，所以不需要1：1划分内存空间。而是将整个新生代按照8 ： 1 ： 1的比例划分为三块，最大的称为Eden（伊甸园）区，较小的两块分别称为To Survivor和From Survivor。 首次GC时，只需要将Eden存活的对象复制到To。然后将Eden区整体回收。再次GC时，将Eden和To存活的复制到From，循环往复这个过程。这样每次新生代中可用的内存就占整个新生代的90%，大大提高了内存利用率。 但不能保证每次存活的对象就永远少于新生代整体的10%，此时复制过去是存不下的，因此这里会用到另一块内存，称为老年代，进行分配担保，将对象存储到老年代。若还不够，就会抛出OOM。 老年代：存放新生代中经过多次回收仍然存活的对象（默认15次）。 3. 标记-整理算法因为前面的复制算法当对象的存活率比较高时，这样一直复制过来，复制过去，没啥意义，且浪费时间。所以针对老年代提出了“标记整理”算法。 执行步骤： 标记：对需要回收的进行标记 整理：让存活的对象，向内存的一端移动，然后直接清理掉没有用的内存。 图解： 4. 分代收集算法当前大多商用虚拟机都采用这种分代收集算法，这个算法并没有新的内容，只是根据对象的存活的时间的长短，将内存分为了新生代和老年代，这样就可以针对不同的区域，采取对应的算法。如： 新生代，每次都有大量对象死亡，有老年代作为内存担保，采取复制算法。 老年代，对象存活时间长，采用标记整理，或者标记清理算法都可。 为什么采用分代收集算法？ 这是基于两个共识 绝大多数对象都是朝生夕死的 熬过越多次垃圾收集过程的对象就越难以消亡 这两个分代假说共同奠定了多款常用的垃圾收集器的一致的设计原则:收集器应该将Java堆划分出不同的区域，然后将回收对象依据其年龄(年龄即对象熬过垃圾收集过程的次数)分配到不同的区域之中存储。显而易见，如果一个区域中大多数对象都是朝生夕灭，难以熬过垃圾收集过程的话，那么把它们集中放在一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的空间;如果剩下的都是难以消亡的对象，那把它们集中放在一块，虚拟机便可以使用较低的频率来回收这个区域，这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用。 在Java堆划分出不同的区域之后，垃圾收集器才可以每次只回收其中某一个或者某些部分的区域 ——因而才有了“Minor GC”“Major GC”“Full GC”这样的回收类型的划分;也才能够针对不同的区域安 排与里面存储对象存亡特征相匹配的垃圾收集算法——因而发展出了“标记-复制算法”“标记-清除算 法”“标记-整理算法”等针对性的垃圾收集算法。这里笔者提前提及了一些新的名词，它们都是本章的 重要角色，稍后都会逐一登场，现在读者只需要知道，这一切的出现都始于分代收集理论。 MinorGC和Majaor/Full GC的区别 MinorGC：发生在新生代的垃圾回收，因为新生代的特点，MinorGC非常频繁，且回收速度比较快，每次回收的量也很大。 Majaor/Full GC：发生在老年代的垃圾回收，也称MajorGC，速度比较慢，相对于MinorGC慢10倍左右。进行一次FullGC通常会伴有多次多次MinorGC。 参考JVM垃圾回收算法 java为什么要分代回收_JVM为什么要分代回收","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"https://xmmarlowe.github.io/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"}],"author":"Marlowe"},{"title":"Java类加载过程","slug":"Java/Java类加载过程","date":"2020-03-31T13:54:49.000Z","updated":"2021-05-03T13:35:14.394Z","comments":true,"path":"2020/03/31/Java/Java类加载过程/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/31/Java/Java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/","excerpt":"","text":"类的生命周期一个类的完整生命周期如下： 类加载过程系统加载 Class 类型的文件主要三步:加载-&gt;连接-&gt;初始化。连接过程又可分为三步:验证-&gt;准备-&gt;解析。 加载类加载过程的第一步，主要完成下面3件事情： 通过全类名获取定义此类的二进制字节流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口 一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。 验证 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意： 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在 Java 堆中。 这里所设置的初始值”通常情况”下是数据类型默认的零值（如0、0L、null、false等），比如我们定义了public static int value=111 ，那么 value 变量在准备阶段的初始值就是 0 而不是111（初始化阶段才会赋值）。特殊情况：比如给 value 变量加上了 fianl 关键字public static final int value=111 ，那么准备阶段 value 的值就被赋值为 111。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方法表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。 综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。 初始化初始化是类加载的最后一步，也是真正执行类中定义的 Java 程序代码(字节码)，初始化阶段是执行初始化方法 &lt;clinit&gt; ()方法的过程。 对于&lt;clinit&gt;（） 方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为 &lt;clinit&gt;（） 方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起死锁，并且这种死锁很难被发现。 对于初始化阶段，虚拟机严格规范了有且只有5种情况下，必须对类进行初始化(只有主动去使用类才会初始化类)： 当遇到 new 、 getstatic、putstatic或invokestatic 这4条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 当jvm执行new指令时会初始化类。即当程序创建一个类的实例对象。 当jvm执行getstatic指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当jvm执行putstatic指令时会初始化类。即程序给类的静态变量赋值。 当jvm执行invokestatic指令时会初始化类。即程序调用类的静态方法。 使用 java.lang.reflect 包的方法对类进行反射调用时如Class.forname(“…”),newInstance()等等。 ，如果类没初始化，需要触发其初始化。 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。M5. ethodHandle和VarHandle可以看作是轻量级的反射调用机制，而要想使用这2个调用， 就必须先使用findStaticVarHandle来初始化要调用的类。 「补充」 当一个接口中定义了JDK8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 卸载卸载类即该类的Class对象被GC。 卸载类需要满足3个要求: 该类的所有的实例对象都已被GC，也就是说堆不存在该类的实例对象。 该类没有在其他任何地方被引用 该类的类加载器的实例已被GC 所以，在JVM生命周期类，由jvm自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。 只要想通一点就好了，jdk自带的BootstrapClassLoader,ExtClassLoader,AppClassLoader负责加载jdk提供的类，所以它们(类加载器的实例)肯定不会被回收。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的。 一个对象从加载到JVM,再到被GC清除，都经历了什么过程? 用户创建一一个对象，JVM首先需要到方法区去找对象的类型信息。然后再创建对象。 JVM要实例化一个对象， 首先要在堆当中先创建一个对象。 -&gt; 半初始化状态 对象首先会分配在堆内存中新生代的Eden。然后经过一次Minor GC,对象如果存活，就会进入S区。在后续的每次GC中，如果对象一直存活，就会在S区来回拷贝，每移动一次， 年龄加1。-&gt;多大年龄才会移入老年代?年龄最大15(markword中大小为4bit)， 超过一定年龄后，对象转入老年代。 当方法执行结束后，栈中的指针会先移除掉。 堆中的对象，经过Full GC,就会被标记为垃圾，然后被GC线程清理掉。 参考类的生命周期","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"}],"author":"Marlowe"},{"title":"Java8四大函数式接口","slug":"Java/Java8四大函数式接口","date":"2020-03-25T05:00:01.000Z","updated":"2021-04-23T14:22:10.954Z","comments":true,"path":"2020/03/25/Java/Java8四大函数式接口/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/25/Java/Java8%E5%9B%9B%E5%A4%A7%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3/","excerpt":"只有一个方法的接口叫做函数式接口。Function、Predicate、Consumer、Supplier","text":"只有一个方法的接口叫做函数式接口。Function、Predicate、Consumer、Supplier 函数式接口的作用：简化编程模型，在新版本的框架底层大量应用！ 12345@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125;// foreach（消费者类型的函数式接口） Function函数型接口：有一个输入参数，有一个输出。 源码： 1234567891011@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t);&#125; 代码示例： 123456789101112131415161718// 只要是函数型接口，可以用lambda表达式简化public static void main(String[] args) &#123; Function function = new Function&lt;String, String&gt;() &#123; @Override public String apply(String string) &#123; return string; &#125; &#125;; System.out.println(function.apply(&quot;hello&quot;)); &#125;// 简化写法public static void main(String[] args) &#123; Function&lt;String, String&gt; function = (str) -&gt; &#123; return str; &#125;; System.out.println(function.apply(&quot;hello&quot;)); &#125; 结果： 1hello Predicate断定型接口：有一个输入参数，返回值只能是布尔值。 源码： 123456789101112@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return &#123;@code true&#125; if the input argument matches the predicate, * otherwise &#123;@code false&#125; */ boolean test(T t);&#125; 代码示例： 12345678910/** * 判断字符串是否为空 * @param args */public static void main(String[] args) &#123; Predicate&lt;String&gt; predicate = (str) -&gt;&#123; return str.isEmpty(); &#125;; System.out.println(predicate.test(&quot;11&quot;));&#125; 结果： 12falsetrue Consumer消费型接口：只有输入，没有返回值。 源码： 12345678910@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; /** * Performs this operation on the given argument. * * @param t the input argument */ void accept(T t);&#125; 代码示例： 1234567891011/** * 打印字符串 * * @param args */public static void main(String[] args) &#123; Consumer&lt;String&gt; consumer = str -&gt; &#123; System.out.println(str); &#125;; consumer.accept(&quot;consumer&quot;);&#125; 结果： 1consumer Supplier供给型接口：没有参数，只有返回值。 12345678910@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; /** * Gets a result. * * @return a result */ T get();&#125; 代码示例： 1234567891011/** * 返回固定值 1024 * * @param args */public static void main(String[] args) &#123; Supplier&lt;Integer&gt; supplier = () -&gt; &#123; return 1024; &#125;; System.out.println(supplier.get());&#125; 结果： 11024","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"函数式接口","slug":"函数式接口","permalink":"https://xmmarlowe.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3/"}],"author":"Marlowe"},{"title":"JVM GC调优","slug":"Java/JVM-GC调优","date":"2020-03-22T16:46:49.000Z","updated":"2021-05-04T11:30:49.162Z","comments":true,"path":"2020/03/23/Java/JVM-GC调优/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/23/Java/JVM-GC%E8%B0%83%E4%BC%98/","excerpt":"JVM调优入门…","text":"JVM调优入门… JVM调优是必须的吗？GC调优对于java服务是必须的吗？实际上，我感觉80%的java的程序员在实际工作中都没有碰到过GC调优吧，这是因为多数的Java应用不需要在服务器上进行GC优化，多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题，需要记住一点：GC调优是最后要做的工作。 GC调优的目的可以总结为下面两点： 减少对象晋升到老年代的数量 减少FullGC的执行时间 减少对象晋升到老年代的数量分代垃圾回收是Oracle JVM中回收思想。 我们知道在Eden区创建的对象，在from Survivor 复制到to Survivor区之后，达到一定年龄就进入了老年代(15次)。有些对象因为比较大就直接进入了老年代。在老年代的GC时间相比于年轻代时间更长。因此，减少对象进入老年代可以降低Full GC的频率。 减少FullGC的执行时间Full GC的时间比Minor GC要长。所以如果执行太长时间的Full GC（超过1秒），就会发生超时错误 如果你试着减少老年代的大小来降低Full GC的执行时间，可能会引发OutOfMemoryError或者导致Full GC的频率升高。 如果是通过增加老年代的大小来降低Full GC的频率，执行时间将会增加。 影响GC的参数JVM调优主要用到参数罗列在下面的两张表中。主要分为内存参数和垃圾类型参数。GC优化的过程就是在调试这些参数的过程。 下表是与JVM内存相关的参数： 1.针对JVM堆的设置，一般可以通过-Xms -Xmx限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，通常把最大、最小设置为相同的值; 2.年轻代和年老代将根据默认的比例（1：2）分配堆内存， 可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代。 比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize设置为同样大小。 一些问题如何进行JVM调优？JVM调优主要就是通过定制VM运行参数来提高JAVA应用程度的运行数据 JVM参数有哪些？JVM参数大致可以分为三类: 标注指令: -开头，这些是所有的HotSpot都支持的参数。可以用java -help打印出来。 非标准指令: -X开头， 这些指令通常是跟特定的HotSpot版本对应的。可以用java -X打印出来。 不稳定参数: -XX开头，这一 -类参数是跟特定HotSpot版本对应的，并且变化非常大。详细的文档资料非常少。在JDK1.8版本下，有几个常用的不稳定指令: java -XX:+ PrintCommandLineFlags :查看当前命令的不稳定指令。 java -XX:+ PrintFlagsInitial :查看所有不稳定指令的默认值。 java -XX: + PrintFlagsFinal:查看所有不稳定指令 最终生效的实际值。 总结JVM调优在实际工作中用到的比较少，但是这也是作为java程序员必须掌握的基本技能。真正熟练的使用GC调优，是建立在多次进行GC监控和调优的实战经验上的。 下面罗列了几个数据作为参考，如果GC执行时间满足下列所有条件，就没有必要进行GC优化了： Minor GC执行非常迅速（50ms以内） Minor GC没有频繁执行（大约10s执行一次） Full GC执行非常迅速（1s以内） Full GC没有频繁执行（大约10min执行一次） 参考JVM GC调优入门","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://xmmarlowe.github.io/tags/GC/"}],"author":"Marlowe"},{"title":"HashMap扩容机制","slug":"Java/HashMap扩容机制","date":"2020-03-16T02:33:21.000Z","updated":"2021-04-23T14:22:02.567Z","comments":true,"path":"2020/03/16/Java/HashMap扩容机制/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/16/Java/HashMap%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/","excerpt":"聊聊HashMap扩容机制","text":"聊聊HashMap扩容机制 1、什么时候才需要扩容 在首次调用put方法的时候，初始化数组table 当HashMap中的元素个数超过数组大小(数组长度)*loadFactor(负载因子)时，就会进行数组扩容，loadFactor的默认值(DEFAULT_LOAD_FACTOR)是0.75,这是一个折中的取值。也就是说，默认情况下，数组大小为16，那么当HashMap中的元素个数超过16×0.75=12(这个值就是阈值或者边界值threshold值)的时候，就把数组的大小扩展为2×16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预知元素的个数能够有效的提高HashMap的性能。 当HashMap中的其中一个链表的对象个数如果达到了8个，此时如果数组长度没有达到64，那么HashMap会先扩容解决，如果已经达到了64，那么这个链表会变成红黑树，节点类型由Node变成TreeNode类型。当然，如果映射关系被移除后，下次执行resize方法时判断树的节点个数低于6，也会再把树转换为链表。 为什么选择长度为6的时候转回链表？ 6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。 什么是红黑树：红黑树是一种自平衡的二叉查找树。 性质： 节点是红色或黑色。 根节点是黑色。 每个叶子节点都是黑色的空节点（NIL节点）。 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 红黑树相比于BST和AVL树有什么优点？ 红黑树是牺牲了严格的高度平衡的优越条件为代价，它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。红黑树能够以O(log2 n)的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。当然，还有一些更好的，但实现起来更复杂的数据结构能够做到一步旋转之内达到平衡，但红黑树能够给我们一个比较“便宜”的解决方案。 相比于BST，因为红黑树可以能确保树的最长路径不大于两倍的最短路径的长度，所以可以看出它的查找效果是有最低保证的。在最坏的情况下也可以保证O(logN)的，这是要好于二叉查找树的。因为二叉查找树最坏情况可以让查找达到O(N)。 红黑树的算法时间复杂度和AVL相同，但统计性能比AVL树更高，所以在插入和删除中所做的后期维护操作肯定会比红黑树要耗时好多，但是他们的查找效率都是O(logN)，所以红黑树应用还是高于AVL树的. 实际上插入 AVL 树和红黑树的速度取决于你所插入的数据.如果你的数据分布较好,则比较宜于采用 AVL树(例如随机产生系列数),但是如果你想处理比较杂乱的情况,则红黑树是比较快的。 2、HashMap的扩容是什么进行扩容，会伴随着一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。在编写程序中，要尽量避免resize。 HashMap在进行扩容时，使用的rehash方式非常巧妙，因为每次扩容都是翻倍，与原来计算的 (n-1)&amp;hash的结果相比，只是多了一个bit位，所以节点要么就在原来的位置，要么就被分配到”原位置+旧容量“这个位置。 说明：5是假设计算出来的原来的索引。这样就验证了上述所描述的：扩容之后所以节点要么就在原来的位置，要么就被分配到”原位置+旧容量”这个位置。 因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就可以了，是0的话索引没变，是1的话索引变成“原索引+oldCap(原位置+旧容量)”。 正是因为这样巧妙的rehash方式，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，在resize的过程中保证了rehash之后每个桶上的节点数一定小于等于原来桶上的节点数，保证了rehash之后不会出现更严重的hash冲突，均匀的把之前的冲突的节点分散到新的桶中了。 resize()方法源码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105final Node&lt;K,V&gt;[] resize() &#123; //得到当前数组 Node&lt;K,V&gt;[] oldTab = table; //如果当前数组等于null长度返回0，否则返回当前数组的长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //当前阀值点 默认是12(16*0.75) int oldThr = threshold; int newCap, newThr = 0; //如果老的数组长度大于0 //开始计算扩容后的大小 if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //修改阈值为int的最大值 threshold = Integer.MAX_VALUE; return oldTab; &#125; /* 没超过最大值，就扩充为原来的2倍 1)(newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY 扩大到2倍之后容量要小于最大容量 2)oldCap &gt;= DEFAULT_INITIAL_CAPACITY 原数组长度大于等于数组初始化长度16 */ else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //阈值扩大一倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; //老阈值点大于0 直接赋值 else if (oldThr &gt; 0) // 老阈值赋值给新的数组长度 newCap = oldThr; else &#123;// 直接使用默认值 newCap = DEFAULT_INITIAL_CAPACITY;//16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize最大上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //新的阀值 默认原来是12 乘以2之后变为24 threshold = newThr; //创建新的哈希表 @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) //newCap是新的数组长度--&gt;32 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //判断旧数组是否等于空 if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 //遍历旧的哈希表的每个桶，重新计算桶里元素的新位置 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; //原来的数据赋值为null 便于GC回收 oldTab[j] = null; //判断数组是否有下一个引用 if (e.next == null) //没有下一个引用，说明不是链表，当前桶上只有一个键值对，直接插入 newTab[e.hash &amp; (newCap - 1)] = e; //判断是否是红黑树 else if (e instanceof TreeNode) //说明是红黑树来处理冲突的，则调用相关方法把树分开 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 采用链表处理冲突 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //通过上述讲解的原理来计算节点的新位置 do &#123; // 原索引 next = e.next; //这里来判断如果等于true e这个节点在resize之后不需要移动位置 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 参考面试题：HashMap扩容机制","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"}],"author":"Marlowe"},{"title":"ConcurrentHashMap 线程安全的具体实现方式/底层具体实现","slug":"Java/ConcurrentHashMap-线程安全的具体实现方式-底层具体实现","date":"2020-03-16T01:57:08.000Z","updated":"2021-04-23T14:21:23.078Z","comments":true,"path":"2020/03/16/Java/ConcurrentHashMap-线程安全的具体实现方式-底层具体实现/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/16/Java/ConcurrentHashMap-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F-%E5%BA%95%E5%B1%82%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"JDK1.7 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 Segment 实现了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 12static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;&#125; 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和 HashMap 类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 的锁。 JDK1.8ConcurrentHashMap 取消了 Segment 分段锁，采用 CAS 和 synchronized 来保证并发安全。数据结构跟 HashMap1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))） synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，效率又提升 N 倍。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"},{"name":"线程安全","slug":"线程安全","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"}],"author":"Marlowe"},{"title":"ConcurrentHashMap 和 Hashtable 的区别","slug":"Java/ConcurrentHashMap-和-Hashtable-的区别","date":"2020-03-16T01:56:52.000Z","updated":"2021-04-23T14:21:20.027Z","comments":true,"path":"2020/03/16/Java/ConcurrentHashMap-和-Hashtable-的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/16/Java/ConcurrentHashMap-%E5%92%8C-Hashtable-%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。","text":"ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7 的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在 JDK1.7 的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 对 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 两者的对比图：HashTable: JDK1.7 的 ConcurrentHashMap： JDK1.8 的 ConcurrentHashMap：JDK1.8 的 ConcurrentHashMap 不再是 Segment 数组 + HashEntry 数组 + 链表，而是 Node 数组 + 链表 / 红黑树。不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。当冲突链表达到一定长度时，链表会转换成红黑树。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"},{"name":"线程安全","slug":"线程安全","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"}],"author":"Marlowe"},{"title":"HashMap 和 Hashtable 的区别","slug":"Java/HashMap-和-Hashtable-的区别","date":"2020-03-15T13:21:12.000Z","updated":"2021-04-23T14:21:48.079Z","comments":true,"path":"2020/03/15/Java/HashMap-和-Hashtable-的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/15/Java/HashMap-%E5%92%8C-Hashtable-%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的,因为 HashTable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对 Null key 和 Null value 的支持： HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： ① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 HashMap 中带有初始容量的构造函数： 12345678910111213141516public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; 下面这个方法保证了 HashMap 总是使用 2 的幂作为哈希表的大小。 12345678910111213/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"}],"author":"Marlowe"},{"title":"ArrayList和LinkedList的区别","slug":"Java/ArrayList和LinkedList的区别","date":"2020-03-15T06:23:58.000Z","updated":"2021-04-23T14:21:09.264Z","comments":true,"path":"2020/03/15/Java/ArrayList和LinkedList的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/15/Java/ArrayList%E5%92%8CLinkedList%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"Arraylist 与 LinkedList 区别? 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。） 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以对于add(E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置i插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为o(n))因为需要先移动到指定位置再插入。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 内存空间占用： ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 参考Arraylist 与 LinkedList 区别?","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"List","slug":"List","permalink":"https://xmmarlowe.github.io/tags/List/"}],"author":"Marlowe"},{"title":"ArrayList扩容机制","slug":"Java/ArrayList扩容机制","date":"2020-03-15T06:23:43.000Z","updated":"2021-04-23T14:21:12.057Z","comments":true,"path":"2020/03/15/Java/ArrayList扩容机制/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/15/Java/ArrayList%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/","excerpt":"","text":"1234567891、添加元素时，首先进行判断是否大于默认容量102、如果，小于默认容量，直接在原来基础上+1，元素添加完毕3、如果，大于默认容量，则需要进行扩容，扩容核心是grow()方法 3.1 扩容之前，首先创建一个新的数组，且旧数组被复制到新的数组中 这样就得到了一个全新的副本，我们在操作时就不会影响原来数组了 3.2 然后通过位运算符将新的容量更新为旧容量的 1.5 倍 3.3 如果新的容量比最小需要容量小，则最小需要容量为当前数组新容量， 如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。 grow()方法： 12345678910111213141516171819202122232425/** * 要分配的最大数组大小 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * ArrayList扩容的核心方法。 */private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"List","slug":"List","permalink":"https://xmmarlowe.github.io/tags/List/"}],"author":"Marlowe"},{"title":"HashMap是线程安全的吗？","slug":"Java/HashMap是线程安全的吗？","date":"2020-03-15T06:23:22.000Z","updated":"2021-04-23T14:22:06.668Z","comments":true,"path":"2020/03/15/Java/HashMap是线程安全的吗？/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/15/Java/HashMap%E6%98%AF%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%90%97%EF%BC%9F/","excerpt":"HashMap的线程不安全体现在会造成死循环、数据丢失、数据覆盖这些问题。其中死循环和数据丢失是在JDK1.7中出现的问题，在JDK1.8中已经得到解决，然而1.8中仍会有数据覆盖这样的问题。","text":"HashMap的线程不安全体现在会造成死循环、数据丢失、数据覆盖这些问题。其中死循环和数据丢失是在JDK1.7中出现的问题，在JDK1.8中已经得到解决，然而1.8中仍会有数据覆盖这样的问题。 扩容引发的线程不安全HashMap的线程不安全主要是发生在扩容函数中，即根源是在transfer函数中，JDK1.7中HashMap的transfer函数如下： 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; 这段代码是HashMap的扩容操作，重新定位每个桶的下标，并采用头插法将元素迁移到新数组中。头插法会将链表的顺序翻转，这也是形成死循环的关键点。 JDK1.8中的线程不安全根据上面JDK1.7出现的问题，在JDK1.8中已经得到了很好的解决，如果你去阅读1.8的源码会发现找不到transfer函数，因为JDK1.8直接在resize函数中完成了数据迁移。另外说一句，JDK1.8在进行元素插入时使用的是尾插法。 为什么说JDK1.8会出现数据覆盖的情况喃，我们来看一下下面这段JDK1.8中的put操作代码： 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 如果没有hash碰撞则直接插入元素 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 其中第六行代码是判断是否出现hash碰撞，假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行完第六行代码后由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所有此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。 除此之前，还有就是代码的第38行处有个++size，我们这样想，还是线程A、B，这两个线程同时进行put操作时，假设当前HashMap的zise大小为10，当线程A执行到第38行代码时，从主内存中获得size的值为10后准备进行+1操作，但是由于时间片耗尽只好让出CPU，线程B快乐的拿到CPU还是从主内存中拿到size的值10进行+1操作，完成了put操作并将size=11写回主内存，然后线程A再次拿到CPU并继续执行(此时size的值仍为10)，当执行完put操作后，还是将size=11写回内存，此时，线程A、B都执行了一次put操作，但是size的值只增加了1，所有说还是由于数据覆盖又导致了线程不安全。 总结HashMap的线程不安全主要体现在下面两个方面： 在JDK1.7中，当并发执行扩容操作时会造成环形链和数据丢失的情况。 在JDK1.8中，在并发执行put操作时会发生数据覆盖的情况。 参考HashMap的实现原理，以及在JDK1.7和1.8的区别","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"}],"author":"Marlowe"},{"title":"HashMap底层原理","slug":"Java/HashMap底层原理","date":"2020-03-15T06:23:01.000Z","updated":"2021-04-23T14:21:58.841Z","comments":true,"path":"2020/03/15/Java/HashMap底层原理/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/15/Java/HashMap%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","excerpt":"","text":"JDK1.7数据结构则是采用的位桶和链表相结合的形式完成了，即拉链法。具体如下图所示： HashMap里面存储的是静态内部类Entry的对象，这个对象其实也是一个key-value的结构。 hash源码： 12345678static int hash(int h) &#123; // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; JDK1.8相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。 hash源码： 1234567 static final int hash(Object key) &#123; int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。 HashMap 的长度为什么是 2 的幂次方为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash 值的范围值-2147483648 到 2147483647，前后加起来大概 40 亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40 亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ (n - 1) &amp; hash”。（n 代表数组长度）。这也就解释了 HashMap 的长度为什么是 2 的幂次方。 这个算法应该如何设计呢？ 我们首先可能会想到采用%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&amp;)操作（也就是说 hash%length==hash&amp;(length-1)的前提是 length 是 2 的 n 次方；）。” 并且 采用二进制位操作 &amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"}],"author":"Marlowe"},{"title":"常见的IO模型有哪些？Java中的BIO，NIO，AIO的区别","slug":"Java/常见的IO模型有哪些？Java中的BIO，NIO，AIO的区别","date":"2020-03-15T06:22:22.000Z","updated":"2021-05-03T08:25:03.009Z","comments":true,"path":"2020/03/15/Java/常见的IO模型有哪些？Java中的BIO，NIO，AIO的区别/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/15/Java/%E5%B8%B8%E8%A7%81%E7%9A%84IO%E6%A8%A1%E5%9E%8B%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9FJava%E4%B8%AD%E7%9A%84BIO%EF%BC%8CNIO%EF%BC%8CAIO%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。","text":"从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。 简介当应用程序发起I/O调用后，会经历两个步骤： 内核等待 I/O 设备准备好数据 内核将数据从内核空间拷贝到用户空间。 UNIX系统5种I/O模型： 同步阻塞 I/O 同步非阻塞 I/O I/O 多路复用 信号驱动 I/O 异步 I/O Java中三种常见的I/O模型BIO (Blocking I/O)BIO 属于同步阻塞 IO 模型 。 同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到在内核把数据拷贝到用户空间。 在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。 NIO (Non-blocking/New I/O)Java 中的 NIO 于 Java 1.4 中引入，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。 对于高负载、高并发的（网络）应用，应使用 NIO 。 Java 中的 NIO 可以看作是 I/O 多路复用模型。也有很多人认为，Java 中的 NIO 属于同步非阻塞 IO 模型。 同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。 相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。 但是，这种 IO 模型同样存在问题：应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。 这个时候，I/O 多路复用模型 就上场了。 IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间-&gt;用户空间）还是阻塞的。 IO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。 Java 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。 ChannelJava NIO中的所有I/O操作都基于Channel对象，就像流操作都要基于Stream对象一样，因此很有必要先了解Channel是什么。以下内容摘自JDK 1.8的文档 A channel represents an open connection to an entity such as a hardware device, a file, a network socket, or a program component that is capable of performing one or more distinct I/O operations, for example reading or writing. 从上述内容可知，一个Channel（通道）代表和某一实体的连接，这个实体可以是文件、网络套接字等。也就是说，通道是Java NIO提供的一座桥梁，用于我们的程序和操作系统底层I/O服务进行交互。 通道是一种很基本很抽象的描述，和不同的I/O服务交互，执行不同的I/O操作，实现不一样，因此具体的有FileChannel、SocketChannel等。 通道使用起来跟Stream比较像，可以读取数据到Buffer中，也可以把Buffer中的数据写入通道。 当然，也有区别，主要体现在如下两点： 一个通道，既可以读又可以写，而一个Stream是单向的（所以分 InputStream 和 OutputStream） 通道有非阻塞I/O模式 实现Java NIO中最常用的通道实现是如下几个，可以看出跟传统的 I/O 操作类是一一对应的。 FileChannel：读写文件 DatagramChannel: UDP协议网络通信 SocketChannel：TCP协议网络通信 ServerSocketChannel：监听TCP连接 BufferNIO中所使用的缓冲区不是一个简单的byte数组，而是封装过的Buffer类，通过它提供的API，我们可以灵活的操纵数据，下面细细道来。 与Java基本类型相对应，NIO提供了多种 Buffer 类型，如ByteBuffer、CharBuffer、IntBuffer等，区别就是读写缓冲区时的单位长度不一样（以对应类型的变量为单位进行读写）。 Buffer中有3个很重要的变量，它们是理解Buffer工作机制的关键，分别是: capacity （总容量） position （指针当前位置） limit （读/写边界位置） Buffer的工作方式跟C语言里的字符数组非常的像，类比一下，capacity就是数组的总长度，position就是我们读/写字符的下标变量，limit就是结束符的位置。Buffer初始时3个变量的情况如下图: 在对Buffer进行读/写的过程中，position会往后移动，而 limit 就是 position 移动的边界。由此不难想象，在对Buffer进行写入操作时，limit应当设置为capacity的大小，而对Buffer进行读取操作时，limit应当设置为数据的实际结束位置。（注意：将Buffer数据 写入 通道是Buffer 读取 操作，从通道 读取 数据到Buffer是Buffer 写入 操作） 在对Buffer进行读/写操作前，我们可以调用Buffer类提供的一些辅助方法来正确设置 position 和 limit 的值，主要有如下几个: flip(): 设置 limit 为 position 的值，然后 position 置为0。对Buffer进行读取操作前调用。 rewind(): 仅仅将 position 置0。一般是在重新读取Buffer数据前调用，比如要读取同一个Buffer的数据写入多个通道时会用到。 clear(): 回到初始状态，即 limit 等于 capacity，position 置0。重新对Buffer进行写入操作前调用。 compact(): 将未读取完的数据（position 与 limit 之间的数据）移动到缓冲区开头，并将 position 设置为这段数据末尾的下一个位置。其实就等价于重新向缓冲区中写入了这么一段数据。 Selector简介 Selector（选择器）是一个特殊的组件，用于采集各个通道的状态（或者说事件）。我们先将通道注册到选择器，并设置好关心的事件，然后就可以通过调用select()方法，静静地等待事件发生。 通道有如下4个事件可供我们监听： Accept：有可以接受的连接 Connect：连接成功 Read：有数据可读 Write：可以写入数据了 为什么要用Selector 前文说了，如果用阻塞I/O，需要多线程（浪费内存），如果用非阻塞I/O，需要不断重试（耗费CPU）。Selector的出现解决了这尴尬的问题，非阻塞模式下，通过Selector，我们的线程只为已就绪的通道工作，不用盲目的重试了。比如，当所有通道都没有数据到达时，也就没有Read事件发生，我们的线程会在select()方法处被挂起，从而让出了CPU资源。 三大组件总结 channel类似于一流。 每个channel对应一 个buffer缓冲区。 channel会注册到selector。 select会根据channel上发生的读写事件，将请求交由某个空闲的线程处理。selector对应一 个或者多个线程。 Buffer和Channel都是可读可写的。 AIO (Asynchronous I/O)AIO 也就是 NIO 2。Java 7 中引入了 NIO 的改进版 NIO 2,它是异步 IO 模型。 异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。 目前来说 AIO 的应用还不是很广泛。Netty 之前也尝试使用过 AIO，不过又放弃了。这是因为，Netty 使用了 AIO 之后，在 Linux 系统上的性能并没有多少提升。 最后，来一张图，简单总结一下 Java 中的 BIO、NIO、AIO。 参考京东数科二面:常见的10模型有哪些? Java中的BIO、NIO、 AIO有啥区别?","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"I/O模型","slug":"I-O模型","permalink":"https://xmmarlowe.github.io/tags/I-O%E6%A8%A1%E5%9E%8B/"}],"author":"Marlowe"},{"title":"final,static,this,super关键字总结","slug":"Java/final-static-this-super关键字总结","date":"2020-03-13T07:55:17.000Z","updated":"2021-04-23T14:21:32.347Z","comments":true,"path":"2020/03/13/Java/final-static-this-super关键字总结/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/13/Java/final-static-this-super%E5%85%B3%E9%94%AE%E5%AD%97%E6%80%BB%E7%BB%93/","excerpt":"","text":"final 关键字final关键字，意思是最终的、不可修改的，最见不得变化 ，用来修饰类、方法和变量，具有以下特点： final修饰的类不能被继承，final类中的所有成员方法都会被隐式的指定为final方法； final修饰的方法不能被重写； final修饰的变量是常量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能让其指向另一个对象。 说明： 使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升（现在的Java版本已经不需要使用final方法进行这些优化了）。类中所有的private方法都隐式地指定为final。 static 关键字static 关键字主要有以下四种使用场景： 修饰成员变量和成员方法: 被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享，可以并且建议通过类名调用。被static 声明的成员变量属于静态成员变量，静态变量 存放在 Java 内存区域的方法区。调用格式：类名.静态变量名 类名.静态方法名() 静态代码块: 静态代码块定义在类中方法外, 静态代码块在非静态代码块之前执行(静态代码块—&gt;非静态代码块—&gt;构造方法)。 该类不管创建多少对象，静态代码块只执行一次. 静态内部类（static修饰类的话只能修饰内部类）： 静态内部类与非静态内部类之间存在一个最大的区别: 非静态内部类在编译完成之后会隐含地保存着一个引用，该引用是指向创建它的外围类，但是静态内部类却没有。没有这个引用就意味着：1. 它的创建是不需要依赖外围类的创建。2. 它不能使用任何外围类的非static成员变量和方法。 静态导包(用来导入类中的静态资源，1.5之后的新特性): 格式为：import static 这两个关键字连用可以指定导入某个类中的指定静态资源，并且不需要使用类名调用类中静态成员，可以直接使用类中静态成员变量和成员方法。 this 关键字this关键字用于引用类的当前实例。例如： 1234567891011class Manager &#123; Employees[] employees; void manageEmployees() &#123; int totalEmp = this.employees.length; System.out.println(&quot;Total employees: &quot; + totalEmp); this.report(); &#125; void report() &#123; &#125;&#125; 在上述代码中，this关键字运用于两个地方: this.employees.length：访问Manager的当前实例的变量。 this.report（）：调用类Manager的当前实例的方法。此关键字是可选的，这意味着如果上面的示例在不使用此关键字的情况下表现相同。 但是，使用此关键字可能会使代码更易读或易懂。super 关键字 使用 this 和 super 要注意的问题： 在构造器中使用 super() 调用父类中的其他构造方法时，该语句必须处于构造器的首行，否则编译器会报错。另外，this 调用本类中的其他构造方法时，也要放在首行。 this、super不能用在static方法中。 简单解释一下： 被 static 修饰的成员属于类，不属于单个这个类的某个对象，被类中所有对象共享。而 this 代表对本类对象的引用，指向本类对象；而 super 代表对父类对象的引用，指向父类对象；所以， this和super是属于对象范畴的东西，而静态方法是属于类范畴的东西。 参考final,static,this,super 关键字总结","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"关键字","slug":"关键字","permalink":"https://xmmarlowe.github.io/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"}],"author":"Marlowe"},{"title":"Arrays.asList()使用指南","slug":"Java/Arrays-asList-使用指南","date":"2020-03-13T02:40:40.000Z","updated":"2021-04-23T14:21:15.510Z","comments":true,"path":"2020/03/13/Java/Arrays-asList-使用指南/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/13/Java/Arrays-asList-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"Arrays.asList()将数组转换为集合后,底层其实还是数组","text":"Arrays.asList()将数组转换为集合后,底层其实还是数组 1234567891011public class Test1 &#123; public static void main(String[] args) &#123; String[] str = new String[]&#123;&quot;111&quot;, &quot;222&quot;&#125;; List&lt;String&gt; list = Arrays.asList(str); list.add(&quot;333&quot;); list.forEach(a-&gt;&#123; System.out.println(a); &#125;); &#125;&#125; 12345运行报错：Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) at test.Test1.main(Test1.java:16) 使用注意事项传递的数组必须是对象数组，而不是基本类型 1234567int[] myArray = &#123;1, 2, 3&#125;;List myList = Arrays.asList(myArray);System.out.println(myList.size());//1System.out.println(myList.get(0));//数组地址值System.out.println(myList.get(1));//报错：ArrayIndexOutOfBoundsException: 1int[] array = (int[]) myList.get(0);System.out.println(array[0]);//1 当传入一个原生数据类型数组时，Arrays.asList() 的真正得到的参数就不是数组中的元素，而是数组对象本身！此时List 的唯一元素就是这个数组，这也就解释了上面的代码。 我们使用包装类型数组就可以解决这个问题。 12345Integer[] myArray = &#123;1, 2, 3&#125;;List myList = Arrays.asList(myArray);System.out.println(myList.size());//3System.out.println(myList.get(0));//1System.out.println(myList.get(1));//2 使用集合的修改方法:add()、remove()、clear()会抛出异常。 1234List myList = Arrays.asList(1, 2, 3);myList.add(4);//运行时报错：UnsupportedOperationExceptionmyList.remove(1);//运行时报错：UnsupportedOperationExceptionmyList.clear();//运行时报错：UnsupportedOperationException Arrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。 12List myList = Arrays.asList(1, 2, 3);System.out.println(myList.getClass());//class java.util.Arrays$ArrayList 查看remove() 方法，可以知道为啥抛出UnsupportedOperationException。 123public E remove(int index) &#123; throw new UnsupportedOperationException();&#125; 如何正确的将数组转换为ArrayList？1、最简便的方法1List list = new ArrayList&lt;&gt;(Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) 2、使用Java8的Stream12345Integer [] myArray = &#123; 1, 2, 3 &#125;;List myList = Arrays.stream(myArray).collect(Collectors.toList());//基本类型也可以实现转换（依赖boxed的装箱操作）int [] myArray2 = &#123; 1, 2, 3 &#125;;List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList()); 参考Arrays.asList()使用指南","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Arrays","slug":"Arrays","permalink":"https://xmmarlowe.github.io/tags/Arrays/"}],"author":"Marlowe"},{"title":"JVM-GC如何判断对象可以被回收","slug":"Java/JVM-GC如何判断对象可以被回收","date":"2020-03-09T08:26:44.000Z","updated":"2021-04-25T02:51:27.475Z","comments":true,"path":"2020/03/09/Java/JVM-GC如何判断对象可以被回收/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/09/Java/JVM-GC%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E5%AF%B9%E8%B1%A1%E5%8F%AF%E4%BB%A5%E8%A2%AB%E5%9B%9E%E6%94%B6/","excerpt":"","text":"引用计数法方式：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。优点：实现简单，效率高。缺点：无法解决循环引用。 可达性分析法方式：从一系列被称为GC ROOT的对象开始，向下搜索，搜索走过的路径称为引用链，当一个对象到GC ROOT之间没有引用链，说明这个对象不可用。 GC ROOT对象： 虚拟机栈中引用的对象 方法区内类的静态属性引用的对象 方法区常量引用的对象 本地方法栈中引用的对象 finalize()当一个对象被判定为不可达对象后，也并不是非死不可。在通过可达性分析算法判断没有引用链使之与GC ROOT相连，会判断该对象是否有必要执行finalize方法:假如重写了finalize，并且未调用过，则说明有必要执行。 判断有必要执行finalize的对象，会被放入一个队列，有jvm建立的低优先级的Finalizer线程去执行。 当在finalize中自救成功的对象，就会在第二次标记时移除即将回收的集合。自救失败的就会被回收，不会再执行finalize。 所谓自救就是把自己与引用链上的一个对象关联起来。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://xmmarlowe.github.io/tags/GC/"}],"author":"Marlowe"},{"title":"Java中的异常体系","slug":"Java/Java中的异常体系","date":"2020-03-09T07:58:09.000Z","updated":"2021-04-23T14:22:33.839Z","comments":true,"path":"2020/03/09/Java/Java中的异常体系/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/09/Java/Java%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BD%93%E7%B3%BB/","excerpt":"","text":"所有异常类都是Throwable的子类 异常可分为Error(错误)和Exception(异常)两类 Exception又可分为RuntimeException(运行时异常)和非运行时异常两类 Error是程序无法处理的错误，一旦出现这个错误，则程序被迫停止运行。 Exception不会导致程序停止，分为RuntimeException运行时异常和CheckedException检查异常。 RuntimeException常常发生在程序运行过程中，会导致程序当前线程执行失败。CheckedException常常发生在程序编译过程中，会导致程序编译不通过。","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"异常","slug":"异常","permalink":"https://xmmarlowe.github.io/tags/%E5%BC%82%E5%B8%B8/"}],"author":"Marlowe"},{"title":"Java类加载机制和类加载器概述","slug":"Java/Java类加载机制和类加载器概述","date":"2020-03-09T05:44:40.000Z","updated":"2021-05-03T13:06:45.847Z","comments":true,"path":"2020/03/09/Java/Java类加载机制和类加载器概述/","link":"","permalink":"https://xmmarlowe.github.io/2020/03/09/Java/Java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%92%8C%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E6%A6%82%E8%BF%B0/","excerpt":"当程序主动使用某个类时，如果该类还未被加载到内存中，则JVM会通过加载、连接、初始化3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时候也把这3个步骤统称为类加载或类初始化。","text":"当程序主动使用某个类时，如果该类还未被加载到内存中，则JVM会通过加载、连接、初始化3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时候也把这3个步骤统称为类加载或类初始化。 一、类加载过程1. 加载加载指的是将类的Class文件读入到内存，并为之创建一个java.lang.Class对象，也就是说，当程序中使用任何类时，系统都会为之建立一个java.lang.Class对象。 2. 链接当类被加载之后，系统为之生成一个对应的Class对象，接着将会进入连接阶段，连接阶段负责把类的二进制数据合并到JRE中。 3. 初始化初始化是为类的静态变量赋予正确的初始值，准备阶段和初始化阶段看似有点矛盾，其实是不矛盾的，如果类中有语句：private static int a = 10，它的执行过程是这样的，首先字节码文件被加载到内存后，先进行链接的验证这一步骤，验证通过后准备阶段，给a分配内存，因为变量a是static的，所以此时a等于int类型的默认初始值0，即a=0,然后到解析（后面在说），到初始化这一步骤时，才把a的真正的值10赋给a,此时a=10。 二、类加载时机 创建类的实例，也即new一个对象 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（Class.forName(“com.lyj.load”)） 初始化一个类的子类（会首先初始化子类的父类） JVM启动时标明的启动类，即文件名和类名相同的那个类 除此之外，下面几种情形需要特别指出： 对于一个final类型的静态变量，如果该变量的值在编译时就可以确定下来，那么这个变量相当于“宏变量”。Java编译器会在编译时直接把这个变量出现的地方替换成它的值，因此即使程序使用该静态变量，也不会导致该类的初始化。反之，如果final类型的静态Field的值不能在编译时确定下来，则必须等到运行时才可以确定该变量的值，如果通过该类来访问它的静态变量，则会导致该类被初始化。 三、类加载器 根类加载器（bootstrap class loader）:它用来加载 Java 的核心类，是用原生代码来实现的，并不继承自 java.lang.ClassLoader（负责加载$JAVA_HOME中jre/lib/rt.jar里所有的class，由C++实现，不是ClassLoader子类）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。 扩展类加载器（extensions class loader）：它负责加载JRE的扩展目录，lib/ext或者由java.ext.dirs系统属性指定的目录中的JAR包的类。由Java语言实现，父类加载器为null。 系统类加载器（system class loader）：被称为系统（也称为应用）类加载器，它负责在JVM启动时加载来自Java命令的-classpath选项、java.class.path系统属性，或者CLASSPATH换将变量所指定的JAR包和类路径。程序可以通过ClassLoader的静态方法getSystemClassLoader()来获取系统类加载器。如果没有特别指定，则用户自定义的类加载器都以此类加载器作为父加载器。由Java语言实现，父类加载器为ExtClassLoader。 四、类加载机制 全盘负责：所谓全盘负责，就是当一个类加载器负责加载某个Class时，该Class所依赖和引用其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入。 双亲委派：所谓的双亲委派，则是先让父类加载器试图加载该Class，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。通俗的讲，就是某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父加载器，依次递归，如果父加载器可以完成类加载任务，就成功返回；只有父加载器无法完成此加载任务时，才自己去加载。 缓存机制。缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区中搜寻该Class，只有当缓存区中不存在该Class对象时，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓冲区中。这就是为很什么修改了Class后，必须重新启动JVM，程序所做的修改才会生效的原因。 双亲委派机制 工作原理双亲委派机制，其工作原理的是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都很懒，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己才想办法去完成。 优势采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。 好处 主要是为了安全性，避免用户自己编写的类动态替换Java的一些核心类，比如String，Integer。 同时避免了类的重新加载，因为JVM中区分不同类，不仅仅是根据类名，相同的class文件被不同的ClassLoader加载就是不同的两个类。 不想用双亲委派模型怎么办？自定义加载器的话，需要继承 ClassLoader 。如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法 五、参考文档jvm之java类加载机制和类加载器(ClassLoader)的详解","categories":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"}],"author":"Marlowe"}],"categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://xmmarlowe.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://xmmarlowe.github.io/categories/NoSQL/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"随笔","slug":"随笔","permalink":"https://xmmarlowe.github.io/categories/%E9%9A%8F%E7%AC%94/"},{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/categories/%E5%B9%B6%E5%8F%91/"},{"name":"数据库","slug":"数据库","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/categories/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://xmmarlowe.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/categories/Spring/"},{"name":"春招面试","slug":"春招面试","permalink":"https://xmmarlowe.github.io/categories/%E6%98%A5%E6%8B%9B%E9%9D%A2%E8%AF%95/"},{"name":"题解","slug":"题解","permalink":"https://xmmarlowe.github.io/categories/%E9%A2%98%E8%A7%A3/"},{"name":"数据结构","slug":"数据结构","permalink":"https://xmmarlowe.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://xmmarlowe.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"自定义工具类","slug":"自定义工具类","permalink":"https://xmmarlowe.github.io/categories/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7%E7%B1%BB/"},{"name":"学习方法","slug":"学习方法","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://xmmarlowe.github.io/categories/ElasticSearch/"},{"name":"环境配置之踩坑","slug":"环境配置之踩坑","permalink":"https://xmmarlowe.github.io/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%B9%8B%E8%B8%A9%E5%9D%91/"},{"name":"Java基础","slug":"Java基础","permalink":"https://xmmarlowe.github.io/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://xmmarlowe.github.io/categories/LeetCode%E9%A2%98%E8%A7%A3/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://xmmarlowe.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Top K","slug":"Top-K","permalink":"https://xmmarlowe.github.io/tags/Top-K/"},{"name":"进程","slug":"进程","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"调度","slug":"调度","permalink":"https://xmmarlowe.github.io/tags/%E8%B0%83%E5%BA%A6/"},{"name":"多线程","slug":"多线程","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Redis","slug":"Redis","permalink":"https://xmmarlowe.github.io/tags/Redis/"},{"name":"Linux","slug":"Linux","permalink":"https://xmmarlowe.github.io/tags/Linux/"},{"name":"命令","slug":"命令","permalink":"https://xmmarlowe.github.io/tags/%E5%91%BD%E4%BB%A4/"},{"name":"僵尸进程","slug":"僵尸进程","permalink":"https://xmmarlowe.github.io/tags/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/"},{"name":"孤儿进程","slug":"孤儿进程","permalink":"https://xmmarlowe.github.io/tags/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/"},{"name":"URL","slug":"URL","permalink":"https://xmmarlowe.github.io/tags/URL/"},{"name":"URI","slug":"URI","permalink":"https://xmmarlowe.github.io/tags/URI/"},{"name":"Java","slug":"Java","permalink":"https://xmmarlowe.github.io/tags/Java/"},{"name":"学习","slug":"学习","permalink":"https://xmmarlowe.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"书籍","slug":"书籍","permalink":"https://xmmarlowe.github.io/tags/%E4%B9%A6%E7%B1%8D/"},{"name":"锁","slug":"锁","permalink":"https://xmmarlowe.github.io/tags/%E9%94%81/"},{"name":"redo log","slug":"redo-log","permalink":"https://xmmarlowe.github.io/tags/redo-log/"},{"name":"binlog","slug":"binlog","permalink":"https://xmmarlowe.github.io/tags/binlog/"},{"name":"undo log","slug":"undo-log","permalink":"https://xmmarlowe.github.io/tags/undo-log/"},{"name":"SQL","slug":"SQL","permalink":"https://xmmarlowe.github.io/tags/SQL/"},{"name":"调优","slug":"调优","permalink":"https://xmmarlowe.github.io/tags/%E8%B0%83%E4%BC%98/"},{"name":"HTTP","slug":"HTTP","permalink":"https://xmmarlowe.github.io/tags/HTTP/"},{"name":"as-if-serial","slug":"as-if-serial","permalink":"https://xmmarlowe.github.io/tags/as-if-serial/"},{"name":"happens-before","slug":"happens-before","permalink":"https://xmmarlowe.github.io/tags/happens-before/"},{"name":"内存布局","slug":"内存布局","permalink":"https://xmmarlowe.github.io/tags/%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"},{"name":"volatile","slug":"volatile","permalink":"https://xmmarlowe.github.io/tags/volatile/"},{"name":"AQS","slug":"AQS","permalink":"https://xmmarlowe.github.io/tags/AQS/"},{"name":"CAS","slug":"CAS","permalink":"https://xmmarlowe.github.io/tags/CAS/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://xmmarlowe.github.io/tags/Synchronized/"},{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"https://xmmarlowe.github.io/tags/ReentrantLock/"},{"name":"线程","slug":"线程","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"线程安全","slug":"线程安全","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"name":"Object","slug":"Object","permalink":"https://xmmarlowe.github.io/tags/Object/"},{"name":"join","slug":"join","permalink":"https://xmmarlowe.github.io/tags/join/"},{"name":"操作系统","slug":"操作系统","permalink":"https://xmmarlowe.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内存管理","slug":"内存管理","permalink":"https://xmmarlowe.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"Unsafe","slug":"Unsafe","permalink":"https://xmmarlowe.github.io/tags/Unsafe/"},{"name":"Thread","slug":"Thread","permalink":"https://xmmarlowe.github.io/tags/Thread/"},{"name":"Runnable","slug":"Runnable","permalink":"https://xmmarlowe.github.io/tags/Runnable/"},{"name":"Future","slug":"Future","permalink":"https://xmmarlowe.github.io/tags/Future/"},{"name":"过滤器","slug":"过滤器","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"name":"BST","slug":"BST","permalink":"https://xmmarlowe.github.io/tags/BST/"},{"name":"AVL","slug":"AVL","permalink":"https://xmmarlowe.github.io/tags/AVL/"},{"name":"红黑树","slug":"红黑树","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"JMM","slug":"JMM","permalink":"https://xmmarlowe.github.io/tags/JMM/"},{"name":"通信","slug":"通信","permalink":"https://xmmarlowe.github.io/tags/%E9%80%9A%E4%BF%A1/"},{"name":"反射","slug":"反射","permalink":"https://xmmarlowe.github.io/tags/%E5%8F%8D%E5%B0%84/"},{"name":"MySQL","slug":"MySQL","permalink":"https://xmmarlowe.github.io/tags/MySQL/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://xmmarlowe.github.io/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"装饰器","slug":"装饰器","permalink":"https://xmmarlowe.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"name":"上下文","slug":"上下文","permalink":"https://xmmarlowe.github.io/tags/%E4%B8%8A%E4%B8%8B%E6%96%87/"},{"name":"IO","slug":"IO","permalink":"https://xmmarlowe.github.io/tags/IO/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://xmmarlowe.github.io/tags/SpringMVC/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://xmmarlowe.github.io/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"name":"RESTful","slug":"RESTful","permalink":"https://xmmarlowe.github.io/tags/RESTful/"},{"name":"缺页中断","slug":"缺页中断","permalink":"https://xmmarlowe.github.io/tags/%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD/"},{"name":"页面置换算法","slug":"页面置换算法","permalink":"https://xmmarlowe.github.io/tags/%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/"},{"name":"进程通信","slug":"进程通信","permalink":"https://xmmarlowe.github.io/tags/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1/"},{"name":"死锁","slug":"死锁","permalink":"https://xmmarlowe.github.io/tags/%E6%AD%BB%E9%94%81/"},{"name":"二叉树","slug":"二叉树","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"https://xmmarlowe.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"数组","slug":"数组","permalink":"https://xmmarlowe.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"dp","slug":"dp","permalink":"https://xmmarlowe.github.io/tags/dp/"},{"name":"TopK","slug":"TopK","permalink":"https://xmmarlowe.github.io/tags/TopK/"},{"name":"ABA","slug":"ABA","permalink":"https://xmmarlowe.github.io/tags/ABA/"},{"name":"异步","slug":"异步","permalink":"https://xmmarlowe.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"ForkJoin","slug":"ForkJoin","permalink":"https://xmmarlowe.github.io/tags/ForkJoin/"},{"name":"BTree","slug":"BTree","permalink":"https://xmmarlowe.github.io/tags/BTree/"},{"name":"B+Tree","slug":"B-Tree","permalink":"https://xmmarlowe.github.io/tags/B-Tree/"},{"name":"排序","slug":"排序","permalink":"https://xmmarlowe.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"JUC","slug":"JUC","permalink":"https://xmmarlowe.github.io/tags/JUC/"},{"name":"原子类","slug":"原子类","permalink":"https://xmmarlowe.github.io/tags/%E5%8E%9F%E5%AD%90%E7%B1%BB/"},{"name":"线程池","slug":"线程池","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"synchronized","slug":"synchronized","permalink":"https://xmmarlowe.github.io/tags/synchronized/"},{"name":"动态代理","slug":"动态代理","permalink":"https://xmmarlowe.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"JDK","slug":"JDK","permalink":"https://xmmarlowe.github.io/tags/JDK/"},{"name":"Spring","slug":"Spring","permalink":"https://xmmarlowe.github.io/tags/Spring/"},{"name":"并发","slug":"并发","permalink":"https://xmmarlowe.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"JWT","slug":"JWT","permalink":"https://xmmarlowe.github.io/tags/JWT/"},{"name":"DNS","slug":"DNS","permalink":"https://xmmarlowe.github.io/tags/DNS/"},{"name":"TCP","slug":"TCP","permalink":"https://xmmarlowe.github.io/tags/TCP/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://xmmarlowe.github.io/tags/HTTPS/"},{"name":"OSI","slug":"OSI","permalink":"https://xmmarlowe.github.io/tags/OSI/"},{"name":"Ping","slug":"Ping","permalink":"https://xmmarlowe.github.io/tags/Ping/"},{"name":"网络分层","slug":"网络分层","permalink":"https://xmmarlowe.github.io/tags/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82/"},{"name":"get","slug":"get","permalink":"https://xmmarlowe.github.io/tags/get/"},{"name":"post","slug":"post","permalink":"https://xmmarlowe.github.io/tags/post/"},{"name":"Cookie","slug":"Cookie","permalink":"https://xmmarlowe.github.io/tags/Cookie/"},{"name":"Session","slug":"Session","permalink":"https://xmmarlowe.github.io/tags/Session/"},{"name":"UDP","slug":"UDP","permalink":"https://xmmarlowe.github.io/tags/UDP/"},{"name":"BufferPoll","slug":"BufferPoll","permalink":"https://xmmarlowe.github.io/tags/BufferPoll/"},{"name":"索引","slug":"索引","permalink":"https://xmmarlowe.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"InnoDB","slug":"InnoDB","permalink":"https://xmmarlowe.github.io/tags/InnoDB/"},{"name":"MyISAM","slug":"MyISAM","permalink":"https://xmmarlowe.github.io/tags/MyISAM/"},{"name":"事务","slug":"事务","permalink":"https://xmmarlowe.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"隔离级别","slug":"隔离级别","permalink":"https://xmmarlowe.github.io/tags/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"name":"mvcc","slug":"mvcc","permalink":"https://xmmarlowe.github.io/tags/mvcc/"},{"name":"countDownLatch","slug":"countDownLatch","permalink":"https://xmmarlowe.github.io/tags/countDownLatch/"},{"name":"CyclicBarrier","slug":"CyclicBarrier","permalink":"https://xmmarlowe.github.io/tags/CyclicBarrier/"},{"name":"Semaphore","slug":"Semaphore","permalink":"https://xmmarlowe.github.io/tags/Semaphore/"},{"name":"Callable","slug":"Callable","permalink":"https://xmmarlowe.github.io/tags/Callable/"},{"name":"redis","slug":"redis","permalink":"https://xmmarlowe.github.io/tags/redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://xmmarlowe.github.io/tags/SpringBoot/"},{"name":"Jedis","slug":"Jedis","permalink":"https://xmmarlowe.github.io/tags/Jedis/"},{"name":"数据类型","slug":"数据类型","permalink":"https://xmmarlowe.github.io/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"name":"效率","slug":"效率","permalink":"https://xmmarlowe.github.io/tags/%E6%95%88%E7%8E%87/"},{"name":"工作方法","slug":"工作方法","permalink":"https://xmmarlowe.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95/"},{"name":"ES","slug":"ES","permalink":"https://xmmarlowe.github.io/tags/ES/"},{"name":"API","slug":"API","permalink":"https://xmmarlowe.github.io/tags/API/"},{"name":"Resuful","slug":"Resuful","permalink":"https://xmmarlowe.github.io/tags/Resuful/"},{"name":"踩坑","slug":"踩坑","permalink":"https://xmmarlowe.github.io/tags/%E8%B8%A9%E5%9D%91/"},{"name":"Java基础","slug":"Java基础","permalink":"https://xmmarlowe.github.io/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"面经","slug":"面经","permalink":"https://xmmarlowe.github.io/tags/%E9%9D%A2%E7%BB%8F/"},{"name":"Swagger","slug":"Swagger","permalink":"https://xmmarlowe.github.io/tags/Swagger/"},{"name":"配置","slug":"配置","permalink":"https://xmmarlowe.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"注解","slug":"注解","permalink":"https://xmmarlowe.github.io/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"DI","slug":"DI","permalink":"https://xmmarlowe.github.io/tags/DI/"},{"name":"Bean","slug":"Bean","permalink":"https://xmmarlowe.github.io/tags/Bean/"},{"name":"IOC","slug":"IOC","permalink":"https://xmmarlowe.github.io/tags/IOC/"},{"name":"list","slug":"list","permalink":"https://xmmarlowe.github.io/tags/list/"},{"name":"线程不安全","slug":"线程不安全","permalink":"https://xmmarlowe.github.io/tags/%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%AE%89%E5%85%A8/"},{"name":"行为型模式","slug":"行为型模式","permalink":"https://xmmarlowe.github.io/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"策略","slug":"策略","permalink":"https://xmmarlowe.github.io/tags/%E7%AD%96%E7%95%A5/"},{"name":"Json","slug":"Json","permalink":"https://xmmarlowe.github.io/tags/Json/"},{"name":"Utils","slug":"Utils","permalink":"https://xmmarlowe.github.io/tags/Utils/"},{"name":"代理","slug":"代理","permalink":"https://xmmarlowe.github.io/tags/%E4%BB%A3%E7%90%86/"},{"name":"单例","slug":"单例","permalink":"https://xmmarlowe.github.io/tags/%E5%8D%95%E4%BE%8B/"},{"name":"创建型模式","slug":"创建型模式","permalink":"https://xmmarlowe.github.io/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"工厂","slug":"工厂","permalink":"https://xmmarlowe.github.io/tags/%E5%B7%A5%E5%8E%82/"},{"name":"模板","slug":"模板","permalink":"https://xmmarlowe.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"java","slug":"java","permalink":"https://xmmarlowe.github.io/tags/java/"},{"name":"插入排序","slug":"插入排序","permalink":"https://xmmarlowe.github.io/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"},{"name":"外观","slug":"外观","permalink":"https://xmmarlowe.github.io/tags/%E5%A4%96%E8%A7%82/"},{"name":"Docker","slug":"Docker","permalink":"https://xmmarlowe.github.io/tags/Docker/"},{"name":"HashMap","slug":"HashMap","permalink":"https://xmmarlowe.github.io/tags/HashMap/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://xmmarlowe.github.io/tags/Leetcode/"},{"name":"test","slug":"test","permalink":"https://xmmarlowe.github.io/tags/test/"},{"name":"随笔","slug":"随笔","permalink":"https://xmmarlowe.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"public","slug":"public","permalink":"https://xmmarlowe.github.io/tags/public/"},{"name":"private","slug":"private","permalink":"https://xmmarlowe.github.io/tags/private/"},{"name":"protected","slug":"protected","permalink":"https://xmmarlowe.github.io/tags/protected/"},{"name":"default","slug":"default","permalink":"https://xmmarlowe.github.io/tags/default/"},{"name":"包装类","slug":"包装类","permalink":"https://xmmarlowe.github.io/tags/%E5%8C%85%E8%A3%85%E7%B1%BB/"},{"name":"常量池","slug":"常量池","permalink":"https://xmmarlowe.github.io/tags/%E5%B8%B8%E9%87%8F%E6%B1%A0/"},{"name":"String","slug":"String","permalink":"https://xmmarlowe.github.io/tags/String/"},{"name":"finally","slug":"finally","permalink":"https://xmmarlowe.github.io/tags/finally/"},{"name":"final","slug":"final","permalink":"https://xmmarlowe.github.io/tags/final/"},{"name":"finalize","slug":"finalize","permalink":"https://xmmarlowe.github.io/tags/finalize/"},{"name":"集合类","slug":"集合类","permalink":"https://xmmarlowe.github.io/tags/%E9%9B%86%E5%90%88%E7%B1%BB/"},{"name":"类图","slug":"类图","permalink":"https://xmmarlowe.github.io/tags/%E7%B1%BB%E5%9B%BE/"},{"name":"抽象类","slug":"抽象类","permalink":"https://xmmarlowe.github.io/tags/%E6%8A%BD%E8%B1%A1%E7%B1%BB/"},{"name":"接口","slug":"接口","permalink":"https://xmmarlowe.github.io/tags/%E6%8E%A5%E5%8F%A3/"},{"name":"JVM","slug":"JVM","permalink":"https://xmmarlowe.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"https://xmmarlowe.github.io/tags/GC/"},{"name":"对象","slug":"对象","permalink":"https://xmmarlowe.github.io/tags/%E5%AF%B9%E8%B1%A1/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"https://xmmarlowe.github.io/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"函数式接口","slug":"函数式接口","permalink":"https://xmmarlowe.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3/"},{"name":"List","slug":"List","permalink":"https://xmmarlowe.github.io/tags/List/"},{"name":"I/O模型","slug":"I-O模型","permalink":"https://xmmarlowe.github.io/tags/I-O%E6%A8%A1%E5%9E%8B/"},{"name":"关键字","slug":"关键字","permalink":"https://xmmarlowe.github.io/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"},{"name":"Arrays","slug":"Arrays","permalink":"https://xmmarlowe.github.io/tags/Arrays/"},{"name":"异常","slug":"异常","permalink":"https://xmmarlowe.github.io/tags/%E5%BC%82%E5%B8%B8/"}]}